{
  "CompileTimeLQP" : {
    "LQP" : {
      "operators" : {
        "12" : {
          "sign" : -1833185194,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 3275,
          "rowCount" : 25,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#14L, n_name#15, n_regionkey#16L, n_comment#17], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "8" : {
          "sign" : -1844519439,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 201000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L)) "
        },
        "19" : {
          "sign" : -1763109902,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 16000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_suppkey#29L] "
        },
        "23" : {
          "sign" : 1635613364,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 201000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#29L, s_name#30, s_address#31, s_nationkey#32L, s_phone#33, s_acctbal#34, s_comment#35], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "4" : {
          "sign" : 1383461897,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 3523613280,
          "rowCount" : 80082120,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#3L = s_suppkey#7L) "
        },
        "15" : {
          "sign" : -114112705,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 13760000000,
          "rowCount" : 80000000,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5, ps_comment#6], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "11" : {
          "sign" : -184173915,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 131,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L)) "
        },
        "9" : {
          "sign" : -582420732,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 201000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#7L, s_name#8, s_address#9, s_nationkey#10L, s_phone#11, s_acctbal#12, s_comment#13], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "22" : {
          "sign" : 861776395,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 201000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#29L) AND isnotnull(s_nationkey#32L)) "
        },
        "26" : {
          "sign" : -2109773610,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 3275,
          "rowCount" : 25,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#36L, n_name#37, n_regionkey#38L, n_comment#39], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "13" : {
          "sign" : -346275464,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 2880000000,
          "rowCount" : 80000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5] "
        },
        "24" : {
          "sign" : 2063394563,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 16,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [n_nationkey#36L] "
        },
        "16" : {
          "sign" : -1591336998,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 24,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [(sum((ps_supplycost#27 * cast(ps_availqty#26 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#23] "
        },
        "5" : {
          "sign" : 1430515012,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 16000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_suppkey#7L] "
        },
        "10" : {
          "sign" : -313453053,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 16,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [n_nationkey#14L] "
        },
        "21" : {
          "sign" : 1428275371,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 24000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_suppkey#29L, s_nationkey#32L] "
        },
        "6" : {
          "sign" : 777070770,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 32000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#10L = n_nationkey#14L) "
        },
        "1" : {
          "sign" : 120055094,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 595682624,
          "rowCount" : 18615082,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(value#0) AND (cast(value#0 as decimal(38,6)) > scalar-subquery#1 [])) "
        },
        "17" : {
          "sign" : 874610647,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 1601642400,
          "rowCount" : 80082120,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ps_availqty#26, ps_supplycost#27] "
        },
        "25" : {
          "sign" : -2012302619,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 131,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#37) AND (n_name#37 = JAPAN)) AND isnotnull(n_nationkey#36L)) "
        },
        "14" : {
          "sign" : 1542235709,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 13760000000,
          "rowCount" : 80000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#3L) "
        },
        "0" : {
          "sign" : 1155009685,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
          "sizeInBytes" : 595682624,
          "rowCount" : 18615082,
          "isRuntime" : false,
          "predicate" : " (unknown) Sort Arguments: [value#0 DESC NULLS LAST], true "
        },
        "20" : {
          "sign" : -458506212,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 32000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#32L = n_nationkey#36L) "
        },
        "27" : {
          "sign" : 1062665249,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 2240000000,
          "rowCount" : 80000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ps_suppkey#25L, ps_availqty#26, ps_supplycost#27] "
        },
        "2" : {
          "sign" : -1211779318,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 595682624,
          "rowCount" : 18615082,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#0] "
        },
        "18" : {
          "sign" : 918586856,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 2882956320,
          "rowCount" : 80082120,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#25L = s_suppkey#29L) "
        },
        "7" : {
          "sign" : 1001821905,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 24000000,
          "rowCount" : 1000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_suppkey#7L, s_nationkey#10L] "
        },
        "29" : {
          "sign" : 2106684597,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 13760000000,
          "rowCount" : 80000000,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#24L, ps_suppkey#25L, ps_availqty#26, ps_supplycost#27, ps_comment#28], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "3" : {
          "sign" : 249550739,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 2242299360,
          "rowCount" : 80082120,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ps_partkey#2L, ps_availqty#4, ps_supplycost#5] "
        },
        "28" : {
          "sign" : -505654325,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 13760000000,
          "rowCount" : 80000000,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#25L) "
        }
      },
      "links" : [ {
        "fromId" : 9,
        "fromName" : "LogicalRelation",
        "toId" : 8,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 8,
        "fromName" : "Filter",
        "toId" : 7,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 7,
        "fromName" : "Project",
        "toId" : 6,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 12,
        "fromName" : "LogicalRelation",
        "toId" : 11,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 11,
        "fromName" : "Filter",
        "toId" : 10,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 10,
        "fromName" : "Project",
        "toId" : 6,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 6,
        "fromName" : "Join",
        "toId" : 5,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 5,
        "fromName" : "Project",
        "toId" : 4,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 15,
        "fromName" : "LogicalRelation",
        "toId" : 14,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 14,
        "fromName" : "Filter",
        "toId" : 13,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 13,
        "fromName" : "Project",
        "toId" : 4,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 4,
        "fromName" : "Join",
        "toId" : 3,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 3,
        "fromName" : "Project",
        "toId" : 2,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 2,
        "fromName" : "Aggregate",
        "toId" : 1,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 23,
        "fromName" : "LogicalRelation",
        "toId" : 22,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 22,
        "fromName" : "Filter",
        "toId" : 21,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 21,
        "fromName" : "Project",
        "toId" : 20,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 26,
        "fromName" : "LogicalRelation",
        "toId" : 25,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 25,
        "fromName" : "Filter",
        "toId" : 24,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 24,
        "fromName" : "Project",
        "toId" : 20,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 20,
        "fromName" : "Join",
        "toId" : 19,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 19,
        "fromName" : "Project",
        "toId" : 18,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 29,
        "fromName" : "LogicalRelation",
        "toId" : 28,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 28,
        "fromName" : "Filter",
        "toId" : 27,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 27,
        "fromName" : "Project",
        "toId" : 18,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 18,
        "fromName" : "Join",
        "toId" : 17,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 17,
        "fromName" : "Project",
        "toId" : 16,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 16,
        "fromName" : "Aggregate",
        "toId" : 1,
        "toName" : "Filter",
        "linkType" : "Subquery"
      }, {
        "fromId" : 1,
        "fromName" : "Filter",
        "toId" : 0,
        "toName" : "Sort",
        "linkType" : "Operator"
      } ],
      "rawPlan" : "Sort [value#0 DESC NULLS LAST], true\n+- Filter (isnotnull(value#0) AND (cast(value#0 as decimal(38,6)) > scalar-subquery#1 []))\n   :  +- Aggregate [(sum((ps_supplycost#27 * cast(ps_availqty#26 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#23]\n   :     +- Project [ps_availqty#26, ps_supplycost#27]\n   :        +- Join Inner, (ps_suppkey#25L = s_suppkey#29L)\n   :           :- Project [s_suppkey#29L]\n   :           :  +- Join Inner, (s_nationkey#32L = n_nationkey#36L)\n   :           :     :- Project [s_suppkey#29L, s_nationkey#32L]\n   :           :     :  +- Filter (isnotnull(s_suppkey#29L) AND isnotnull(s_nationkey#32L))\n   :           :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#29L,s_name#30,s_address#31,s_nationkey#32L,s_phone#33,s_acctbal#34,s_comment#35] parquet\n   :           :     +- Project [n_nationkey#36L]\n   :           :        +- Filter ((isnotnull(n_name#37) AND (n_name#37 = JAPAN)) AND isnotnull(n_nationkey#36L))\n   :           :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#36L,n_name#37,n_regionkey#38L,n_comment#39] parquet\n   :           +- Project [ps_suppkey#25L, ps_availqty#26, ps_supplycost#27]\n   :              +- Filter isnotnull(ps_suppkey#25L)\n   :                 +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#24L,ps_suppkey#25L,ps_availqty#26,ps_supplycost#27,ps_comment#28] parquet\n   +- Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#0]\n      +- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n         +- Join Inner, (ps_suppkey#3L = s_suppkey#7L)\n            :- Project [s_suppkey#7L]\n            :  +- Join Inner, (s_nationkey#10L = n_nationkey#14L)\n            :     :- Project [s_suppkey#7L, s_nationkey#10L]\n            :     :  +- Filter (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L))\n            :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#7L,s_name#8,s_address#9,s_nationkey#10L,s_phone#11,s_acctbal#12,s_comment#13] parquet\n            :     +- Project [n_nationkey#14L]\n            :        +- Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n            :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15,n_regionkey#16L,n_comment#17] parquet\n            +- Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5]\n               +- Filter isnotnull(ps_suppkey#3L)\n                  +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#2L,ps_suppkey#3L,ps_availqty#4,ps_supplycost#5,ps_comment#6] parquet\n"
    },
    "IM" : {
      "inputSizeInBytes" : 13961003275,
      "inputRowCount" : 81000025
    },
    "PD" : { },
    "Configuration" : {
      "theta_c" : [ {
        "spark.executor.memory" : "1g"
      }, {
        "spark.executor.cores" : "1"
      }, {
        "spark.executor.instances" : "16"
      }, {
        "spark.default.parallelism" : "16"
      }, {
        "spark.reducer.maxSizeInFlight" : "48m"
      }, {
        "spark.shuffle.sort.bypassMergeThreshold" : "200"
      }, {
        "spark.shuffle.compress" : "true"
      }, {
        "spark.memory.fraction" : "0.6"
      } ],
      "theta_p" : [ {
        "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
      }, {
        "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
      }, {
        "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
      }, {
        "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
      }, {
        "spark.sql.shuffle.partitions" : "200"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
      }, {
        "spark.sql.files.maxPartitionBytes" : "128MB"
      }, {
        "spark.sql.files.openCostInBytes" : "4MB"
      } ],
      "theta_s" : [ {
        "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
      }, {
        "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
      } ]
    }
  },
  "RuntimeLQPs" : {
    "8" : {
      "LQP" : {
        "operators" : {
          "0" : {
            "sign" : -709534016,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 3820200,
            "rowCount" : 95505,
            "isRuntime" : true,
            "predicate" : " (unknown) Sort Arguments: [value#43 DESC NULLS LAST], true "
          },
          "1" : {
            "sign" : 463495024,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 3820200,
            "rowCount" : 95505,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 [])), ShuffleQueryStage 5 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Sort",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Sort [value#43 DESC NULLS LAST], true\n+- LogicalQueryStage Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 [])), ShuffleQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 3820200,
        "inputRowCount" : 95505
      },
      "PD" : {
        "5" : [ 8556, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 9412, 7778, 8556, 8556, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 8556, 9412, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 7778, 7778, 8556, 7778, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 7778, 7778, 8556, 7778, 7778, 7778, 8556, 7778, 7778, 7778, 8556, 7778, 7778, 7778, 8556, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 8556, 8556, 7778, 7778, 8556, 7778, 8556, 7778, 8556, 8556, 7778, 8556, 8556, 7778, 7778, 7778, 8556, 7778, 7778, 8556, 8556, 7778, 8556, 7778, 8556, 7778, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 7778, 7778, 8556, 7778, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 7778, 7778, 7778, 7778, 8556, 8556, 7778, 8556, 7778, 8556, 8556 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226643659,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 494,
        "IOBytes" : {
          "Total" : 1580556,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1580556,
            "SW" : 0
          }
        }
      }
    },
    "4" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 563723864,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L, s_nationkey#56L] "
          },
          "8" : {
            "sign" : -1701378528,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1601642400,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_availqty#50, ps_supplycost#51] "
          },
          "19" : {
            "sign" : 1552007108,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#49L) "
          },
          "4" : {
            "sign" : -835678110,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 140314240000000,
            "rowCount" : 3188960000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#3L = s_suppkey#7L) "
          },
          "15" : {
            "sign" : 462583583,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [n_nationkey#60L] "
          },
          "11" : {
            "sign" : 479804008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 32000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#56L = n_nationkey#60L) "
          },
          "9" : {
            "sign" : 1069953915,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2882956320,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#49L = s_suppkey#53L) "
          },
          "13" : {
            "sign" : 1816609901,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L)) "
          },
          "16" : {
            "sign" : 1005511772,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 131,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L)) "
          },
          "5" : {
            "sign" : -1713091715,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 3145728,
            "rowCount" : 39862,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2, BroadcastQueryStage 3 "
          },
          "10" : {
            "sign" : -329647969,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L] "
          },
          "6" : {
            "sign" : 280945496,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 3200000000,
            "rowCount" : 80000000,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1 "
          },
          "1" : {
            "sign" : 34619910,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 102046720000000,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 [])) "
          },
          "17" : {
            "sign" : -1747563484,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 3275,
            "rowCount" : 25,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#60L, n_name#61, n_regionkey#62L, n_comment#63], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "14" : {
            "sign" : -422771711,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#53L, s_name#54, s_address#55, s_nationkey#56L, s_phone#57, s_acctbal#58, s_comment#59], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : -168850740,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 102046720000000,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [value#43 DESC NULLS LAST], true "
          },
          "20" : {
            "sign" : 759886188,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#48L, ps_suppkey#49L, ps_availqty#50, ps_supplycost#51, ps_comment#52], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "2" : {
            "sign" : 1040177704,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 102046720000000,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43] "
          },
          "18" : {
            "sign" : 1703060674,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2240000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] "
          },
          "7" : {
            "sign" : 501377547,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 24,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47] "
          },
          "3" : {
            "sign" : 1984961764,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 89290880000000,
            "rowCount" : 3188960000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_partkey#2L, ps_availqty#4, ps_supplycost#5] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalRelation",
          "toId" : 16,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "Filter",
          "toId" : 15,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "LogicalRelation",
          "toId" : 19,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Filter",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Join",
          "toId" : 8,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Project",
          "toId" : 7,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Sort",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Sort [value#43 DESC NULLS LAST], true\n+- Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 []))\n   :  +- Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n   :     +- Project [ps_availqty#50, ps_supplycost#51]\n   :        +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n   :           :- Project [s_suppkey#53L]\n   :           :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n   :           :     :- Project [s_suppkey#53L, s_nationkey#56L]\n   :           :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n   :           :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n   :           :     +- Project [n_nationkey#60L]\n   :           :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n   :           :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n   :           +- Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n   :              +- Filter isnotnull(ps_suppkey#49L)\n   :                 +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n   +- Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43]\n      +- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n         +- Join Inner, (ps_suppkey#3L = s_suppkey#7L)\n            :- LogicalQueryStage LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2, BroadcastQueryStage 3\n            +- LogicalQueryStage Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1\n"
      },
      "IM" : {
        "inputSizeInBytes" : 3203145728,
        "inputRowCount" : 80039862
      },
      "PD" : {
        "0" : [ 9142614, 9157545, 9183996, 9157545, 9157545, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9210447, 9157545, 9183996, 9157545, 9157545, 9765918, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9792369, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9210447, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9395604, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9142614, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9395604, 9157545, 9157545, 9157545, 9157545, 9210447, 9157545, 9157545, 9474957, 9157545, 9157545, 9210447, 9157545, 9157545, 9157545, 9157545, 9422055, 9157545, 9157545, 9157545, 9157545, 9157545, 9554310, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9395604, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9263349, 9157545, 9236898, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9474957, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9210447, 9157545, 9157545, 9183996, 9157545, 9157545, 9157545, 9157545, 9210447, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9422055, 9157545, 9157545, 9157545, 9157545, 9157545, 9422055, 9183996, 9157545, 9183996, 9157545, 9157545, 9157545, 9142614, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9316251, 9157545, 9157545, 9501408, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226625947,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 18206,
        "IOBytes" : {
          "Total" : 5350756274,
          "Details" : {
            "IR" : 866018451,
            "IW" : 0,
            "SR" : 3155309011,
            "SW" : 1329428812
          }
        }
      }
    },
    "5" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 1005511772,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 131,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L)) "
          },
          "8" : {
            "sign" : 563723864,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L, s_nationkey#56L] "
          },
          "4" : {
            "sign" : -1701378528,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1601642400,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_availqty#50, ps_supplycost#51] "
          },
          "15" : {
            "sign" : 1552007108,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#49L) "
          },
          "11" : {
            "sign" : 462583583,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [n_nationkey#60L] "
          },
          "9" : {
            "sign" : 1816609901,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L)) "
          },
          "13" : {
            "sign" : -1747563484,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 3275,
            "rowCount" : 25,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#60L, n_name#61, n_regionkey#62L, n_comment#63], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "16" : {
            "sign" : 759886188,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#48L, ps_suppkey#49L, ps_availqty#50, ps_supplycost#51, ps_comment#52], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "5" : {
            "sign" : 1069953915,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2882956320,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#49L = s_suppkey#53L) "
          },
          "10" : {
            "sign" : -422771711,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#53L, s_name#54, s_address#55, s_nationkey#56L, s_phone#57, s_acctbal#58, s_comment#59], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "6" : {
            "sign" : -329647969,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L] "
          },
          "1" : {
            "sign" : -1736684445,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 96598880,
            "rowCount" : 3018715,
            "isRuntime" : true,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 [])) "
          },
          "14" : {
            "sign" : 1703060674,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2240000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] "
          },
          "0" : {
            "sign" : 532462833,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 96598880,
            "rowCount" : 3018715,
            "isRuntime" : true,
            "predicate" : " (unknown) Sort Arguments: [value#43 DESC NULLS LAST], true "
          },
          "2" : {
            "sign" : 1651787157,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 144898320,
            "rowCount" : 3018715,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43], HashAggregate(keys=[ps_partkey#2L], functions=[sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))]) "
          },
          "7" : {
            "sign" : 479804008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 32000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#56L = n_nationkey#60L) "
          },
          "3" : {
            "sign" : 501377547,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 24,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47] "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalRelation",
          "toId" : 9,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Filter",
          "toId" : 8,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Project",
          "toId" : 7,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "LogicalRelation",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Filter",
          "toId" : 11,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Project",
          "toId" : 7,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Join",
          "toId" : 6,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Project",
          "toId" : 5,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalRelation",
          "toId" : 15,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Filter",
          "toId" : 14,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Project",
          "toId" : 5,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Join",
          "toId" : 4,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Project",
          "toId" : 3,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Sort",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Sort [value#43 DESC NULLS LAST], true\n+- Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 []))\n   :  +- Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n   :     +- Project [ps_availqty#50, ps_supplycost#51]\n   :        +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n   :           :- Project [s_suppkey#53L]\n   :           :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n   :           :     :- Project [s_suppkey#53L, s_nationkey#56L]\n   :           :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n   :           :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n   :           :     +- Project [n_nationkey#60L]\n   :           :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n   :           :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n   :           +- Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n   :              +- Filter isnotnull(ps_suppkey#49L)\n   :                 +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n   +- LogicalQueryStage Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43], HashAggregate(keys=[ps_partkey#2L], functions=[sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 144898320,
        "inputRowCount" : 3018715
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226628585,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 15568,
        "IOBytes" : {
          "Total" : 3525096788,
          "Details" : {
            "IR" : 866018451,
            "IW" : 0,
            "SR" : 1384333122,
            "SW" : 1274745215
          }
        }
      }
    },
    "6" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : 462583583,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [n_nationkey#60L] "
          },
          "4" : {
            "sign" : 479804008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 32000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#56L = n_nationkey#60L) "
          },
          "11" : {
            "sign" : 320262998,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2560000000,
            "rowCount" : 80000000,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51], ShuffleQueryStage 4 "
          },
          "9" : {
            "sign" : 1005511772,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 131,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L)) "
          },
          "5" : {
            "sign" : 563723864,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L, s_nationkey#56L] "
          },
          "10" : {
            "sign" : -1747563484,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 3275,
            "rowCount" : 25,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#60L, n_name#61, n_regionkey#62L, n_comment#63], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "6" : {
            "sign" : 1816609901,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L)) "
          },
          "1" : {
            "sign" : -1685474504,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1600000000000000,
            "rowCount" : 80000000000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_availqty#50, ps_supplycost#51] "
          },
          "0" : {
            "sign" : 1323836509,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 24,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47] "
          },
          "2" : {
            "sign" : -2102638483,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2880000000000000,
            "rowCount" : 80000000000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#49L = s_suppkey#53L) "
          },
          "7" : {
            "sign" : -422771711,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#53L, s_name#54, s_address#55, s_nationkey#56L, s_phone#57, s_acctbal#58, s_comment#59], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "3" : {
            "sign" : -329647969,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L] "
          }
        },
        "links" : [ {
          "fromId" : 7,
          "fromName" : "LogicalRelation",
          "toId" : 6,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Filter",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalRelation",
          "toId" : 9,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Filter",
          "toId" : 8,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n+- Project [ps_availqty#50, ps_supplycost#51]\n   +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n      :- Project [s_suppkey#53L]\n      :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n      :     :- Project [s_suppkey#53L, s_nationkey#56L]\n      :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n      :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n      :     +- Project [n_nationkey#60L]\n      :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n      :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n      +- LogicalQueryStage Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51], ShuffleQueryStage 4\n"
      },
      "IM" : {
        "inputSizeInBytes" : 2761003275,
        "inputRowCount" : 81000025
      },
      "PD" : {
        "3" : [ 6290853, 6688327, 6868997, 6868997, 6880215, 6868997, 6880215, 6880215, 6796729, 6850930, 6850930, 6868997, 6850930, 6399255, 6880215, 6832863, 6880215, 6778662, 6868997, 6880215, 6850930, 6862148, 6880215, 6760595, 6868997, 6880215, 6868997, 6868997, 6525724, 6832863, 6453456, 6880215, 6850930, 6868997, 6616059, 6868997, 6850930, 6561858, 6880215, 6724461, 6850930, 6880215, 6760595, 6760595, 6724461, 6489590, 6880215, 6634126, 6850930, 6880215, 6868997, 6868997, 6880215, 6862148, 6862148, 6880215, 6868997, 6880215, 6670260, 6489590, 6832863, 6814796, 6561858, 6880215, 6880215, 6880215, 6880215, 6507657, 6417322, 6742528, 6742528, 6844081, 6796729, 6868997, 6862148, 6706394, 6832863, 6868997, 6850930, 6706394, 6868997, 6254719, 6807947, 6814796, 6760595, 6880215, 6880215, 6868997, 6778662, 6742528, 6814796, 6627277, 6832863, 6880215, 6850930, 6814796, 6832863, 6868997, 6880215, 6868997, 6868997, 6880215, 6880215, 6832863, 6880215, 6796729, 6814796, 6616059, 6880215, 6880215, 6634126, 6760595, 6543791, 6880215, 6862148, 6880215, 6634126, 6850930, 6868997, 6706394, 6760595, 6742528, 6880215, 6850930, 6880215, 6742528, 6862148, 6880215, 6850930, 6771813, 6826014, 6880215, 6771813, 6868997, 6616059, 6832863, 6880215, 6742528, 6832863, 6868997, 6880215, 6868997, 6868997, 6832863, 6868997, 6814796, 6760595, 6880215, 6826014, 6778662, 6880215, 6814796, 6634126, 6272786, 6814796, 6880215, 6880215, 6742528, 6880215, 6832863, 6880215, 6507657, 6862148, 6862148, 6868997, 6868997, 6543791, 6880215, 6814796, 6453456, 6880215, 6724461, 6771813, 6868997, 6789880, 6868997, 6880215, 6880215, 6579925, 6880215, 6760595, 6850930, 6363121, 6706394, 6616059, 6850930, 6850930, 6850930, 6868997, 6778662, 6880215, 6760595, 6850930, 6880215, 6862148, 6363121, 6868997, 6868997, 6880215, 6868997 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226632007,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 12146,
        "IOBytes" : {
          "Total" : 1385915495,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1384333122,
            "SW" : 1582373
          }
        }
      }
    },
    "1" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 501377547,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 24,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47] "
          },
          "8" : {
            "sign" : -1844519439,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L)) "
          },
          "19" : {
            "sign" : -422771711,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#53L, s_name#54, s_address#55, s_nationkey#56L, s_phone#57, s_acctbal#58, s_comment#59], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "23" : {
            "sign" : 1703060674,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2240000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] "
          },
          "4" : {
            "sign" : -1252467326,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 3523613280,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#3L = s_suppkey#7L) "
          },
          "15" : {
            "sign" : -329647969,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L] "
          },
          "11" : {
            "sign" : 280945496,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2880000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1 "
          },
          "9" : {
            "sign" : -582420732,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#7L, s_name#8, s_address#9, s_nationkey#10L, s_phone#11, s_acctbal#12, s_comment#13], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "22" : {
            "sign" : -1747563484,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 3275,
            "rowCount" : 25,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#60L, n_name#61, n_regionkey#62L, n_comment#63], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "13" : {
            "sign" : -1701378528,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1601642400,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_availqty#50, ps_supplycost#51] "
          },
          "24" : {
            "sign" : 1552007108,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#49L) "
          },
          "16" : {
            "sign" : 479804008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 32000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#56L = n_nationkey#60L) "
          },
          "5" : {
            "sign" : 1512776827,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#7L] "
          },
          "10" : {
            "sign" : -453051334,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1048584,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [n_nationkey#14L], BroadcastQueryStage 0 "
          },
          "21" : {
            "sign" : 1005511772,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 131,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L)) "
          },
          "6" : {
            "sign" : -2056752085,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 32000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#10L = n_nationkey#14L) "
          },
          "1" : {
            "sign" : 2046512426,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 [])) "
          },
          "17" : {
            "sign" : 563723864,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L, s_nationkey#56L] "
          },
          "25" : {
            "sign" : 759886188,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#48L, ps_suppkey#49L, ps_availqty#50, ps_supplycost#51, ps_comment#52], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "14" : {
            "sign" : 1069953915,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2882956320,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#49L = s_suppkey#53L) "
          },
          "0" : {
            "sign" : 917621720,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [value#43 DESC NULLS LAST], true "
          },
          "20" : {
            "sign" : 462583583,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [n_nationkey#60L] "
          },
          "2" : {
            "sign" : -1403141124,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43] "
          },
          "18" : {
            "sign" : 1816609901,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L)) "
          },
          "7" : {
            "sign" : 1001821905,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#7L, s_nationkey#10L] "
          },
          "3" : {
            "sign" : 194731016,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2242299360,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_partkey#2L, ps_availqty#4, ps_supplycost#5] "
          }
        },
        "links" : [ {
          "fromId" : 9,
          "fromName" : "LogicalRelation",
          "toId" : 8,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Filter",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "LogicalRelation",
          "toId" : 18,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Filter",
          "toId" : 17,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "Project",
          "toId" : 16,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "LogicalRelation",
          "toId" : 21,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "Filter",
          "toId" : 20,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Project",
          "toId" : 16,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "Join",
          "toId" : 15,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Project",
          "toId" : 14,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "LogicalRelation",
          "toId" : 24,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Filter",
          "toId" : 23,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Project",
          "toId" : 14,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Join",
          "toId" : 13,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Project",
          "toId" : 12,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Sort",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Sort [value#43 DESC NULLS LAST], true\n+- Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 []))\n   :  +- Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n   :     +- Project [ps_availqty#50, ps_supplycost#51]\n   :        +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n   :           :- Project [s_suppkey#53L]\n   :           :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n   :           :     :- Project [s_suppkey#53L, s_nationkey#56L]\n   :           :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n   :           :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n   :           :     +- Project [n_nationkey#60L]\n   :           :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n   :           :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n   :           +- Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n   :              +- Filter isnotnull(ps_suppkey#49L)\n   :                 +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n   +- Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43]\n      +- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n         +- Join Inner, (ps_suppkey#3L = s_suppkey#7L)\n            :- Project [s_suppkey#7L]\n            :  +- Join Inner, (s_nationkey#10L = n_nationkey#14L)\n            :     :- Project [s_suppkey#7L, s_nationkey#10L]\n            :     :  +- Filter (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L))\n            :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#7L,s_name#8,s_address#9,s_nationkey#10L,s_phone#11,s_acctbal#12,s_comment#13] parquet\n            :     +- LogicalQueryStage Project [n_nationkey#14L], BroadcastQueryStage 0\n            +- LogicalQueryStage Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1\n"
      },
      "IM" : {
        "inputSizeInBytes" : 3082048584,
        "inputRowCount" : 81000001
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 11,
        "FinishedTasksNum" : 24,
        "FinishedTasksTotalTimeInMs" : 87110.0,
        "FinishedTasksDistributionInMs" : [ 1243.0, 1491.0, 4754.0, 5666.0, 6977.0 ]
      },
      "StartTimeInMs" : 1702226624397,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 19756,
        "IOBytes" : {
          "Total" : 8358749021,
          "Details" : {
            "IR" : 2102593883,
            "IW" : 0,
            "SR" : 3155529724,
            "SW" : 3100625414
          }
        }
      }
    },
    "2" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 563723864,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L, s_nationkey#56L] "
          },
          "8" : {
            "sign" : -1701378528,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1601642400,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_availqty#50, ps_supplycost#51] "
          },
          "19" : {
            "sign" : 1552007108,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#49L) "
          },
          "4" : {
            "sign" : -1372186067,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 140314240000000,
            "rowCount" : 3188960000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#3L = s_suppkey#7L) "
          },
          "15" : {
            "sign" : 462583583,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [n_nationkey#60L] "
          },
          "11" : {
            "sign" : 479804008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 32000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#56L = n_nationkey#60L) "
          },
          "9" : {
            "sign" : 1069953915,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2882956320,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#49L = s_suppkey#53L) "
          },
          "13" : {
            "sign" : 1816609901,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L)) "
          },
          "16" : {
            "sign" : 1005511772,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 131,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L)) "
          },
          "5" : {
            "sign" : -1325547232,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 637792,
            "rowCount" : 39862,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_suppkey#7L], ShuffleQueryStage 2 "
          },
          "10" : {
            "sign" : -329647969,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L] "
          },
          "6" : {
            "sign" : 280945496,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2880000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1 "
          },
          "1" : {
            "sign" : 1664932451,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 [])) "
          },
          "17" : {
            "sign" : -1747563484,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 3275,
            "rowCount" : 25,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#60L, n_name#61, n_regionkey#62L, n_comment#63], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "14" : {
            "sign" : -422771711,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#53L, s_name#54, s_address#55, s_nationkey#56L, s_phone#57, s_acctbal#58, s_comment#59], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : 268635139,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [value#43 DESC NULLS LAST], true "
          },
          "20" : {
            "sign" : 759886188,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#48L, ps_suppkey#49L, ps_availqty#50, ps_supplycost#51, ps_comment#52], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "2" : {
            "sign" : 656233319,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43] "
          },
          "18" : {
            "sign" : 1703060674,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2240000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] "
          },
          "7" : {
            "sign" : 501377547,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 24,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47] "
          },
          "3" : {
            "sign" : -1240506491,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 89290880000000,
            "rowCount" : 3188960000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_partkey#2L, ps_availqty#4, ps_supplycost#5] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalRelation",
          "toId" : 16,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "Filter",
          "toId" : 15,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "LogicalRelation",
          "toId" : 19,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Filter",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Join",
          "toId" : 8,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Project",
          "toId" : 7,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Sort",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Sort [value#43 DESC NULLS LAST], true\n+- Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 []))\n   :  +- Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n   :     +- Project [ps_availqty#50, ps_supplycost#51]\n   :        +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n   :           :- Project [s_suppkey#53L]\n   :           :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n   :           :     :- Project [s_suppkey#53L, s_nationkey#56L]\n   :           :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n   :           :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n   :           :     +- Project [n_nationkey#60L]\n   :           :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n   :           :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n   :           +- Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n   :              +- Filter isnotnull(ps_suppkey#49L)\n   :                 +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n   +- Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43]\n      +- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n         +- Join Inner, (ps_suppkey#3L = s_suppkey#7L)\n            :- LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2\n            +- LogicalQueryStage Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1\n"
      },
      "IM" : {
        "inputSizeInBytes" : 2880637792,
        "inputRowCount" : 80039862
      },
      "PD" : {
        "1" : [ 1156, 1051, 1156, 1156, 1271, 1156, 1271, 1156, 1051, 1399, 1051, 1156, 1051, 1156, 1156, 1271, 1271, 1051, 1156, 1156, 1051, 1156, 1156, 1271, 1156, 1271, 1271, 1156, 1156, 1271, 1156, 1271, 1051, 1156, 1156, 1156, 1051, 1156, 1271, 955, 955, 1051, 1051, 1051, 1156, 1051, 1156, 1156, 1156, 1156, 1156, 1156, 1271, 1156, 1271, 1156, 1271, 1051, 1051, 1156, 1156, 1156, 1051, 1271, 1156, 1156, 1156, 1156, 1399, 1156, 1051, 1051, 1051, 1156, 1156, 1271, 1051, 1156, 1156, 1271, 1156, 1156, 1156, 1051, 1156, 955, 1051, 1156, 1156, 1051, 1271, 1051, 1051, 1051, 1051, 1156, 1156, 955, 1156, 1051, 1156, 1271, 1271, 1399, 1399, 1156, 1156, 1399, 1156, 1156, 1051, 1051, 1271, 1156, 1156, 1156, 1156, 1271, 1271, 1156, 1051, 1156, 1051, 1156, 1271, 1271, 1051, 1271, 1051, 1156, 1156, 955, 1271, 1156, 1156, 1156, 1156, 1051, 1156, 1399, 1156, 1271, 1051, 1399, 1271, 1271, 1051, 1156, 1156, 1156, 1271, 1051, 1156, 1271, 1156, 1271, 1156, 1271, 1156, 1156, 1271, 1156, 1156, 1051, 1156, 1156, 1051, 1271, 1156, 1156, 1156, 1271, 1051, 955, 1156, 1156, 1156, 1156, 1051, 1156, 1051, 955, 1051, 1051, 1271, 1156, 1156, 1051, 1156, 1051, 1156, 1156, 1051, 1271, 1156, 1051, 1156, 1156, 1271, 1156 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 7,
        "FinishedTasksNum" : 28,
        "FinishedTasksTotalTimeInMs" : 98969.0,
        "FinishedTasksDistributionInMs" : [ 909.0, 1479.0, 1756.0, 5666.0, 8118.0 ]
      },
      "StartTimeInMs" : 1702226624915,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 19238,
        "IOBytes" : {
          "Total" : 8352828183,
          "Details" : {
            "IR" : 2096893758,
            "IW" : 0,
            "SR" : 3155529724,
            "SW" : 3100404701
          }
        }
      }
    },
    "7" : {
      "LQP" : {
        "operators" : {
          "0" : {
            "sign" : -254787027,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 920,
            "rowCount" : 23,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47], HashAggregate(keys=[], functions=[sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47], HashAggregate(keys=[], functions=[sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 920,
        "inputRowCount" : 23
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226635874,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 8279,
        "IOBytes" : {
          "Total" : 112530123,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 110949567,
            "SW" : 1580556
          }
        }
      }
    },
    "3" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 563723864,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L, s_nationkey#56L] "
          },
          "8" : {
            "sign" : -1701378528,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1601642400,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_availqty#50, ps_supplycost#51] "
          },
          "19" : {
            "sign" : 1552007108,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#49L) "
          },
          "4" : {
            "sign" : -835678110,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 140314240000000,
            "rowCount" : 3188960000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#3L = s_suppkey#7L) "
          },
          "15" : {
            "sign" : 462583583,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [n_nationkey#60L] "
          },
          "11" : {
            "sign" : 479804008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 32000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#56L = n_nationkey#60L) "
          },
          "9" : {
            "sign" : 1069953915,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2882956320,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#49L = s_suppkey#53L) "
          },
          "13" : {
            "sign" : 1816609901,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L)) "
          },
          "16" : {
            "sign" : 1005511772,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 131,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L)) "
          },
          "5" : {
            "sign" : -1713091715,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 3145728,
            "rowCount" : 39862,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2, BroadcastQueryStage 3 "
          },
          "10" : {
            "sign" : -329647969,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#53L] "
          },
          "6" : {
            "sign" : 280945496,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2880000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1 "
          },
          "1" : {
            "sign" : 34619910,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 [])) "
          },
          "17" : {
            "sign" : -1747563484,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 3275,
            "rowCount" : 25,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#60L, n_name#61, n_regionkey#62L, n_comment#63], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "14" : {
            "sign" : -422771711,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 201000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#53L, s_name#54, s_address#55, s_nationkey#56L, s_phone#57, s_acctbal#58, s_comment#59], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : -168850740,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [value#43 DESC NULLS LAST], true "
          },
          "20" : {
            "sign" : 759886188,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 13760000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#48L, ps_suppkey#49L, ps_availqty#50, ps_supplycost#51, ps_comment#52], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "2" : {
            "sign" : 1040177704,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43] "
          },
          "18" : {
            "sign" : 1703060674,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2240000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] "
          },
          "7" : {
            "sign" : 501377547,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 24,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47] "
          },
          "3" : {
            "sign" : 1984961764,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 89290880000000,
            "rowCount" : 3188960000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_partkey#2L, ps_availqty#4, ps_supplycost#5] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalRelation",
          "toId" : 16,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "Filter",
          "toId" : 15,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "LogicalRelation",
          "toId" : 19,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Filter",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Join",
          "toId" : 8,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Project",
          "toId" : 7,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Aggregate",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Sort",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Sort [value#43 DESC NULLS LAST], true\n+- Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 []))\n   :  +- Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n   :     +- Project [ps_availqty#50, ps_supplycost#51]\n   :        +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n   :           :- Project [s_suppkey#53L]\n   :           :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n   :           :     :- Project [s_suppkey#53L, s_nationkey#56L]\n   :           :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n   :           :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n   :           :     +- Project [n_nationkey#60L]\n   :           :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n   :           :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n   :           +- Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n   :              +- Filter isnotnull(ps_suppkey#49L)\n   :                 +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n   +- Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43]\n      +- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n         +- Join Inner, (ps_suppkey#3L = s_suppkey#7L)\n            :- LogicalQueryStage LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2, BroadcastQueryStage 3\n            +- LogicalQueryStage Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1\n"
      },
      "IM" : {
        "inputSizeInBytes" : 2883145728,
        "inputRowCount" : 80039862
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 3,
        "FinishedTasksNum" : 32,
        "FinishedTasksTotalTimeInMs" : 105006.0,
        "FinishedTasksDistributionInMs" : [ 909.0, 1479.0, 1566.0, 5558.0, 8118.0 ]
      },
      "StartTimeInMs" : 1702226625301,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 18852,
        "IOBytes" : {
          "Total" : 8352607470,
          "Details" : {
            "IR" : 2096893758,
            "IW" : 0,
            "SR" : 3155309011,
            "SW" : 3100404701
          }
        }
      }
    }
  },
  "RuntimeQSs" : {
    "8" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1664932451,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 595682624,
                "rowCount" : 18615082
              },
              "compileTime" : {
                "sizeInBytes" : 595682624,
                "rowCount" : 18615082
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 [])) "
          }
        },
        "links" : [ ],
        "rawPlan" : "Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 []))\n:  +- Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n:     +- Project [ps_availqty#50, ps_supplycost#51]\n:        +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n:           :- Project [s_suppkey#53L]\n:           :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n:           :     :- Project [s_suppkey#53L, s_nationkey#56L]\n:           :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n:           :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n:           :     +- Project [n_nationkey#60L]\n:           :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n:           :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n:           +- Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n:              +- Filter isnotnull(ps_suppkey#49L)\n:                 +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n+- Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43]\n   +- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n      +- Join Inner, (ps_suppkey#3L = s_suppkey#7L)\n         :- LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2\n         +- LogicalQueryStage Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1917727496,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [ps_partkey#2L, value#43] Condition : (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > Subquery subquery#44, [id=#110])) "
          },
          "1" : {
            "sign" : 692998031,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 144898320,
            "rowCount" : 3018715,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [3]: [ps_partkey#2L, sum#69, isEmpty#70] Keys [1]: [ps_partkey#2L] Functions [1]: [sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))] Aggregate Attributes [1]: [sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))#45] Results [2]: [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))#45 AS value#43] "
          },
          "2" : {
            "sign" : 581547079,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [3]: [ps_partkey#2L, sum#69, isEmpty#70] Arguments: 4 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "ShuffleQueryStage",
          "toId" : 1,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "Filter",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > Subquery subquery#44, [id=#110]))\n:  +- Subquery subquery#44, [id=#110]\n:     +- AdaptiveSparkPlan isFinalPlan=false\n:        +- HashAggregate(keys=[], functions=[sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[(sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47])\n:           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=108]\n:              +- HashAggregate(keys=[], functions=[partial_sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[sum#73, isEmpty#74])\n:                 +- Project [ps_availqty#50, ps_supplycost#51]\n:                    +- SortMergeJoin [s_suppkey#53L], [ps_suppkey#49L], Inner\n:                       :- Sort [s_suppkey#53L ASC NULLS FIRST], false, 0\n:                       :  +- Exchange hashpartitioning(s_suppkey#53L, 200), ENSURE_REQUIREMENTS, [plan_id=100]\n:                       :     +- Project [s_suppkey#53L]\n:                       :        +- BroadcastHashJoin [s_nationkey#56L], [n_nationkey#60L], Inner, BuildRight, false\n:                       :           :- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n:                       :           :  +- FileScan parquet spark_catalog.tpch_100.supplier[s_suppkey#53L,s_nationkey#56L] Batched: true, DataFilters: [isnotnull(s_suppkey#53L), isnotnull(s_nationkey#56L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/supplier], PartitionFilters: [], PushedFilters: [IsNotNull(s_suppkey), IsNotNull(s_nationkey)], ReadSchema: struct<s_suppkey:bigint,s_nationkey:bigint>\n:                       :           +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=95]\n:                       :              +- Project [n_nationkey#60L]\n:                       :                 +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n:                       :                    +- FileScan parquet spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61] Batched: true, DataFilters: [isnotnull(n_name#61), (n_name#61 = JAPAN), isnotnull(n_nationkey#60L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:bigint,n_name:string>\n:                       +- Sort [ps_suppkey#49L ASC NULLS FIRST], false, 0\n:                          +- Exchange hashpartitioning(ps_suppkey#49L, 200), ENSURE_REQUIREMENTS, [plan_id=101]\n:                             +- Filter isnotnull(ps_suppkey#49L)\n:                                +- FileScan parquet spark_catalog.tpch_100.partsupp[ps_suppkey#49L,ps_availqty#50,ps_supplycost#51] Batched: true, DataFilters: [isnotnull(ps_suppkey#49L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n+- HashAggregate(keys=[ps_partkey#2L], functions=[sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))], output=[ps_partkey#2L, value#43])\n   +- ShuffleQueryStage 4\n      +- Exchange hashpartitioning(ps_partkey#2L, 200), ENSURE_REQUIREMENTS, [plan_id=516]\n         +- *(4) HashAggregate(keys=[ps_partkey#2L], functions=[partial_sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))], output=[ps_partkey#2L, sum#69, isEmpty#70])\n            +- *(4) Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n               +- *(4) BroadcastHashJoin [s_suppkey#7L], [ps_suppkey#3L], Inner, BuildLeft, false\n                  :- BroadcastQueryStage 3\n                  :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=419]\n                  :     +- AQEShuffleRead local\n                  :        +- ShuffleQueryStage 2\n                  :           +- Exchange hashpartitioning(s_suppkey#7L, 200), ENSURE_REQUIREMENTS, [plan_id=346]\n                  :              +- *(3) Project [s_suppkey#7L]\n                  :                 +- *(3) BroadcastHashJoin [s_nationkey#10L], [n_nationkey#14L], Inner, BuildRight, false\n                  :                    :- *(3) Filter (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L))\n                  :                    :  +- *(3) ColumnarToRow\n                  :                    :     +- FileScan parquet spark_catalog.tpch_100.supplier[s_suppkey#7L,s_nationkey#10L] Batched: true, DataFilters: [isnotnull(s_suppkey#7L), isnotnull(s_nationkey#10L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/supplier], PartitionFilters: [], PushedFilters: [IsNotNull(s_suppkey), IsNotNull(s_nationkey)], ReadSchema: struct<s_suppkey:bigint,s_nationkey:bigint>\n                  :                    +- BroadcastQueryStage 0\n                  :                       +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=216]\n                  :                          +- *(1) Project [n_nationkey#14L]\n                  :                             +- *(1) Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n                  :                                +- *(1) ColumnarToRow\n                  :                                   +- FileScan parquet spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15] Batched: true, DataFilters: [isnotnull(n_name#15), (n_name#15 = JAPAN), isnotnull(n_nationkey#14L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:bigint,n_name:string>\n                  +- AQEShuffleRead local\n                     +- ShuffleQueryStage 1\n                        +- Exchange hashpartitioning(ps_suppkey#3L, 200), ENSURE_REQUIREMENTS, [plan_id=237]\n                           +- *(2) Filter isnotnull(ps_suppkey#3L)\n                              +- *(2) ColumnarToRow\n                                 +- FileScan parquet spark_catalog.tpch_100.partsupp[ps_partkey#2L,ps_suppkey#3L,ps_availqty#4,ps_supplycost#5] Batched: true, DataFilters: [isnotnull(ps_suppkey#3L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_partkey:bigint,ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 144898320,
        "inputRowCount" : 3018715
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "2" : [ 285404, 287189, 286882, 287443, 284371, 285475, 288478, 289530, 286736, 286854, 289777, 290150, 287587, 285849, 289039, 284933, 288412, 285169, 284628, 289648, 289039, 287000, 293397, 293182, 285849, 290221, 292489, 288221, 281516, 291333, 292222, 283515, 290477, 282777, 288705, 291982, 284333, 289895, 288832, 284666, 285031, 286922, 290928, 282848, 287738, 285326, 289777, 289855, 290039, 285338, 284442, 286380, 288221, 286587, 285967, 281594, 289850, 289699, 288143, 285182, 287927, 286553, 286371, 285484, 283744, 288365, 287443, 286627, 290477, 285960, 284333, 291975, 286707, 285998, 287038, 285155, 284411, 290308, 292267, 285927, 285307, 287771, 288221, 285444, 286045, 282294, 286960, 287856, 289699, 282737, 285522, 286071, 289110, 285298, 286665, 284371, 286783, 284746, 284371, 282808, 286627, 290555, 289216, 287594, 289110, 290633, 285602, 289327, 286979, 285562, 287071, 283072, 287896, 287731, 287405, 287816, 287521, 286627, 290112, 291373, 292517, 286409, 285071, 288363, 285849, 287967, 288598, 287856, 286104, 285338, 282777, 286085, 283595, 285484, 290426, 285602, 290961, 285149, 282254, 289273, 287483, 289810, 287738, 285031, 297000, 285229, 290270, 287158, 284324, 289608, 285477, 284371, 285680, 288438, 291366, 289010, 284588, 286993, 287033, 282294, 287000, 286705, 291411, 283770, 288483, 284666, 290379, 288254, 284333, 286738, 285680, 287298, 288007, 288495, 287405, 286104, 284364, 281476, 288903, 286960, 281261, 282737, 285798, 286783, 283555, 291444, 289699, 294257, 291084, 288254, 288261, 286922, 290706, 292255, 286380, 281221, 285927, 285031, 290051, 286458 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 5,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 17, 20 ],
      "Objectives" : {
        "DurationInMs" : 7442,
        "TotalTasksDurationInMs" : 7042,
        "IOBytes" : {
          "Total" : 110947750,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 109367194,
            "SW" : 1580556
          }
        }
      }
    },
    "4" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 656233319,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 595682624,
                "rowCount" : 18615082
              },
              "compileTime" : {
                "sizeInBytes" : 595682624,
                "rowCount" : 18615082
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43] "
          },
          "1" : {
            "sign" : -1240506491,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 89290880000000,
                "rowCount" : 3188960000000
              },
              "compileTime" : {
                "sizeInBytes" : 89290880000000,
                "rowCount" : 3188960000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_partkey#2L, ps_availqty#4, ps_supplycost#5] "
          },
          "2" : {
            "sign" : -1372186067,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 140314240000000,
                "rowCount" : 3188960000000
              },
              "compileTime" : {
                "sizeInBytes" : 140314240000000,
                "rowCount" : 3188960000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#3L = s_suppkey#7L) "
          },
          "3" : {
            "sign" : 280945496,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 3200000000,
                "rowCount" : 80000000
              },
              "compileTime" : {
                "sizeInBytes" : 2880000000,
                "rowCount" : 80000000
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43]\n+- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n   +- Join Inner, (ps_suppkey#3L = s_suppkey#7L)\n      :- LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2\n      +- LogicalQueryStage Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : 2016227107,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 3200000000,
            "rowCount" : 80000000,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5] Arguments: 1 "
          },
          "1" : {
            "sign" : -727725127,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 89290880000000,
            "rowCount" : 3188960000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [3]: [ps_partkey#2L, ps_availqty#4, ps_supplycost#5] Input [5]: [s_suppkey#7L, ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5] "
          },
          "0" : {
            "sign" : -1698240596,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [3]: [ps_partkey#2L, ps_availqty#4, ps_supplycost#5] Keys [1]: [ps_partkey#2L] Functions [1]: [partial_sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))] Aggregate Attributes [2]: [sum#67, isEmpty#68] Results [3]: [ps_partkey#2L, sum#69, isEmpty#70] "
          },
          "2" : {
            "sign" : 1292219807,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 140314240000000,
            "rowCount" : 3188960000000,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [s_suppkey#7L] Right keys [1]: [ps_suppkey#3L] Join type: Inner Join condition: None "
          },
          "3" : {
            "sign" : 1346904586,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 3145728,
            "rowCount" : 39862,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [1]: [s_suppkey#7L] Arguments: 3 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "BroadcastQueryStage",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "ShuffleQueryStage",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "BroadcastHashJoin",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[ps_partkey#2L], functions=[partial_sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))], output=[ps_partkey#2L, sum#69, isEmpty#70])\n+- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n   +- BroadcastHashJoin [s_suppkey#7L], [ps_suppkey#3L], Inner, BuildLeft, false\n      :- BroadcastQueryStage 3\n      :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=419]\n      :     +- AQEShuffleRead local\n      :        +- ShuffleQueryStage 2\n      :           +- Exchange hashpartitioning(s_suppkey#7L, 200), ENSURE_REQUIREMENTS, [plan_id=346]\n      :              +- *(3) Project [s_suppkey#7L]\n      :                 +- *(3) BroadcastHashJoin [s_nationkey#10L], [n_nationkey#14L], Inner, BuildRight, false\n      :                    :- *(3) Filter (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L))\n      :                    :  +- *(3) ColumnarToRow\n      :                    :     +- FileScan parquet spark_catalog.tpch_100.supplier[s_suppkey#7L,s_nationkey#10L] Batched: true, DataFilters: [isnotnull(s_suppkey#7L), isnotnull(s_nationkey#10L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/supplier], PartitionFilters: [], PushedFilters: [IsNotNull(s_suppkey), IsNotNull(s_nationkey)], ReadSchema: struct<s_suppkey:bigint,s_nationkey:bigint>\n      :                    +- BroadcastQueryStage 0\n      :                       +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=216]\n      :                          +- *(1) Project [n_nationkey#14L]\n      :                             +- *(1) Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n      :                                +- *(1) ColumnarToRow\n      :                                   +- FileScan parquet spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15] Batched: true, DataFilters: [isnotnull(n_name#15), (n_name#15 = JAPAN), isnotnull(n_nationkey#14L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:bigint,n_name:string>\n      +- ShuffleQueryStage 1\n         +- Exchange hashpartitioning(ps_suppkey#3L, 200), ENSURE_REQUIREMENTS, [plan_id=237]\n            +- *(2) Filter isnotnull(ps_suppkey#3L)\n               +- *(2) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpch_100.partsupp[ps_partkey#2L,ps_suppkey#3L,ps_availqty#4,ps_supplycost#5] Batched: true, DataFilters: [isnotnull(ps_suppkey#3L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_partkey:bigint,ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 3203145728,
        "inputRowCount" : 80039862
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "0" : [ 9142614, 9157545, 9183996, 9157545, 9157545, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9210447, 9157545, 9183996, 9157545, 9157545, 9765918, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9792369, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9210447, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9395604, 9183996, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9142614, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9395604, 9157545, 9157545, 9157545, 9157545, 9210447, 9157545, 9157545, 9474957, 9157545, 9157545, 9210447, 9157545, 9157545, 9157545, 9157545, 9422055, 9157545, 9157545, 9157545, 9157545, 9157545, 9554310, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9395604, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9263349, 9157545, 9236898, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9474957, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9210447, 9157545, 9157545, 9183996, 9157545, 9157545, 9157545, 9157545, 9210447, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9422055, 9157545, 9157545, 9157545, 9157545, 9157545, 9422055, 9183996, 9157545, 9183996, 9157545, 9157545, 9157545, 9142614, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545, 9316251, 9157545, 9157545, 9501408, 9157545, 9157545, 9157545, 9157545, 9157545, 9157545 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 4,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 6 ],
      "Objectives" : {
        "DurationInMs" : 2467,
        "TotalTasksDurationInMs" : 35333,
        "IOBytes" : {
          "Total" : 1825659486,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1770975889,
            "SW" : 54683597
          }
        }
      }
    },
    "9" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 268635139,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 595682624,
                "rowCount" : 18615082
              },
              "compileTime" : {
                "sizeInBytes" : 595682624,
                "rowCount" : 18615082
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [value#43 DESC NULLS LAST], true "
          }
        },
        "links" : [ ],
        "rawPlan" : "Sort [value#43 DESC NULLS LAST], true\n+- Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > scalar-subquery#44 []))\n   :  +- Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n   :     +- Project [ps_availqty#50, ps_supplycost#51]\n   :        +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n   :           :- Project [s_suppkey#53L]\n   :           :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n   :           :     :- Project [s_suppkey#53L, s_nationkey#56L]\n   :           :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n   :           :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n   :           :     +- Project [n_nationkey#60L]\n   :           :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n   :           :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n   :           +- Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n   :              +- Filter isnotnull(ps_suppkey#49L)\n   :                 +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n   +- Aggregate [ps_partkey#2L], [ps_partkey#2L, sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0)))) AS value#43]\n      +- Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n         +- Join Inner, (ps_suppkey#3L = s_suppkey#7L)\n            :- LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2\n            +- LogicalQueryStage Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5], ShuffleQueryStage 1\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 764892125,
            "className" : "org.apache.spark.sql.execution.SortExec",
            "sizeInBytes" : 595682624,
            "rowCount" : 18615082,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Input [2]: [ps_partkey#2L, value#43] Arguments: [value#43 DESC NULLS LAST], true, 0 "
          },
          "1" : {
            "sign" : -361295641,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 3820200,
            "rowCount" : 95505,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [2]: [ps_partkey#2L, value#43] Arguments: 5 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "ShuffleQueryStage",
          "toId" : 0,
          "toName" : "Sort",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Sort [value#43 DESC NULLS LAST], true, 0\n+- ShuffleQueryStage 5\n   +- Exchange rangepartitioning(value#43 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=559]\n      +- *(5) Filter (isnotnull(value#43) AND (cast(value#43 as decimal(38,6)) > Subquery subquery#44, [id=#110]))\n         :  +- Subquery subquery#44, [id=#110]\n         :     +- AdaptiveSparkPlan isFinalPlan=true\n                  +- == Final Plan ==\n                     *(7) HashAggregate(keys=[], functions=[sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[(sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47])\n                     +- ShuffleQueryStage 5\n                        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=751]\n                           +- *(6) HashAggregate(keys=[], functions=[partial_sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[sum#73, isEmpty#74])\n                              +- *(6) Project [ps_availqty#50, ps_supplycost#51]\n                                 +- *(6) SortMergeJoin [s_suppkey#53L], [ps_suppkey#49L], Inner\n                                    :- *(4) Sort [s_suppkey#53L ASC NULLS FIRST], false, 0\n                                    :  +- AQEShuffleRead coalesced\n                                    :     +- ShuffleQueryStage 3\n                                    :        +- ReusedExchange [s_suppkey#53L], Exchange hashpartitioning(s_suppkey#7L, 200), ENSURE_REQUIREMENTS, [plan_id=346]\n                                    +- *(5) Sort [ps_suppkey#49L ASC NULLS FIRST], false, 0\n                                       +- AQEShuffleRead coalesced\n                                          +- ShuffleQueryStage 4\n                                             +- Exchange hashpartitioning(ps_suppkey#49L, 200), ENSURE_REQUIREMENTS, [plan_id=657]\n                                                +- *(3) Filter isnotnull(ps_suppkey#49L)\n                                                   +- *(3) ColumnarToRow\n                                                      +- FileScan parquet spark_catalog.tpch_100.partsupp[ps_suppkey#49L,ps_availqty#50,ps_supplycost#51] Batched: true, DataFilters: [isnotnull(ps_suppkey#49L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n                  +- == Initial Plan ==\n                     HashAggregate(keys=[], functions=[sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[(sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47])\n                     +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=108]\n                        +- HashAggregate(keys=[], functions=[partial_sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[sum#73, isEmpty#74])\n                           +- Project [ps_availqty#50, ps_supplycost#51]\n                              +- SortMergeJoin [s_suppkey#53L], [ps_suppkey#49L], Inner\n                                 :- Sort [s_suppkey#53L ASC NULLS FIRST], false, 0\n                                 :  +- Exchange hashpartitioning(s_suppkey#53L, 200), ENSURE_REQUIREMENTS, [plan_id=100]\n                                 :     +- Project [s_suppkey#53L]\n                                 :        +- BroadcastHashJoin [s_nationkey#56L], [n_nationkey#60L], Inner, BuildRight, false\n                                 :           :- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n                                 :           :  +- FileScan parquet spark_catalog.tpch_100.supplier[s_suppkey#53L,s_nationkey#56L] Batched: true, DataFilters: [isnotnull(s_suppkey#53L), isnotnull(s_nationkey#56L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/supplier], PartitionFilters: [], PushedFilters: [IsNotNull(s_suppkey), IsNotNull(s_nationkey)], ReadSchema: struct<s_suppkey:bigint,s_nationkey:bigint>\n                                 :           +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=95]\n                                 :              +- Project [n_nationkey#60L]\n                                 :                 +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n                                 :                    +- FileScan parquet spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61] Batched: true, DataFilters: [isnotnull(n_name#61), (n_name#61 = JAPAN), isnotnull(n_nationkey#60L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:bigint,n_name:string>\n                                 +- Sort [ps_suppkey#49L ASC NULLS FIRST], false, 0\n                                    +- Exchange hashpartitioning(ps_suppkey#49L, 200), ENSURE_REQUIREMENTS, [plan_id=101]\n                                       +- Filter isnotnull(ps_suppkey#49L)\n                                          +- FileScan parquet spark_catalog.tpch_100.partsupp[ps_suppkey#49L,ps_availqty#50,ps_supplycost#51] Batched: true, DataFilters: [isnotnull(ps_suppkey#49L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n         +- *(5) HashAggregate(keys=[ps_partkey#2L], functions=[sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))], output=[ps_partkey#2L, value#43])\n            +- AQEShuffleRead coalesced\n               +- ShuffleQueryStage 4\n                  +- Exchange hashpartitioning(ps_partkey#2L, 200), ENSURE_REQUIREMENTS, [plan_id=516]\n                     +- *(4) HashAggregate(keys=[ps_partkey#2L], functions=[partial_sum((ps_supplycost#5 * cast(ps_availqty#4 as decimal(10,0))))], output=[ps_partkey#2L, sum#69, isEmpty#70])\n                        +- *(4) Project [ps_partkey#2L, ps_availqty#4, ps_supplycost#5]\n                           +- *(4) BroadcastHashJoin [s_suppkey#7L], [ps_suppkey#3L], Inner, BuildLeft, false\n                              :- BroadcastQueryStage 3\n                              :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=419]\n                              :     +- AQEShuffleRead local\n                              :        +- ShuffleQueryStage 2\n                              :           +- Exchange hashpartitioning(s_suppkey#7L, 200), ENSURE_REQUIREMENTS, [plan_id=346]\n                              :              +- *(3) Project [s_suppkey#7L]\n                              :                 +- *(3) BroadcastHashJoin [s_nationkey#10L], [n_nationkey#14L], Inner, BuildRight, false\n                              :                    :- *(3) Filter (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L))\n                              :                    :  +- *(3) ColumnarToRow\n                              :                    :     +- FileScan parquet spark_catalog.tpch_100.supplier[s_suppkey#7L,s_nationkey#10L] Batched: true, DataFilters: [isnotnull(s_suppkey#7L), isnotnull(s_nationkey#10L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/supplier], PartitionFilters: [], PushedFilters: [IsNotNull(s_suppkey), IsNotNull(s_nationkey)], ReadSchema: struct<s_suppkey:bigint,s_nationkey:bigint>\n                              :                    +- BroadcastQueryStage 0\n                              :                       +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=216]\n                              :                          +- *(1) Project [n_nationkey#14L]\n                              :                             +- *(1) Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n                              :                                +- *(1) ColumnarToRow\n                              :                                   +- FileScan parquet spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15] Batched: true, DataFilters: [isnotnull(n_name#15), (n_name#15 = JAPAN), isnotnull(n_nationkey#14L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:bigint,n_name:string>\n                              +- AQEShuffleRead local\n                                 +- ShuffleQueryStage 1\n                                    +- Exchange hashpartitioning(ps_suppkey#3L, 200), ENSURE_REQUIREMENTS, [plan_id=237]\n                                       +- *(2) Filter isnotnull(ps_suppkey#3L)\n                                          +- *(2) ColumnarToRow\n                                             +- FileScan parquet spark_catalog.tpch_100.partsupp[ps_partkey#2L,ps_suppkey#3L,ps_availqty#4,ps_supplycost#5] Batched: true, DataFilters: [isnotnull(ps_suppkey#3L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_partkey:bigint,ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 3820200,
        "inputRowCount" : 95505
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "5" : [ 8556, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 9412, 7778, 8556, 8556, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 8556, 9412, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 7778, 7778, 8556, 7778, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 7778, 7778, 8556, 7778, 7778, 7778, 8556, 7778, 7778, 7778, 8556, 7778, 7778, 7778, 8556, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 8556, 8556, 7778, 7778, 8556, 7778, 8556, 7778, 8556, 8556, 7778, 8556, 8556, 7778, 7778, 7778, 8556, 7778, 7778, 8556, 8556, 7778, 8556, 7778, 8556, 7778, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 8556, 8556, 8556, 7778, 7778, 7778, 8556, 7778, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 7778, 8556, 8556, 8556, 7778, 7778, 7778, 7778, 7778, 8556, 8556, 7778, 8556, 7778, 8556, 8556 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 9,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 24 ],
      "Objectives" : {
        "DurationInMs" : 370,
        "TotalTasksDurationInMs" : 360,
        "IOBytes" : {
          "Total" : 1580556,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1580556,
            "SW" : 0
          }
        }
      }
    },
    "5" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1703060674,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 2240000000,
                "rowCount" : 80000000
              },
              "compileTime" : {
                "sizeInBytes" : 2240000000,
                "rowCount" : 80000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] "
          },
          "1" : {
            "sign" : 1552007108,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 13760000000,
                "rowCount" : 80000000
              },
              "compileTime" : {
                "sizeInBytes" : 13760000000,
                "rowCount" : 80000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#49L) "
          },
          "2" : {
            "sign" : 759886188,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 13760000000,
                "rowCount" : 80000000
              },
              "compileTime" : {
                "sizeInBytes" : 13760000000,
                "rowCount" : 80000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#48L, ps_suppkey#49L, ps_availqty#50, ps_supplycost#51, ps_comment#52], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n+- Filter isnotnull(ps_suppkey#49L)\n   +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1038501383,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 2240000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] Condition : isnotnull(ps_suppkey#49L) "
          },
          "1" : {
            "sign" : 485197137,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 2240000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpch_100.partsupp Output [3]: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] Batched: true Location: InMemoryFileIndex [hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp] PushedFilters: [IsNotNull(ps_suppkey)] ReadSchema: struct<ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)> "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "Scan parquet spark_catalog.tpch_100.partsupp",
          "toId" : 0,
          "toName" : "Filter",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Filter isnotnull(ps_suppkey#49L)\n+- FileScan parquet spark_catalog.tpch_100.partsupp[ps_suppkey#49L,ps_availqty#50,ps_supplycost#51] Batched: true, DataFilters: [isnotnull(ps_suppkey#49L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 2240000000,
        "inputRowCount" : 80000000
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 6,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 7 ],
      "Objectives" : {
        "DurationInMs" : 3318,
        "TotalTasksDurationInMs" : 43340,
        "IOBytes" : {
          "Total" : 2139181293,
          "Details" : {
            "IR" : 866018451,
            "IW" : 0,
            "SR" : 0,
            "SW" : 1273162842
          }
        }
      }
    },
    "6" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 501377547,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 24,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 24,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47] "
          },
          "1" : {
            "sign" : -1701378528,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 1601642400,
                "rowCount" : 80082120
              },
              "compileTime" : {
                "sizeInBytes" : 1601642400,
                "rowCount" : 80082120
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_availqty#50, ps_supplycost#51] "
          },
          "2" : {
            "sign" : 1069953915,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 2882956320,
                "rowCount" : 80082120
              },
              "compileTime" : {
                "sizeInBytes" : 2882956320,
                "rowCount" : 80082120
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ps_suppkey#49L = s_suppkey#53L) "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47]\n+- Project [ps_availqty#50, ps_supplycost#51]\n   +- Join Inner, (ps_suppkey#49L = s_suppkey#53L)\n      :- Project [s_suppkey#53L]\n      :  +- Join Inner, (s_nationkey#56L = n_nationkey#60L)\n      :     :- Project [s_suppkey#53L, s_nationkey#56L]\n      :     :  +- Filter (isnotnull(s_suppkey#53L) AND isnotnull(s_nationkey#56L))\n      :     :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#53L,s_name#54,s_address#55,s_nationkey#56L,s_phone#57,s_acctbal#58,s_comment#59] parquet\n      :     +- Project [n_nationkey#60L]\n      :        +- Filter ((isnotnull(n_name#61) AND (n_name#61 = JAPAN)) AND isnotnull(n_nationkey#60L))\n      :           +- Relation spark_catalog.tpch_100.nation[n_nationkey#60L,n_name#61,n_regionkey#62L,n_comment#63] parquet\n      +- Project [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51]\n         +- Filter isnotnull(ps_suppkey#49L)\n            +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#48L,ps_suppkey#49L,ps_availqty#50,ps_supplycost#51,ps_comment#52] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : 462923836,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [1]: [s_suppkey#53L] Arguments: 3 "
          },
          "5" : {
            "sign" : 111386429,
            "className" : "org.apache.spark.sql.execution.SortExec",
            "sizeInBytes" : -1,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Input [3]: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] Arguments: [ps_suppkey#49L ASC NULLS FIRST], false, 0 "
          },
          "6" : {
            "sign" : 276675448,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 2560000000,
            "rowCount" : 80000000,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [3]: [ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] Arguments: 4 "
          },
          "1" : {
            "sign" : 1538550042,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 1601642400,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [2]: [ps_availqty#50, ps_supplycost#51] Input [4]: [s_suppkey#53L, ps_suppkey#49L, ps_availqty#50, ps_supplycost#51] "
          },
          "0" : {
            "sign" : -136046598,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 24,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [2]: [ps_availqty#50, ps_supplycost#51] Keys: [] Functions [1]: [partial_sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))] Aggregate Attributes [2]: [sum#71, isEmpty#72] Results [2]: [sum#73, isEmpty#74] "
          },
          "2" : {
            "sign" : 594258323,
            "className" : "org.apache.spark.sql.execution.joins.SortMergeJoinExec",
            "sizeInBytes" : 2882956320,
            "rowCount" : 80082120,
            "isRuntime" : false,
            "predicate" : " (unknown) SortMergeJoin Left keys [1]: [s_suppkey#53L] Right keys [1]: [ps_suppkey#49L] Join type: Inner Join condition: None "
          },
          "3" : {
            "sign" : 1361975550,
            "className" : "org.apache.spark.sql.execution.SortExec",
            "sizeInBytes" : -1,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Input [1]: [s_suppkey#53L] Arguments: [s_suppkey#53L ASC NULLS FIRST], false, 0 "
          }
        },
        "links" : [ {
          "fromId" : 4,
          "fromName" : "ShuffleQueryStage",
          "toId" : 3,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Sort",
          "toId" : 2,
          "toName" : "SortMergeJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "ShuffleQueryStage",
          "toId" : 5,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Sort",
          "toId" : 2,
          "toName" : "SortMergeJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "SortMergeJoin",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[partial_sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[sum#73, isEmpty#74])\n+- Project [ps_availqty#50, ps_supplycost#51]\n   +- SortMergeJoin [s_suppkey#53L], [ps_suppkey#49L], Inner\n      :- Sort [s_suppkey#53L ASC NULLS FIRST], false, 0\n      :  +- ShuffleQueryStage 3\n      :     +- ReusedExchange [s_suppkey#53L], Exchange hashpartitioning(s_suppkey#7L, 200), ENSURE_REQUIREMENTS, [plan_id=346]\n      +- Sort [ps_suppkey#49L ASC NULLS FIRST], false, 0\n         +- ShuffleQueryStage 4\n            +- Exchange hashpartitioning(ps_suppkey#49L, 200), ENSURE_REQUIREMENTS, [plan_id=657]\n               +- *(3) Filter isnotnull(ps_suppkey#49L)\n                  +- *(3) ColumnarToRow\n                     +- FileScan parquet spark_catalog.tpch_100.partsupp[ps_suppkey#49L,ps_availqty#50,ps_supplycost#51] Batched: true, DataFilters: [isnotnull(ps_suppkey#49L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 2560637792,
        "inputRowCount" : 80039862
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "1" : [ 1156, 1051, 1156, 1156, 1271, 1156, 1271, 1156, 1051, 1399, 1051, 1156, 1051, 1156, 1156, 1271, 1271, 1051, 1156, 1156, 1051, 1156, 1156, 1271, 1156, 1271, 1271, 1156, 1156, 1271, 1156, 1271, 1051, 1156, 1156, 1156, 1051, 1156, 1271, 955, 955, 1051, 1051, 1051, 1156, 1051, 1156, 1156, 1156, 1156, 1156, 1156, 1271, 1156, 1271, 1156, 1271, 1051, 1051, 1156, 1156, 1156, 1051, 1271, 1156, 1156, 1156, 1156, 1399, 1156, 1051, 1051, 1051, 1156, 1156, 1271, 1051, 1156, 1156, 1271, 1156, 1156, 1156, 1051, 1156, 955, 1051, 1156, 1156, 1051, 1271, 1051, 1051, 1051, 1051, 1156, 1156, 955, 1156, 1051, 1156, 1271, 1271, 1399, 1399, 1156, 1156, 1399, 1156, 1156, 1051, 1051, 1271, 1156, 1156, 1156, 1156, 1271, 1271, 1156, 1051, 1156, 1051, 1156, 1271, 1271, 1051, 1271, 1051, 1156, 1156, 955, 1271, 1156, 1156, 1156, 1156, 1051, 1156, 1399, 1156, 1271, 1051, 1399, 1271, 1271, 1051, 1156, 1156, 1156, 1271, 1051, 1156, 1271, 1156, 1271, 1156, 1271, 1156, 1156, 1271, 1156, 1156, 1051, 1156, 1156, 1051, 1271, 1156, 1156, 1156, 1271, 1051, 955, 1156, 1156, 1156, 1156, 1051, 1156, 1051, 955, 1051, 1051, 1271, 1156, 1156, 1051, 1156, 1051, 1156, 1156, 1051, 1271, 1156, 1051, 1156, 1156, 1271, 1156 ],
        "3" : [ 6290853, 6688327, 6868997, 6868997, 6880215, 6868997, 6880215, 6880215, 6796729, 6850930, 6850930, 6868997, 6850930, 6399255, 6880215, 6832863, 6880215, 6778662, 6868997, 6880215, 6850930, 6862148, 6880215, 6760595, 6868997, 6880215, 6868997, 6868997, 6525724, 6832863, 6453456, 6880215, 6850930, 6868997, 6616059, 6868997, 6850930, 6561858, 6880215, 6724461, 6850930, 6880215, 6760595, 6760595, 6724461, 6489590, 6880215, 6634126, 6850930, 6880215, 6868997, 6868997, 6880215, 6862148, 6862148, 6880215, 6868997, 6880215, 6670260, 6489590, 6832863, 6814796, 6561858, 6880215, 6880215, 6880215, 6880215, 6507657, 6417322, 6742528, 6742528, 6844081, 6796729, 6868997, 6862148, 6706394, 6832863, 6868997, 6850930, 6706394, 6868997, 6254719, 6807947, 6814796, 6760595, 6880215, 6880215, 6868997, 6778662, 6742528, 6814796, 6627277, 6832863, 6880215, 6850930, 6814796, 6832863, 6868997, 6880215, 6868997, 6868997, 6880215, 6880215, 6832863, 6880215, 6796729, 6814796, 6616059, 6880215, 6880215, 6634126, 6760595, 6543791, 6880215, 6862148, 6880215, 6634126, 6850930, 6868997, 6706394, 6760595, 6742528, 6880215, 6850930, 6880215, 6742528, 6862148, 6880215, 6850930, 6771813, 6826014, 6880215, 6771813, 6868997, 6616059, 6832863, 6880215, 6742528, 6832863, 6868997, 6880215, 6868997, 6868997, 6832863, 6868997, 6814796, 6760595, 6880215, 6826014, 6778662, 6880215, 6814796, 6634126, 6272786, 6814796, 6880215, 6880215, 6742528, 6880215, 6832863, 6880215, 6507657, 6862148, 6862148, 6868997, 6868997, 6543791, 6880215, 6814796, 6453456, 6880215, 6724461, 6771813, 6868997, 6789880, 6868997, 6880215, 6880215, 6579925, 6880215, 6760595, 6850930, 6363121, 6706394, 6616059, 6850930, 6850930, 6850930, 6868997, 6778662, 6880215, 6760595, 6850930, 6880215, 6862148, 6363121, 6868997, 6868997, 6880215, 6868997 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 7,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 10 ],
      "Objectives" : {
        "DurationInMs" : 3732,
        "TotalTasksDurationInMs" : 44943,
        "IOBytes" : {
          "Total" : 1273385372,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1273383555,
            "SW" : 1817
          }
        }
      }
    },
    "1" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -346275464,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 2880000000,
                "rowCount" : 80000000
              },
              "compileTime" : {
                "sizeInBytes" : 2880000000,
                "rowCount" : 80000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5] "
          },
          "1" : {
            "sign" : 1542235709,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 13760000000,
                "rowCount" : 80000000
              },
              "compileTime" : {
                "sizeInBytes" : 13760000000,
                "rowCount" : 80000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(ps_suppkey#3L) "
          },
          "2" : {
            "sign" : -114112705,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 13760000000,
                "rowCount" : 80000000
              },
              "compileTime" : {
                "sizeInBytes" : 13760000000,
                "rowCount" : 80000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5, ps_comment#6], `spark_catalog`.`tpch_100`.`partsupp`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5]\n+- Filter isnotnull(ps_suppkey#3L)\n   +- Relation spark_catalog.tpch_100.partsupp[ps_partkey#2L,ps_suppkey#3L,ps_availqty#4,ps_supplycost#5,ps_comment#6] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -845335001,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 2880000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [4]: [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5] Condition : isnotnull(ps_suppkey#3L) "
          },
          "1" : {
            "sign" : -1284625239,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 2880000000,
            "rowCount" : 80000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpch_100.partsupp Output [4]: [ps_partkey#2L, ps_suppkey#3L, ps_availqty#4, ps_supplycost#5] Batched: true Location: InMemoryFileIndex [hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp] PushedFilters: [IsNotNull(ps_suppkey)] ReadSchema: struct<ps_partkey:bigint,ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)> "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "Scan parquet spark_catalog.tpch_100.partsupp",
          "toId" : 0,
          "toName" : "Filter",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Filter isnotnull(ps_suppkey#3L)\n+- FileScan parquet spark_catalog.tpch_100.partsupp[ps_partkey#2L,ps_suppkey#3L,ps_availqty#4,ps_supplycost#5] Batched: true, DataFilters: [isnotnull(ps_suppkey#3L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_partkey:bigint,ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 2880000000,
        "inputRowCount" : 80000000
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 1,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 0 ],
      "Objectives" : {
        "DurationInMs" : 9550,
        "TotalTasksDurationInMs" : 133261,
        "IOBytes" : {
          "Total" : 3001851196,
          "Details" : {
            "IR" : 1230875307,
            "IW" : 0,
            "SR" : 0,
            "SW" : 1770975889
          }
        }
      }
    },
    "0" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -313453053,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 16,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 16,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [n_nationkey#14L] "
          },
          "1" : {
            "sign" : -184173915,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 131,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 131,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L)) "
          },
          "2" : {
            "sign" : -1833185194,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 3275,
                "rowCount" : 25
              },
              "compileTime" : {
                "sizeInBytes" : 3275,
                "rowCount" : 25
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [n_nationkey#14L, n_name#15, n_regionkey#16L, n_comment#17], `spark_catalog`.`tpch_100`.`nation`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [n_nationkey#14L]\n+- Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n   +- Relation spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15,n_regionkey#16L,n_comment#17] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -206321729,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [n_nationkey#14L] Input [2]: [n_nationkey#14L, n_name#15] "
          },
          "1" : {
            "sign" : -637399203,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [n_nationkey#14L, n_name#15] Condition : ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L)) "
          },
          "2" : {
            "sign" : -2062394420,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 16,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpch_100.nation Output [2]: [n_nationkey#14L, n_name#15] Batched: true Location: InMemoryFileIndex [hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation] PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)] ReadSchema: struct<n_nationkey:bigint,n_name:string> "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Scan parquet spark_catalog.tpch_100.nation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [n_nationkey#14L]\n+- Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n   +- FileScan parquet spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15] Batched: true, DataFilters: [isnotnull(n_name#15), (n_name#15 = JAPAN), isnotnull(n_nationkey#14L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:bigint,n_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 16,
        "inputRowCount" : 1
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 0,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 1 ],
      "Objectives" : {
        "DurationInMs" : 7828,
        "TotalTasksDurationInMs" : 389,
        "IOBytes" : {
          "Total" : 2780,
          "Details" : {
            "IR" : 2780,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "2" : {
      "QSLogical" : {
        "operators" : {
          "4" : {
            "sign" : -582420732,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 201000000,
                "rowCount" : 1000000
              },
              "compileTime" : {
                "sizeInBytes" : 201000000,
                "rowCount" : 1000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_suppkey#7L, s_name#8, s_address#9, s_nationkey#10L, s_phone#11, s_acctbal#12, s_comment#13], `spark_catalog`.`tpch_100`.`supplier`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "1" : {
            "sign" : 777070770,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32000000,
                "rowCount" : 1000000
              },
              "compileTime" : {
                "sizeInBytes" : 32000000,
                "rowCount" : 1000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_nationkey#10L = n_nationkey#14L) "
          },
          "0" : {
            "sign" : 1430515012,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 16000000,
                "rowCount" : 1000000
              },
              "compileTime" : {
                "sizeInBytes" : 16000000,
                "rowCount" : 1000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#7L] "
          },
          "2" : {
            "sign" : 1001821905,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 24000000,
                "rowCount" : 1000000
              },
              "compileTime" : {
                "sizeInBytes" : 24000000,
                "rowCount" : 1000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_suppkey#7L, s_nationkey#10L] "
          },
          "3" : {
            "sign" : -1844519439,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 201000000,
                "rowCount" : 1000000
              },
              "compileTime" : {
                "sizeInBytes" : 201000000,
                "rowCount" : 1000000
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L)) "
          }
        },
        "links" : [ {
          "fromId" : 4,
          "fromName" : "LogicalRelation",
          "toId" : 3,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Filter",
          "toId" : 2,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Project",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_suppkey#7L]\n+- Join Inner, (s_nationkey#10L = n_nationkey#14L)\n   :- Project [s_suppkey#7L, s_nationkey#10L]\n   :  +- Filter (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L))\n   :     +- Relation spark_catalog.tpch_100.supplier[s_suppkey#7L,s_name#8,s_address#9,s_nationkey#10L,s_phone#11,s_acctbal#12,s_comment#13] parquet\n   +- Project [n_nationkey#14L]\n      +- Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n         +- Relation spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15,n_regionkey#16L,n_comment#17] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : -704579276,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1048584,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [1]: [n_nationkey#14L] Arguments: 0 "
          },
          "1" : {
            "sign" : 212536968,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 32000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [s_nationkey#10L] Right keys [1]: [n_nationkey#14L] Join type: Inner Join condition: None "
          },
          "0" : {
            "sign" : -99052848,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 16000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [s_suppkey#7L] Input [3]: [s_suppkey#7L, s_nationkey#10L, n_nationkey#14L] "
          },
          "2" : {
            "sign" : -1385561198,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [s_suppkey#7L, s_nationkey#10L] Condition : (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L)) "
          },
          "3" : {
            "sign" : -389621345,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 24000000,
            "rowCount" : 1000000,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpch_100.supplier Output [2]: [s_suppkey#7L, s_nationkey#10L] Batched: true Location: InMemoryFileIndex [hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/supplier] PushedFilters: [IsNotNull(s_suppkey), IsNotNull(s_nationkey)] ReadSchema: struct<s_suppkey:bigint,s_nationkey:bigint> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpch_100.supplier",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "BroadcastQueryStage",
          "toId" : 1,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "BroadcastHashJoin",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_suppkey#7L]\n+- BroadcastHashJoin [s_nationkey#10L], [n_nationkey#14L], Inner, BuildRight, false\n   :- Filter (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L))\n   :  +- FileScan parquet spark_catalog.tpch_100.supplier[s_suppkey#7L,s_nationkey#10L] Batched: true, DataFilters: [isnotnull(s_suppkey#7L), isnotnull(s_nationkey#10L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/supplier], PartitionFilters: [], PushedFilters: [IsNotNull(s_suppkey), IsNotNull(s_nationkey)], ReadSchema: struct<s_suppkey:bigint,s_nationkey:bigint>\n   +- BroadcastQueryStage 0\n      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=216]\n         +- *(1) Project [n_nationkey#14L]\n            +- *(1) Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n               +- *(1) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15] Batched: true, DataFilters: [isnotnull(n_name#15), (n_name#15 = JAPAN), isnotnull(n_nationkey#14L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:bigint,n_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 25048584,
        "inputRowCount" : 1000001
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 11,
        "FinishedTasksNum" : 24,
        "FinishedTasksTotalTimeInMs" : 87110.0,
        "FinishedTasksDistributionInMs" : [ 1243.0, 1491.0, 4754.0, 5666.0, 6977.0 ]
      },
      "QueryStageOptimizationId" : 2,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 2 ],
      "Objectives" : {
        "DurationInMs" : 372,
        "TotalTasksDurationInMs" : 1863,
        "IOBytes" : {
          "Total" : 5920838,
          "Details" : {
            "IR" : 5700125,
            "IW" : 0,
            "SR" : 0,
            "SW" : 220713
          }
        }
      }
    },
    "7" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -254787027,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 920,
                "rowCount" : 23
              },
              "compileTime" : {
                "sizeInBytes" : 24,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47], HashAggregate(keys=[], functions=[sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0)))) * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47], HashAggregate(keys=[], functions=[sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 1510764512,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 920,
            "rowCount" : 23,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [2]: [sum#73, isEmpty#74] Keys: [] Functions [1]: [sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))] Aggregate Attributes [1]: [sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))#46] Results [1]: [(sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))#46 * 0.0000010000) AS (sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47] "
          },
          "1" : {
            "sign" : 611961359,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 24,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [2]: [sum#73, isEmpty#74] Arguments: 5 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "ShuffleQueryStage",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[(sum((ps_supplycost * ps_availqty)) * 0.0000010000)#47])\n+- ShuffleQueryStage 5\n   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=751]\n      +- *(6) HashAggregate(keys=[], functions=[partial_sum((ps_supplycost#51 * cast(ps_availqty#50 as decimal(10,0))))], output=[sum#73, isEmpty#74])\n         +- *(6) Project [ps_availqty#50, ps_supplycost#51]\n            +- *(6) SortMergeJoin [s_suppkey#53L], [ps_suppkey#49L], Inner\n               :- *(4) Sort [s_suppkey#53L ASC NULLS FIRST], false, 0\n               :  +- AQEShuffleRead coalesced\n               :     +- ShuffleQueryStage 3\n               :        +- ReusedExchange [s_suppkey#53L], Exchange hashpartitioning(s_suppkey#7L, 200), ENSURE_REQUIREMENTS, [plan_id=346]\n               +- *(5) Sort [ps_suppkey#49L ASC NULLS FIRST], false, 0\n                  +- AQEShuffleRead coalesced\n                     +- ShuffleQueryStage 4\n                        +- Exchange hashpartitioning(ps_suppkey#49L, 200), ENSURE_REQUIREMENTS, [plan_id=657]\n                           +- *(3) Filter isnotnull(ps_suppkey#49L)\n                              +- *(3) ColumnarToRow\n                                 +- FileScan parquet spark_catalog.tpch_100.partsupp[ps_suppkey#49L,ps_availqty#50,ps_supplycost#51] Batched: true, DataFilters: [isnotnull(ps_suppkey#49L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/partsupp], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_suppkey:bigint,ps_availqty:int,ps_supplycost:decimal(12,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 920,
        "inputRowCount" : 23
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "4" : [ 1840 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 8,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 14 ],
      "Objectives" : {
        "DurationInMs" : 181,
        "TotalTasksDurationInMs" : 171,
        "IOBytes" : {
          "Total" : 1817,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1817,
            "SW" : 0
          }
        }
      }
    },
    "3" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -1325547232,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 637792,
                "rowCount" : 39862
              },
              "compileTime" : {
                "sizeInBytes" : 16000000,
                "rowCount" : 1000000
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_suppkey#7L], ShuffleQueryStage 2 "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Project [s_suppkey#7L], ShuffleQueryStage 2\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1258391406,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 637792,
            "rowCount" : 39862,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [1]: [s_suppkey#7L] Arguments: 2 "
          }
        },
        "links" : [ ],
        "rawPlan" : "ShuffleQueryStage 2\n+- Exchange hashpartitioning(s_suppkey#7L, 200), ENSURE_REQUIREMENTS, [plan_id=346]\n   +- *(3) Project [s_suppkey#7L]\n      +- *(3) BroadcastHashJoin [s_nationkey#10L], [n_nationkey#14L], Inner, BuildRight, false\n         :- *(3) Filter (isnotnull(s_suppkey#7L) AND isnotnull(s_nationkey#10L))\n         :  +- *(3) ColumnarToRow\n         :     +- FileScan parquet spark_catalog.tpch_100.supplier[s_suppkey#7L,s_nationkey#10L] Batched: true, DataFilters: [isnotnull(s_suppkey#7L), isnotnull(s_nationkey#10L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/supplier], PartitionFilters: [], PushedFilters: [IsNotNull(s_suppkey), IsNotNull(s_nationkey)], ReadSchema: struct<s_suppkey:bigint,s_nationkey:bigint>\n         +- BroadcastQueryStage 0\n            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=216]\n               +- *(1) Project [n_nationkey#14L]\n                  +- *(1) Filter ((isnotnull(n_name#15) AND (n_name#15 = JAPAN)) AND isnotnull(n_nationkey#14L))\n                     +- *(1) ColumnarToRow\n                        +- FileScan parquet spark_catalog.tpch_100.nation[n_nationkey#14L,n_name#15] Batched: true, DataFilters: [isnotnull(n_name#15), (n_name#15 = JAPAN), isnotnull(n_nationkey#14L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node1-opa:8020/user/spark_benchmark/tpch_100/dataset/nation], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), EqualTo(n_name,JAPAN), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:bigint,n_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 637792,
        "inputRowCount" : 39862
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "1" : [ 1156, 1051, 1156, 1156, 1271, 1156, 1271, 1156, 1051, 1399, 1051, 1156, 1051, 1156, 1156, 1271, 1271, 1051, 1156, 1156, 1051, 1156, 1156, 1271, 1156, 1271, 1271, 1156, 1156, 1271, 1156, 1271, 1051, 1156, 1156, 1156, 1051, 1156, 1271, 955, 955, 1051, 1051, 1051, 1156, 1051, 1156, 1156, 1156, 1156, 1156, 1156, 1271, 1156, 1271, 1156, 1271, 1051, 1051, 1156, 1156, 1156, 1051, 1271, 1156, 1156, 1156, 1156, 1399, 1156, 1051, 1051, 1051, 1156, 1156, 1271, 1051, 1156, 1156, 1271, 1156, 1156, 1156, 1051, 1156, 955, 1051, 1156, 1156, 1051, 1271, 1051, 1051, 1051, 1051, 1156, 1156, 955, 1156, 1051, 1156, 1271, 1271, 1399, 1399, 1156, 1156, 1399, 1156, 1156, 1051, 1051, 1271, 1156, 1156, 1156, 1156, 1271, 1271, 1156, 1051, 1156, 1051, 1156, 1271, 1271, 1051, 1271, 1051, 1156, 1156, 955, 1271, 1156, 1156, 1156, 1156, 1051, 1156, 1399, 1156, 1271, 1051, 1399, 1271, 1271, 1051, 1156, 1156, 1156, 1271, 1051, 1156, 1271, 1156, 1271, 1156, 1271, 1156, 1156, 1271, 1156, 1156, 1051, 1156, 1156, 1051, 1271, 1156, 1156, 1156, 1271, 1051, 955, 1156, 1156, 1156, 1156, 1051, 1156, 1051, 955, 1051, 1051, 1271, 1156, 1156, 1051, 1156, 1051, 1156, 1156, 1051, 1271, 1156, 1051, 1156, 1156, 1271, 1156 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 7,
        "FinishedTasksNum" : 28,
        "FinishedTasksTotalTimeInMs" : 98969.0,
        "FinishedTasksDistributionInMs" : [ 909.0, 1479.0, 1756.0, 5666.0, 8118.0 ]
      },
      "QueryStageOptimizationId" : 3,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 4 ],
      "Objectives" : {
        "DurationInMs" : 265,
        "TotalTasksDurationInMs" : 256,
        "IOBytes" : {
          "Total" : 220713,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 220713,
            "SW" : 0
          }
        }
      }
    }
  },
  "SQLStartTimeInMs" : 1702226615400,
  "SQLEndTimeInMs" : 1702226644153,
  "Objectives" : {
    "DurationInMs" : 28753,
    "IOBytes" : {
      "Total" : 8358751801,
      "Details" : {
        "IR" : 2102596663,
        "IW" : 0,
        "SR" : 3155529724,
        "SW" : 3100625414
      }
    }
  }
}
