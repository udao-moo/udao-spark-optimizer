{
  "CompileTimeLQP" : {
    "LQP" : {
      "operators" : {
        "12" : {
          "sign" : -1504048896,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 43776970976,
          "rowCount" : 288006388,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#41, ss_item_sk#42, ss_customer_sk#43, ss_cdemo_sk#44, ss_hdemo_sk#45, ss_addr_sk#46, ss_store_sk#47, ss_promo_sk#48, ss_ticket_number#49L, ss_quantity#50, ss_wholesale_cost#51, ss_list_price#52, ss_sales_price#53, ss_ext_discount_amt#54, ss_ext_sales_price#55, ss_ext_wholesale_cost#56, ss_ext_list_price#57, ss_ext_tax#58, ss_coupon_amt#59, ss_net_paid#60, ss_net_paid_inc_tax#61, ss_net_profit#62, ss_sold_date_sk#63], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "8" : {
          "sign" : -913851183,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 43776970976,
          "rowCount" : 288006388,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#18, ss_item_sk#19, ss_customer_sk#20, ss_cdemo_sk#21, ss_hdemo_sk#22, ss_addr_sk#23, ss_store_sk#24, ss_promo_sk#25, ss_ticket_number#26L, ss_quantity#27, ss_wholesale_cost#28, ss_list_price#29, ss_sales_price#30, ss_ext_discount_amt#31, ss_ext_sales_price#32, ss_ext_wholesale_cost#33, ss_ext_list_price#34, ss_ext_tax#35, ss_coupon_amt#36, ss_net_paid#37, ss_net_paid_inc_tax#38, ss_net_profit#39, ss_sold_date_sk#40], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "19" : {
          "sign" : -1453876181,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 609092728,
          "rowCount" : 4007189,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#96) AND (((ss_quantity#96 >= 16) AND (ss_quantity#96 <= 20)) AND ((((ss_list_price#98 >= 142.00) AND (ss_list_price#98 <= 152.00)) OR ((ss_coupon_amt#105 >= 3054.00) AND (ss_coupon_amt#105 <= 4054.00))) OR ((ss_wholesale_cost#97 >= 80.00) AND (ss_wholesale_cost#97 <= 100.00))))) "
        },
        "23" : {
          "sign" : 1375628566,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 995958872,
          "rowCount" : 6552361,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#119) AND (((ss_quantity#119 >= 21) AND (ss_quantity#119 <= 25)) AND ((((ss_list_price#121 >= 135.00) AND (ss_list_price#121 <= 145.00)) OR ((ss_coupon_amt#128 >= 14180.00) AND (ss_coupon_amt#128 <= 15180.00))) OR ((ss_wholesale_cost#120 >= 38.00) AND (ss_wholesale_cost#120 <= 58.00))))) "
        },
        "4" : {
          "sign" : 1484629545,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 56,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Cross "
        },
        "15" : {
          "sign" : -554481135,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 1105867336,
          "rowCount" : 7275443,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#73) AND (((ss_quantity#73 >= 11) AND (ss_quantity#73 <= 15)) AND ((((ss_list_price#75 >= 66.00) AND (ss_list_price#75 <= 76.00)) OR ((ss_coupon_amt#82 >= 920.00) AND (ss_coupon_amt#82 <= 1920.00))) OR ((ss_wholesale_cost#74 >= 4.00) AND (ss_wholesale_cost#74 <= 24.00))))) "
        },
        "11" : {
          "sign" : 1412047523,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 1247909208,
          "rowCount" : 8209929,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#50) AND (((ss_quantity#50 >= 6) AND (ss_quantity#50 <= 10)) AND ((((ss_list_price#52 >= 91.00) AND (ss_list_price#52 <= 101.00)) OR ((ss_coupon_amt#59 >= 1430.00) AND (ss_coupon_amt#59 <= 2430.00))) OR ((ss_wholesale_cost#51 >= 32.00) AND (ss_wholesale_cost#51 <= 52.00))))) "
        },
        "9" : {
          "sign" : 1228376260,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 32,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#52)) / 100.0) as decimal(11,6)) AS B2_LP#3, count(ss_list_price#52) AS B2_CNT#4L, count(distinct ss_list_price#52) AS B2_CNTD#5L] "
        },
        "22" : {
          "sign" : 813047717,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 104837776,
          "rowCount" : 6552361,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_list_price#121] "
        },
        "26" : {
          "sign" : -593302086,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 122517936,
          "rowCount" : 7657371,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_list_price#144] "
        },
        "13" : {
          "sign" : -1833133292,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 32,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#75)) / 100.0) as decimal(11,6)) AS B3_LP#6, count(ss_list_price#75) AS B3_CNT#7L, count(distinct ss_list_price#75) AS B3_CNTD#8L] "
        },
        "24" : {
          "sign" : 1161395655,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 43776970976,
          "rowCount" : 288006388,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#110, ss_item_sk#111, ss_customer_sk#112, ss_cdemo_sk#113, ss_hdemo_sk#114, ss_addr_sk#115, ss_store_sk#116, ss_promo_sk#117, ss_ticket_number#118L, ss_quantity#119, ss_wholesale_cost#120, ss_list_price#121, ss_sales_price#122, ss_ext_discount_amt#123, ss_ext_sales_price#124, ss_ext_wholesale_cost#125, ss_ext_list_price#126, ss_ext_tax#127, ss_coupon_amt#128, ss_net_paid#129, ss_net_paid_inc_tax#130, ss_net_profit#131, ss_sold_date_sk#132], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "16" : {
          "sign" : 1642365957,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 43776970976,
          "rowCount" : 288006388,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#64, ss_item_sk#65, ss_customer_sk#66, ss_cdemo_sk#67, ss_hdemo_sk#68, ss_addr_sk#69, ss_store_sk#70, ss_promo_sk#71, ss_ticket_number#72L, ss_quantity#73, ss_wholesale_cost#74, ss_list_price#75, ss_sales_price#76, ss_ext_discount_amt#77, ss_ext_sales_price#78, ss_ext_wholesale_cost#79, ss_ext_list_price#80, ss_ext_tax#81, ss_coupon_amt#82, ss_net_paid#83, ss_net_paid_inc_tax#84, ss_net_profit#85, ss_sold_date_sk#86], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "5" : {
          "sign" : 1228675738,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 32,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#0, count(ss_list_price#29) AS B1_CNT#1L, count(distinct ss_list_price#29) AS B1_CNTD#2L] "
        },
        "10" : {
          "sign" : 690663461,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 131358864,
          "rowCount" : 8209929,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_list_price#52] "
        },
        "21" : {
          "sign" : -1906492930,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 32,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#121)) / 100.0) as decimal(11,6)) AS B5_LP#12, count(ss_list_price#121) AS B5_CNT#13L, count(distinct ss_list_price#121) AS B5_CNTD#14L] "
        },
        "6" : {
          "sign" : 1385135785,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 98010800,
          "rowCount" : 6125675,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_list_price#29] "
        },
        "1" : {
          "sign" : 905114786,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 128,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Cross "
        },
        "17" : {
          "sign" : 384785762,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 32,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#98)) / 100.0) as decimal(11,6)) AS B4_LP#9, count(ss_list_price#98) AS B4_CNT#10L, count(distinct ss_list_price#98) AS B4_CNTD#11L] "
        },
        "25" : {
          "sign" : 1597866238,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 32,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#144)) / 100.0) as decimal(11,6)) AS B6_LP#15, count(ss_list_price#144) AS B6_CNT#16L, count(distinct ss_list_price#144) AS B6_CNTD#17L] "
        },
        "14" : {
          "sign" : 387542144,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 116407088,
          "rowCount" : 7275443,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_list_price#75] "
        },
        "0" : {
          "sign" : -1984539643,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 152,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Cross "
        },
        "20" : {
          "sign" : -356777290,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 43776970976,
          "rowCount" : 288006388,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#87, ss_item_sk#88, ss_customer_sk#89, ss_cdemo_sk#90, ss_hdemo_sk#91, ss_addr_sk#92, ss_store_sk#93, ss_promo_sk#94, ss_ticket_number#95L, ss_quantity#96, ss_wholesale_cost#97, ss_list_price#98, ss_sales_price#99, ss_ext_discount_amt#100, ss_ext_sales_price#101, ss_ext_wholesale_cost#102, ss_ext_list_price#103, ss_ext_tax#104, ss_coupon_amt#105, ss_net_paid#106, ss_net_paid_inc_tax#107, ss_net_profit#108, ss_sold_date_sk#109], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "27" : {
          "sign" : -373089894,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 1163920392,
          "rowCount" : 7657371,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#142) AND (((ss_quantity#142 >= 26) AND (ss_quantity#142 <= 30)) AND ((((ss_list_price#144 >= 28.00) AND (ss_list_price#144 <= 38.00)) OR ((ss_coupon_amt#151 >= 2513.00) AND (ss_coupon_amt#151 <= 3513.00))) OR ((ss_wholesale_cost#143 >= 42.00) AND (ss_wholesale_cost#143 <= 62.00))))) "
        },
        "2" : {
          "sign" : -2094239481,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 104,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Cross "
        },
        "18" : {
          "sign" : 96488643,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 64115024,
          "rowCount" : 4007189,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_list_price#98] "
        },
        "7" : {
          "sign" : -785224445,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 931102600,
          "rowCount" : 6125675,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#27) AND (((ss_quantity#27 >= 0) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00))))) "
        },
        "3" : {
          "sign" : 530579064,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 80,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Cross "
        },
        "28" : {
          "sign" : -1782334540,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 43776970976,
          "rowCount" : 288006388,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#133, ss_item_sk#134, ss_customer_sk#135, ss_cdemo_sk#136, ss_hdemo_sk#137, ss_addr_sk#138, ss_store_sk#139, ss_promo_sk#140, ss_ticket_number#141L, ss_quantity#142, ss_wholesale_cost#143, ss_list_price#144, ss_sales_price#145, ss_ext_discount_amt#146, ss_ext_sales_price#147, ss_ext_wholesale_cost#148, ss_ext_list_price#149, ss_ext_tax#150, ss_coupon_amt#151, ss_net_paid#152, ss_net_paid_inc_tax#153, ss_net_profit#154, ss_sold_date_sk#155], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        }
      },
      "links" : [ {
        "fromId" : 8,
        "fromName" : "LogicalRelation",
        "toId" : 7,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 7,
        "fromName" : "Filter",
        "toId" : 6,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 6,
        "fromName" : "Project",
        "toId" : 5,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 5,
        "fromName" : "Aggregate",
        "toId" : 4,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 12,
        "fromName" : "LogicalRelation",
        "toId" : 11,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 11,
        "fromName" : "Filter",
        "toId" : 10,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 10,
        "fromName" : "Project",
        "toId" : 9,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 9,
        "fromName" : "Aggregate",
        "toId" : 4,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 4,
        "fromName" : "Join",
        "toId" : 3,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 16,
        "fromName" : "LogicalRelation",
        "toId" : 15,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 15,
        "fromName" : "Filter",
        "toId" : 14,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 14,
        "fromName" : "Project",
        "toId" : 13,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 13,
        "fromName" : "Aggregate",
        "toId" : 3,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 3,
        "fromName" : "Join",
        "toId" : 2,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 20,
        "fromName" : "LogicalRelation",
        "toId" : 19,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 19,
        "fromName" : "Filter",
        "toId" : 18,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 18,
        "fromName" : "Project",
        "toId" : 17,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 17,
        "fromName" : "Aggregate",
        "toId" : 2,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 2,
        "fromName" : "Join",
        "toId" : 1,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 24,
        "fromName" : "LogicalRelation",
        "toId" : 23,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 23,
        "fromName" : "Filter",
        "toId" : 22,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 22,
        "fromName" : "Project",
        "toId" : 21,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 21,
        "fromName" : "Aggregate",
        "toId" : 1,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 1,
        "fromName" : "Join",
        "toId" : 0,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 28,
        "fromName" : "LogicalRelation",
        "toId" : 27,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 27,
        "fromName" : "Filter",
        "toId" : 26,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 26,
        "fromName" : "Project",
        "toId" : 25,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 25,
        "fromName" : "Aggregate",
        "toId" : 0,
        "toName" : "Join",
        "linkType" : "Operator"
      } ],
      "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#0, count(ss_list_price#29) AS B1_CNT#1L, count(distinct ss_list_price#29) AS B1_CNTD#2L]\n:  :  :  :  :  +- Project [ss_list_price#29]\n:  :  :  :  :     +- Filter (isnotnull(ss_quantity#27) AND (((ss_quantity#27 >= 0) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00)))))\n:  :  :  :  :        +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#18,ss_item_sk#19,ss_customer_sk#20,ss_cdemo_sk#21,ss_hdemo_sk#22,ss_addr_sk#23,ss_store_sk#24,ss_promo_sk#25,ss_ticket_number#26L,ss_quantity#27,ss_wholesale_cost#28,ss_list_price#29,ss_sales_price#30,ss_ext_discount_amt#31,ss_ext_sales_price#32,ss_ext_wholesale_cost#33,ss_ext_list_price#34,ss_ext_tax#35,ss_coupon_amt#36,ss_net_paid#37,ss_net_paid_inc_tax#38,ss_net_profit#39,ss_sold_date_sk#40] parquet\n:  :  :  :  +- Aggregate [cast((avg(UnscaledValue(ss_list_price#52)) / 100.0) as decimal(11,6)) AS B2_LP#3, count(ss_list_price#52) AS B2_CNT#4L, count(distinct ss_list_price#52) AS B2_CNTD#5L]\n:  :  :  :     +- Project [ss_list_price#52]\n:  :  :  :        +- Filter (isnotnull(ss_quantity#50) AND (((ss_quantity#50 >= 6) AND (ss_quantity#50 <= 10)) AND ((((ss_list_price#52 >= 91.00) AND (ss_list_price#52 <= 101.00)) OR ((ss_coupon_amt#59 >= 1430.00) AND (ss_coupon_amt#59 <= 2430.00))) OR ((ss_wholesale_cost#51 >= 32.00) AND (ss_wholesale_cost#51 <= 52.00)))))\n:  :  :  :           +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#41,ss_item_sk#42,ss_customer_sk#43,ss_cdemo_sk#44,ss_hdemo_sk#45,ss_addr_sk#46,ss_store_sk#47,ss_promo_sk#48,ss_ticket_number#49L,ss_quantity#50,ss_wholesale_cost#51,ss_list_price#52,ss_sales_price#53,ss_ext_discount_amt#54,ss_ext_sales_price#55,ss_ext_wholesale_cost#56,ss_ext_list_price#57,ss_ext_tax#58,ss_coupon_amt#59,ss_net_paid#60,ss_net_paid_inc_tax#61,ss_net_profit#62,ss_sold_date_sk#63] parquet\n:  :  :  +- Aggregate [cast((avg(UnscaledValue(ss_list_price#75)) / 100.0) as decimal(11,6)) AS B3_LP#6, count(ss_list_price#75) AS B3_CNT#7L, count(distinct ss_list_price#75) AS B3_CNTD#8L]\n:  :  :     +- Project [ss_list_price#75]\n:  :  :        +- Filter (isnotnull(ss_quantity#73) AND (((ss_quantity#73 >= 11) AND (ss_quantity#73 <= 15)) AND ((((ss_list_price#75 >= 66.00) AND (ss_list_price#75 <= 76.00)) OR ((ss_coupon_amt#82 >= 920.00) AND (ss_coupon_amt#82 <= 1920.00))) OR ((ss_wholesale_cost#74 >= 4.00) AND (ss_wholesale_cost#74 <= 24.00)))))\n:  :  :           +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#64,ss_item_sk#65,ss_customer_sk#66,ss_cdemo_sk#67,ss_hdemo_sk#68,ss_addr_sk#69,ss_store_sk#70,ss_promo_sk#71,ss_ticket_number#72L,ss_quantity#73,ss_wholesale_cost#74,ss_list_price#75,ss_sales_price#76,ss_ext_discount_amt#77,ss_ext_sales_price#78,ss_ext_wholesale_cost#79,ss_ext_list_price#80,ss_ext_tax#81,ss_coupon_amt#82,ss_net_paid#83,ss_net_paid_inc_tax#84,ss_net_profit#85,ss_sold_date_sk#86] parquet\n:  :  +- Aggregate [cast((avg(UnscaledValue(ss_list_price#98)) / 100.0) as decimal(11,6)) AS B4_LP#9, count(ss_list_price#98) AS B4_CNT#10L, count(distinct ss_list_price#98) AS B4_CNTD#11L]\n:  :     +- Project [ss_list_price#98]\n:  :        +- Filter (isnotnull(ss_quantity#96) AND (((ss_quantity#96 >= 16) AND (ss_quantity#96 <= 20)) AND ((((ss_list_price#98 >= 142.00) AND (ss_list_price#98 <= 152.00)) OR ((ss_coupon_amt#105 >= 3054.00) AND (ss_coupon_amt#105 <= 4054.00))) OR ((ss_wholesale_cost#97 >= 80.00) AND (ss_wholesale_cost#97 <= 100.00)))))\n:  :           +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#87,ss_item_sk#88,ss_customer_sk#89,ss_cdemo_sk#90,ss_hdemo_sk#91,ss_addr_sk#92,ss_store_sk#93,ss_promo_sk#94,ss_ticket_number#95L,ss_quantity#96,ss_wholesale_cost#97,ss_list_price#98,ss_sales_price#99,ss_ext_discount_amt#100,ss_ext_sales_price#101,ss_ext_wholesale_cost#102,ss_ext_list_price#103,ss_ext_tax#104,ss_coupon_amt#105,ss_net_paid#106,ss_net_paid_inc_tax#107,ss_net_profit#108,ss_sold_date_sk#109] parquet\n:  +- Aggregate [cast((avg(UnscaledValue(ss_list_price#121)) / 100.0) as decimal(11,6)) AS B5_LP#12, count(ss_list_price#121) AS B5_CNT#13L, count(distinct ss_list_price#121) AS B5_CNTD#14L]\n:     +- Project [ss_list_price#121]\n:        +- Filter (isnotnull(ss_quantity#119) AND (((ss_quantity#119 >= 21) AND (ss_quantity#119 <= 25)) AND ((((ss_list_price#121 >= 135.00) AND (ss_list_price#121 <= 145.00)) OR ((ss_coupon_amt#128 >= 14180.00) AND (ss_coupon_amt#128 <= 15180.00))) OR ((ss_wholesale_cost#120 >= 38.00) AND (ss_wholesale_cost#120 <= 58.00)))))\n:           +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#110,ss_item_sk#111,ss_customer_sk#112,ss_cdemo_sk#113,ss_hdemo_sk#114,ss_addr_sk#115,ss_store_sk#116,ss_promo_sk#117,ss_ticket_number#118L,ss_quantity#119,ss_wholesale_cost#120,ss_list_price#121,ss_sales_price#122,ss_ext_discount_amt#123,ss_ext_sales_price#124,ss_ext_wholesale_cost#125,ss_ext_list_price#126,ss_ext_tax#127,ss_coupon_amt#128,ss_net_paid#129,ss_net_paid_inc_tax#130,ss_net_profit#131,ss_sold_date_sk#132] parquet\n+- Aggregate [cast((avg(UnscaledValue(ss_list_price#144)) / 100.0) as decimal(11,6)) AS B6_LP#15, count(ss_list_price#144) AS B6_CNT#16L, count(distinct ss_list_price#144) AS B6_CNTD#17L]\n   +- Project [ss_list_price#144]\n      +- Filter (isnotnull(ss_quantity#142) AND (((ss_quantity#142 >= 26) AND (ss_quantity#142 <= 30)) AND ((((ss_list_price#144 >= 28.00) AND (ss_list_price#144 <= 38.00)) OR ((ss_coupon_amt#151 >= 2513.00) AND (ss_coupon_amt#151 <= 3513.00))) OR ((ss_wholesale_cost#143 >= 42.00) AND (ss_wholesale_cost#143 <= 62.00)))))\n         +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#133,ss_item_sk#134,ss_customer_sk#135,ss_cdemo_sk#136,ss_hdemo_sk#137,ss_addr_sk#138,ss_store_sk#139,ss_promo_sk#140,ss_ticket_number#141L,ss_quantity#142,ss_wholesale_cost#143,ss_list_price#144,ss_sales_price#145,ss_ext_discount_amt#146,ss_ext_sales_price#147,ss_ext_wholesale_cost#148,ss_ext_list_price#149,ss_ext_tax#150,ss_coupon_amt#151,ss_net_paid#152,ss_net_paid_inc_tax#153,ss_net_profit#154,ss_sold_date_sk#155] parquet\n"
    },
    "IM" : {
      "inputSizeInBytes" : 262661825856,
      "inputRowCount" : 1728038328
    },
    "PD" : { },
    "Configuration" : {
      "theta_c" : [ {
        "spark.executor.memory" : "1g"
      }, {
        "spark.executor.cores" : "1"
      }, {
        "spark.executor.instances" : "16"
      }, {
        "spark.default.parallelism" : "16"
      }, {
        "spark.reducer.maxSizeInFlight" : "48m"
      }, {
        "spark.shuffle.sort.bypassMergeThreshold" : "200"
      }, {
        "spark.shuffle.compress" : "true"
      }, {
        "spark.memory.fraction" : "0.6"
      } ],
      "theta_p" : [ {
        "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
      }, {
        "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
      }, {
        "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
      }, {
        "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
      }, {
        "spark.sql.shuffle.partitions" : "200"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
      }, {
        "spark.sql.files.maxPartitionBytes" : "128MB"
      }, {
        "spark.sql.files.openCostInBytes" : "4MB"
      } ],
      "theta_s" : [ {
        "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
      }, {
        "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
      } ]
    }
  },
  "RuntimeLQPs" : {
    "12" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "5" : {
            "sign" : -811463019,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14 "
          },
          "6" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "1" : {
            "sign" : 391841115,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 128,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 1008267833,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 152,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 1995617573,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 104,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "3" : {
            "sign" : 262868704,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join Cross, BroadcastQueryStage 13 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- LogicalQueryStage Join Cross, BroadcastQueryStage 13\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 192,
        "inputRowCount" : 4
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 3,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226868253,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 7130,
        "IOBytes" : {
          "Total" : 2463020944,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 19216644,
            "SW" : 19216422
          }
        }
      }
    },
    "8" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -449665902,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 56,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : 1915343924,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : 682730074,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11 "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : -1627946789,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : -531951654,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 187752971397120,
            "rowCount" : 1466820089040,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : -464770376,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 222956653534080,
            "rowCount" : 1466820089040,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 1948380403,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 137925840,
            "rowCount" : 1326210,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : 429442485,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          },
          "3" : {
            "sign" : -727590668,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11\n:  :  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 97289512,
        "inputRowCount" : 2432238
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 6,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226868078,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 7305,
        "IOBytes" : {
          "Total" : 2501270233,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 57465785,
            "SW" : 19216570
          }
        }
      }
    },
    "4" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : 1635563970,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -323900714,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 54966576,
            "rowCount" : 981546,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : -519389093,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : -77505962,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]) "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : -1627946789,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 39261840,
            "rowCount" : 981546,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : 16460917,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 146335967740114560000,
            "rowCount" : 1143249747969645000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : -1021470419,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 173773961691386040000,
            "rowCount" : 1143249747969645000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : -1389142665,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 118897973788843080000,
            "rowCount" : 1143249747969645000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : 429442485,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          },
          "3" : {
            "sign" : -5493512,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 68963421960000,
            "rowCount" : 862042774500,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)])\n:  :  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n:  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 127440336,
        "inputRowCount" : 3186009
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 11,
        "FinishedTasksTotalTimeInMs" : 12108.0,
        "FinishedTasksDistributionInMs" : [ 542.0, 608.0, 867.0, 1054.0, 2751.0 ]
      },
      "StartTimeInMs" : 1702226858347,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 17036,
        "IOBytes" : {
          "Total" : 4989189693,
          "Details" : {
            "IR" : 4849175756,
            "IW" : 0,
            "SR" : 102982326,
            "SW" : 37031611
          }
        }
      }
    },
    "15" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "5" : {
            "sign" : -811463019,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14 "
          },
          "6" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 47700280,
            "rowCount" : 1192507,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "1" : {
            "sign" : 391841115,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 128,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 1008267833,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 181261064,
            "rowCount" : 1192507,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 1995617573,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 104,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "3" : {
            "sign" : 262868704,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join Cross, BroadcastQueryStage 13 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- LogicalQueryStage Join Cross, BroadcastQueryStage 13\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 47700432,
        "inputRowCount" : 1192510
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226874761,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 622,
        "IOBytes" : {
          "Total" : 19216570,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 19216496,
            "SW" : 74
          }
        }
      }
    },
    "11" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "5" : {
            "sign" : 1915343924,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "6" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "1" : {
            "sign" : 1905787514,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 169754880,
            "rowCount" : 1326210,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 713796282,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 201583920,
            "rowCount" : 1326210,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 1995617573,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 137925840,
            "rowCount" : 1326210,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "3" : {
            "sign" : 262868704,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join Cross, BroadcastQueryStage 13 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- LogicalQueryStage Join Cross, BroadcastQueryStage 13\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 53048552,
        "inputRowCount" : 1326213
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 3,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226868231,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 7152,
        "IOBytes" : {
          "Total" : 2463020944,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 19216644,
            "SW" : 19216422
          }
        }
      }
    },
    "9" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -449665902,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 56,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : 1915343924,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : 682730074,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11 "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : -1627946789,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : -1070335401,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 187752971397120,
            "rowCount" : 1466820089040,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 1894767451,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 222956653534080,
            "rowCount" : 1466820089040,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 909137136,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 137925840,
            "rowCount" : 1326210,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : -1578840872,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), BroadcastQueryStage 12 "
          },
          "3" : {
            "sign" : -939499177,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11\n:  :  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), BroadcastQueryStage 12\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 97289504,
        "inputRowCount" : 2432238
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 6,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226868179,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 7204,
        "IOBytes" : {
          "Total" : 2501270159,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 57465711,
            "SW" : 19216570
          }
        }
      }
    },
    "13" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "5" : {
            "sign" : -811463019,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14 "
          },
          "6" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "1" : {
            "sign" : 391841115,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 128,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 1008267833,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 152,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 1995617573,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 104,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "3" : {
            "sign" : 262868704,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join Cross, BroadcastQueryStage 13 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- LogicalQueryStage Join Cross, BroadcastQueryStage 13\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 184,
        "inputRowCount" : 4
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 4,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226868417,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 6966,
        "IOBytes" : {
          "Total" : 2463020870,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 19216570,
            "SW" : 19216422
          }
        }
      }
    },
    "16" : {
      "LQP" : {
        "operators" : {
          "0" : {
            "sign" : -2141114127,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 181261064,
            "rowCount" : 1192507,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "1" : {
            "sign" : 262868766,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 128,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join Cross, BroadcastQueryStage 15 "
          },
          "2" : {
            "sign" : 2091385604,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 47700280,
            "rowCount" : 1192507,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- LogicalQueryStage Join Cross, BroadcastQueryStage 15\n+- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 47700408,
        "inputRowCount" : 1192508
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226874892,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 491,
        "IOBytes" : {
          "Total" : 19216496,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 19216422,
            "SW" : 74
          }
        }
      }
    },
    "5" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -323900714,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 54966576,
            "rowCount" : 981546,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : -519389093,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : -77505962,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]) "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : -1627946789,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 39261840,
            "rowCount" : 981546,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : -529237635,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 161851092383792466109440000,
            "rowCount" : 1264461659248378641480000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 952504437,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 192198172205753553504960000,
            "rowCount" : 1264461659248378641480000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : -1203444305,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 118897973788843080000,
            "rowCount" : 1143249747969645000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : 429442485,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          },
          "3" : {
            "sign" : -5493512,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 68963421960000,
            "rowCount" : 862042774500,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)])\n:  :  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 171681264,
        "inputRowCount" : 4292032
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 3,
        "FinishedTasksTotalTimeInMs" : 1413.0,
        "FinishedTasksDistributionInMs" : [ 436.0, 436.0, 483.0, 494.0, 494.0 ]
      },
      "StartTimeInMs" : 1702226862946,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 12437,
        "IOBytes" : {
          "Total" : 2546786996,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 102982326,
            "SW" : 19216792
          }
        }
      }
    },
    "10" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -449665902,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 56,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : 1915343924,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : 682730074,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11 "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : -1627946789,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : -1070335401,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 187752971397120,
            "rowCount" : 1466820089040,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 1894767451,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 222956653534080,
            "rowCount" : 1466820089040,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 909137136,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 137925840,
            "rowCount" : 1326210,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : -1578840872,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), BroadcastQueryStage 12 "
          },
          "3" : {
            "sign" : -939499177,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11\n:  :  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), BroadcastQueryStage 12\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 97289496,
        "inputRowCount" : 2432238
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 5,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226868196,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 7187,
        "IOBytes" : {
          "Total" : 2501270085,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 57465637,
            "SW" : 19216570
          }
        }
      }
    },
    "6" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -323900714,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 54966576,
            "rowCount" : 981546,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : 1915343924,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : -77505962,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]) "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : -1627946789,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 39261840,
            "rowCount" : 981546,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : 602302166,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 161851092383792466109440000,
            "rowCount" : 1264461659248378641480000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : -555611908,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 192198172205753553504960000,
            "rowCount" : 1264461659248378641480000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : -1203444305,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 118897973788843080000,
            "rowCount" : 1143249747969645000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : 429442485,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          },
          "3" : {
            "sign" : -5493512,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 68963421960000,
            "rowCount" : 862042774500,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)])\n:  :  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 171681272,
        "inputRowCount" : 4292032
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 7,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226867993,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 7390,
        "IOBytes" : {
          "Total" : 2532844465,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 89039869,
            "SW" : 19216718
          }
        }
      }
    },
    "1" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : 1635563970,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -1204640363,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 44863392,
            "rowCount" : 801132,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : -519389093,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : -77505962,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32045280,
            "rowCount" : 801132,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]) "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : 1997195226,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : -164398869,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 102544896,
            "rowCount" : 801132,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : -464298859,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 121772064,
            "rowCount" : 801132,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : -893022513,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 83317728,
            "rowCount" : 801132,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : 424799646,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          },
          "3" : {
            "sign" : 624390274,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 64090560,
            "rowCount" : 801132,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)])\n:  :  :  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n:  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 32045440,
        "inputRowCount" : 801137
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 165,
        "FinishedTasksTotalTimeInMs" : 131827.0,
        "FinishedTasksDistributionInMs" : [ 168.0, 387.0, 460.0, 686.0, 5825.0 ]
      },
      "StartTimeInMs" : 1702226843110,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 32273,
        "IOBytes" : {
          "Total" : 12314961585,
          "Details" : {
            "IR" : 12122939390,
            "IW" : 0,
            "SR" : 102982326,
            "SW" : 89039869
          }
        }
      }
    },
    "17" : {
      "LQP" : {
        "operators" : {
          "0" : {
            "sign" : -2141114127,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 152,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "1" : {
            "sign" : 262868766,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 128,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join Cross, BroadcastQueryStage 15 "
          },
          "2" : {
            "sign" : 2091385604,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- LogicalQueryStage Join Cross, BroadcastQueryStage 15\n+- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 168,
        "inputRowCount" : 2
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226875250,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 133,
        "IOBytes" : {
          "Total" : 74,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 74,
            "SW" : 0
          }
        }
      }
    },
    "14" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "5" : {
            "sign" : -811463019,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14 "
          },
          "6" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "1" : {
            "sign" : 391841115,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 128,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 1008267833,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 152,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 1995617573,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 104,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "3" : {
            "sign" : 262868704,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join Cross, BroadcastQueryStage 13 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- LogicalQueryStage Join Cross, BroadcastQueryStage 13\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 184,
        "inputRowCount" : 4
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 3,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226868453,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 6930,
        "IOBytes" : {
          "Total" : 2463020796,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 19216496,
            "SW" : 19216422
          }
        }
      }
    },
    "2" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : 1635563970,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -1204640363,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 56,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : -519389093,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : -77505962,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]) "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : 1997195226,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : -164398869,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 112416000,
            "rowCount" : 878250,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : -464298859,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 133494000,
            "rowCount" : 878250,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : -893022513,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 91338000,
            "rowCount" : 878250,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : 424799646,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          },
          "3" : {
            "sign" : 624390274,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 70260000,
            "rowCount" : 878250,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)])\n:  :  :  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n:  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 35130160,
        "inputRowCount" : 878255
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 209,
        "FinishedTasksTotalTimeInMs" : 191935.0,
        "FinishedTasksDistributionInMs" : [ 168.0, 366.0, 441.0, 603.0, 12439.0 ]
      },
      "StartTimeInMs" : 1702226852703,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 22680,
        "IOBytes" : {
          "Total" : 9875338911,
          "Details" : {
            "IR" : 9698351512,
            "IW" : 0,
            "SR" : 102982326,
            "SW" : 74005073
          }
        }
      }
    },
    "7" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -449665902,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 56,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : 1915343924,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : 682730074,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11 "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : -1627946789,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : -531951654,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 164894047129520640000,
            "rowCount" : 1288234743199380000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : -464770376,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 195811680966305760000,
            "rowCount" : 1288234743199380000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 1948380403,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 121133368980000,
            "rowCount" : 1164743932500,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : 429442485,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          },
          "3" : {
            "sign" : -727590668,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 70260000,
            "rowCount" : 878250,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11\n:  :  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 132419472,
        "inputRowCount" : 3310487
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 6,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "StartTimeInMs" : 1702226868070,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 7313,
        "IOBytes" : {
          "Total" : 2501270233,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 57465785,
            "SW" : 19216570
          }
        }
      }
    },
    "3" : {
      "LQP" : {
        "operators" : {
          "8" : {
            "sign" : 1635563970,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          },
          "4" : {
            "sign" : -1204640363,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 54966576,
            "rowCount" : 981546,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "9" : {
            "sign" : -519389093,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          },
          "5" : {
            "sign" : -77505962,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]) "
          },
          "10" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          },
          "6" : {
            "sign" : 1997195226,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 39261840,
            "rowCount" : 981546,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          },
          "1" : {
            "sign" : -492787276,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 110341475136000,
            "rowCount" : 862042774500,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : -282151444,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 131030501724000,
            "rowCount" : 862042774500,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : -731473832,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 89652448548000,
            "rowCount" : 862042774500,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "7" : {
            "sign" : 429442485,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          },
          "3" : {
            "sign" : -1573882983,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 68963421960000,
            "rowCount" : 862042774500,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "LogicalQueryStage",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- Join Cross\n:  :  :  :- Join Cross\n:  :  :  :  :- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)])\n:  :  :  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n:  :  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n:  :  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 74391968,
        "inputRowCount" : 1859800
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 50,
        "FinishedTasksTotalTimeInMs" : 30124.0,
        "FinishedTasksDistributionInMs" : [ 276.0, 323.0, 380.0, 488.0, 3128.0 ]
      },
      "StartTimeInMs" : 1702226852771,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 22612,
        "IOBytes" : {
          "Total" : 7434211745,
          "Details" : {
            "IR" : 7273763634,
            "IW" : 0,
            "SR" : 102982326,
            "SW" : 57465785
          }
        }
      }
    }
  },
  "RuntimeQSs" : {
    "12" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 429442485,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 40,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 35130000,
                "rowCount" : 878250
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1025903347,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [sum#394, count#395L, count#397L, count#400L] Keys: [] Functions [3]: [avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#250))#342, count(ss_list_price#250)#343L, count(ss_list_price#250)#344L] Results [3]: [cast((avg(UnscaledValue(ss_list_price#250))#342 / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250)#343L AS B3_CNT#205L, count(ss_list_price#250)#344L AS B3_CNTD#206L] "
          },
          "1" : {
            "sign" : 970686787,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [sum#394, count#395L, count#397L, count#400L] Arguments: 7 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "ShuffleQueryStage",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)], output=[B3_LP#204, B3_CNT#205L, B3_CNTD#206L])\n+- ShuffleQueryStage 7\n   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=639]\n      +- *(8) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250), partial_count(distinct ss_list_price#250)], output=[sum#394, count#395L, count#397L, count#400L])\n         +- *(8) HashAggregate(keys=[ss_list_price#250], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n            +- AQEShuffleRead coalesced\n               +- ShuffleQueryStage 2\n                  +- Exchange hashpartitioning(ss_list_price#250, 200), ENSURE_REQUIREMENTS, [plan_id=317]\n                     +- *(3) HashAggregate(keys=[ss_list_price#250], functions=[partial_avg(UnscaledValue(ss_list_price#250)), partial_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n                        +- *(3) Project [ss_list_price#250]\n                           +- *(3) Filter (((isnotnull(ss_quantity#248) AND (ss_quantity#248 >= 11)) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00))))\n                              +- *(3) ColumnarToRow\n                                 +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#248,ss_wholesale_cost#249,ss_list_price#250,ss_coupon_amt#257,ss_sold_date_sk#261] Batched: true, DataFilters: [isnotnull(ss_quantity#248), (ss_quantity#248 >= 11), (ss_quantity#248 <= 15), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,11), LessThanOrEqual(ss_quantity,15), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 40,
        "inputRowCount" : 1
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "7" : [ 80 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 6,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "QueryStageOptimizationId" : 12,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 22 ],
      "Objectives" : {
        "DurationInMs" : 44,
        "TotalTasksDurationInMs" : 39,
        "IOBytes" : {
          "Total" : 74,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 74,
            "SW" : 0
          }
        }
      }
    },
    "8" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1997195226,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 39261840,
                "rowCount" : 981546
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1193000680,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 39261840,
            "rowCount" : 981546,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#227, sum#384, count#385L, count#387L] Keys: [] Functions [3]: [merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227), partial_count(distinct ss_list_price#227)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#227))#339, count(ss_list_price#227)#340L, count(ss_list_price#227)#341L] Results [4]: [sum#384, count#385L, count#387L, count#390L] "
          },
          "1" : {
            "sign" : 901622543,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 39261840,
            "rowCount" : 981546,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#227, sum#384, count#385L, count#387L] Keys [1]: [ss_list_price#227] Functions [2]: [merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#227))#339, count(ss_list_price#227)#340L] Results [4]: [ss_list_price#227, sum#384, count#385L, count#387L] "
          },
          "2" : {
            "sign" : -947159509,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [ss_list_price#227, sum#384, count#385L, count#387L] Arguments: 1 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "ShuffleQueryStage",
          "toId" : 1,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227), partial_count(distinct ss_list_price#227)], output=[sum#384, count#385L, count#387L, count#390L])\n+- HashAggregate(keys=[ss_list_price#227], functions=[merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n   +- ShuffleQueryStage 1\n      +- Exchange hashpartitioning(ss_list_price#227, 200), ENSURE_REQUIREMENTS, [plan_id=270]\n         +- *(2) HashAggregate(keys=[ss_list_price#227], functions=[partial_avg(UnscaledValue(ss_list_price#227)), partial_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n            +- *(2) Project [ss_list_price#227]\n               +- *(2) Filter (((isnotnull(ss_quantity#225) AND (ss_quantity#225 >= 6)) AND (ss_quantity#225 <= 10)) AND ((((ss_list_price#227 >= 91.00) AND (ss_list_price#227 <= 101.00)) OR ((ss_coupon_amt#234 >= 1430.00) AND (ss_coupon_amt#234 <= 2430.00))) OR ((ss_wholesale_cost#226 >= 32.00) AND (ss_wholesale_cost#226 <= 52.00))))\n                  +- *(2) ColumnarToRow\n                     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#225,ss_wholesale_cost#226,ss_list_price#227,ss_coupon_amt#234,ss_sold_date_sk#238] Batched: true, DataFilters: [isnotnull(ss_quantity#225), (ss_quantity#225 >= 6), (ss_quantity#225 <= 10), ((((ss_list_price#2..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,6), LessThanOrEqual(ss_quantity,10), Or(O..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 39261840,
        "inputRowCount" : 981546
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "1" : [ 64196, 71247, 76372, 81605, 87099, 77687, 92336, 77749, 88437, 93218, 74176, 99997, 99597, 97214, 75890, 85356, 91906, 74167, 65752, 91122, 98635, 100355, 75012, 97540, 88786, 94036, 93869, 77521, 92292, 80770, 83236, 96359, 97196, 91851, 68938, 98710, 76422, 86752, 97878, 88901, 74479, 76846, 83016, 95173, 96401, 85050, 88192, 87126, 94128, 90334, 81186, 81130, 74184, 91063, 84629, 99843, 105395, 75714, 87852, 79945, 97954, 78022, 90381, 88081, 97104, 87534, 89655, 84855, 80805, 94727, 77999, 97914, 63510, 68170, 79541, 80230, 93015, 70468, 108779, 74877, 76923, 97903, 89280, 85264, 78477, 93751, 80167, 87864, 87626, 94002, 90978, 87727, 78546, 86822, 83973, 70940, 85345, 66016, 100461, 87335, 59333, 106151, 86890, 69296, 92102, 93212, 105316, 96468, 98114, 90598, 84968, 86987, 70500, 90270, 95036, 83984, 80824, 87869, 105946, 61964, 89877, 91800, 73371, 66241, 120093, 84061, 86036, 106581, 110657, 92846, 82730, 106194, 77692, 99783, 81430, 83684, 82226, 81451, 103073, 85560, 89855, 81085, 86001, 89435, 80530, 83674, 93820, 94570, 94913, 97953, 95213, 82485, 66775, 93137, 99404, 91913, 89963, 93921, 89823, 73643, 82111, 68076, 79048, 83604, 79186, 79507, 72298, 90921, 91934, 93604, 83826, 94074, 67447, 89806, 99915, 97823, 105589, 111326, 89145, 86202, 88479, 84705, 91279, 79671, 80329, 57518, 84884, 83036, 108376, 95662, 94893, 82558, 83029, 89120, 69541, 91785, 76422, 72155, 81000, 83463 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 50,
        "FinishedTasksTotalTimeInMs" : 30124.0,
        "FinishedTasksDistributionInMs" : [ 276.0, 323.0, 380.0, 488.0, 3128.0 ]
      },
      "QueryStageOptimizationId" : 8,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 12 ],
      "Objectives" : {
        "DurationInMs" : 15208,
        "TotalTasksDurationInMs" : 604,
        "IOBytes" : {
          "Total" : 16539362,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 16539288,
            "SW" : 74
          }
        }
      }
    },
    "4" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1599458891,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L] "
          },
          "1" : {
            "sign" : -2011735735,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 104837776,
                "rowCount" : 6552361
              },
              "compileTime" : {
                "sizeInBytes" : 104837776,
                "rowCount" : 6552361
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_list_price#296] "
          },
          "2" : {
            "sign" : -2136210255,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 995958872,
                "rowCount" : 6552361
              },
              "compileTime" : {
                "sizeInBytes" : 995958872,
                "rowCount" : 6552361
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#294) AND (((ss_quantity#294 >= 21) AND (ss_quantity#294 <= 25)) AND ((((ss_list_price#296 >= 135.00) AND (ss_list_price#296 <= 145.00)) OR ((ss_coupon_amt#303 >= 14180.00) AND (ss_coupon_amt#303 <= 15180.00))) OR ((ss_wholesale_cost#295 >= 38.00) AND (ss_wholesale_cost#295 <= 58.00))))) "
          },
          "3" : {
            "sign" : 1996827814,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              },
              "compileTime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#285, ss_item_sk#286, ss_customer_sk#287, ss_cdemo_sk#288, ss_hdemo_sk#289, ss_addr_sk#290, ss_store_sk#291, ss_promo_sk#292, ss_ticket_number#293L, ss_quantity#294, ss_wholesale_cost#295, ss_list_price#296, ss_sales_price#297, ss_ext_discount_amt#298, ss_ext_sales_price#299, ss_ext_wholesale_cost#300, ss_ext_list_price#301, ss_ext_tax#302, ss_coupon_amt#303, ss_net_paid#304, ss_net_paid_inc_tax#305, ss_net_profit#306, ss_sold_date_sk#307], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalRelation",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L]\n+- Project [ss_list_price#296]\n   +- Filter (isnotnull(ss_quantity#294) AND (((ss_quantity#294 >= 21) AND (ss_quantity#294 <= 25)) AND ((((ss_list_price#296 >= 135.00) AND (ss_list_price#296 <= 145.00)) OR ((ss_coupon_amt#303 >= 14180.00) AND (ss_coupon_amt#303 <= 15180.00))) OR ((ss_wholesale_cost#295 >= 38.00) AND (ss_wholesale_cost#295 <= 58.00)))))\n      +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#285,ss_item_sk#286,ss_customer_sk#287,ss_cdemo_sk#288,ss_hdemo_sk#289,ss_addr_sk#290,ss_store_sk#291,ss_promo_sk#292,ss_ticket_number#293L,ss_quantity#294,ss_wholesale_cost#295,ss_list_price#296,ss_sales_price#297,ss_ext_discount_amt#298,ss_ext_sales_price#299,ss_ext_wholesale_cost#300,ss_ext_list_price#301,ss_ext_tax#302,ss_coupon_amt#303,ss_net_paid#304,ss_net_paid_inc_tax#305,ss_net_profit#306,ss_sold_date_sk#307] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1384143529,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [1]: [ss_list_price#296] Keys [1]: [ss_list_price#296] Functions [2]: [partial_avg(UnscaledValue(ss_list_price#296)), partial_count(ss_list_price#296)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#296))#348, count(ss_list_price#296)#349L] Results [4]: [ss_list_price#296, sum#414, count#415L, count#417L] "
          },
          "1" : {
            "sign" : -1170220849,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 104837776,
            "rowCount" : 6552361,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [ss_list_price#296] Input [5]: [ss_quantity#294, ss_wholesale_cost#295, ss_list_price#296, ss_coupon_amt#303, ss_sold_date_sk#307] "
          },
          "2" : {
            "sign" : 2064153723,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 104837776,
            "rowCount" : 6552361,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [5]: [ss_quantity#294, ss_wholesale_cost#295, ss_list_price#296, ss_coupon_amt#303, ss_sold_date_sk#307] Condition : (((isnotnull(ss_quantity#294) AND (ss_quantity#294 >= 21)) AND (ss_quantity#294 <= 25)) AND ((((ss_list_price#296 >= 135.00) AND (ss_list_price#296 <= 145.00)) OR ((ss_coupon_amt#303 >= 14180.00) AND (ss_coupon_amt#303 <= 15180.00))) OR ((ss_wholesale_cost#295 >= 38.00) AND (ss_wholesale_cost#295 <= 58.00)))) "
          },
          "3" : {
            "sign" : 12824302,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 104837776,
            "rowCount" : 6552361,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [5]: [ss_quantity#294, ss_wholesale_cost#295, ss_list_price#296, ss_coupon_amt#303, ss_sold_date_sk#307] Batched: true Location: CatalogFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales] PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,25), Or(Or(And(GreaterThanOrEqual(ss_list_price,135.00),LessThanOrEqual(ss_list_price,145.00)),And(GreaterThanOrEqual(ss_coupon_amt,14180.00),LessThanOrEqual(ss_coupon_amt,15180.00))),And(GreaterThanOrEqual(ss_wholesale_cost,38.00),LessThanOrEqual(ss_wholesale_cost,58.00)))] ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:decimal(7,2)> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[ss_list_price#296], functions=[partial_avg(UnscaledValue(ss_list_price#296)), partial_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n+- Project [ss_list_price#296]\n   +- Filter (((isnotnull(ss_quantity#294) AND (ss_quantity#294 >= 21)) AND (ss_quantity#294 <= 25)) AND ((((ss_list_price#296 >= 135.00) AND (ss_list_price#296 <= 145.00)) OR ((ss_coupon_amt#303 >= 14180.00) AND (ss_coupon_amt#303 <= 15180.00))) OR ((ss_wholesale_cost#295 >= 38.00) AND (ss_wholesale_cost#295 <= 58.00))))\n      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#294,ss_wholesale_cost#295,ss_list_price#296,ss_coupon_amt#303,ss_sold_date_sk#307] Batched: true, DataFilters: [isnotnull(ss_quantity#294), (ss_quantity#294 >= 21), (ss_quantity#294 <= 25), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,25), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 104837776,
        "inputRowCount" : 6552361
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 4,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 5 ],
      "Objectives" : {
        "DurationInMs" : 44175,
        "TotalTasksDurationInMs" : 107658,
        "IOBytes" : {
          "Total" : 2442402697,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 0,
            "SW" : 17814819
          }
        }
      }
    },
    "15" : {
      "QSLogical" : {
        "operators" : {
          "4" : {
            "sign" : -811463019,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 40,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14 "
          },
          "1" : {
            "sign" : 1995617573,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 104,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 104,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "0" : {
            "sign" : 391841115,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 128,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 128,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 262868704,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 80,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 80,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join Cross, BroadcastQueryStage 13 "
          },
          "3" : {
            "sign" : -1602258374,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 40,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 53048400,
                "rowCount" : 1326210
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "LogicalQueryStage",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- LogicalQueryStage Join Cross, BroadcastQueryStage 13\n:  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n+- LogicalQueryStage LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : -1634139585,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [sum#404, count#405L, count#407L, count#410L] Arguments: 9 "
          },
          "5" : {
            "sign" : -563251782,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [3]: [B5_LP#210, B5_CNT#211L, B5_CNTD#212L] Arguments: 14 "
          },
          "1" : {
            "sign" : -209089084,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastNestedLoopJoinExec",
            "sizeInBytes" : 104,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastNestedLoopJoin Join type: Cross Join condition: None "
          },
          "0" : {
            "sign" : 439500573,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastNestedLoopJoinExec",
            "sizeInBytes" : 128,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastNestedLoopJoin Join type: Cross Join condition: None "
          },
          "2" : {
            "sign" : 862268782,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [9]: [B1_LP#198, B1_CNT#199L, B1_CNTD#200L, B2_LP#201, B2_CNT#202L, B2_CNTD#203L, B3_LP#204, B3_CNT#205L, B3_CNTD#206L] Arguments: 13 "
          },
          "3" : {
            "sign" : 192272530,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [sum#404, count#405L, count#407L, count#410L] Keys: [] Functions [3]: [avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#273))#345, count(ss_list_price#273)#346L, count(ss_list_price#273)#347L] Results [3]: [cast((avg(UnscaledValue(ss_list_price#273))#345 / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273)#346L AS B4_CNT#208L, count(ss_list_price#273)#347L AS B4_CNTD#209L] "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "BroadcastQueryStage",
          "toId" : 1,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "ShuffleQueryStage",
          "toId" : 3,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "HashAggregate",
          "toId" : 1,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "BroadcastNestedLoopJoin",
          "toId" : 0,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "BroadcastQueryStage",
          "toId" : 0,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "BroadcastNestedLoopJoin BuildRight, Cross\n:- BroadcastNestedLoopJoin BuildLeft, Cross\n:  :- BroadcastQueryStage 13\n:  :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=1058]\n:  :     +- *(14) BroadcastNestedLoopJoin BuildRight, Cross\n:  :        :- *(14) BroadcastNestedLoopJoin BuildLeft, Cross\n:  :        :  :- BroadcastQueryStage 11\n:  :        :  :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=878]\n:  :        :  :     +- *(12) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)], output=[B1_LP#198, B1_CNT#199L, B1_CNTD#200L])\n:  :        :  :        +- ShuffleQueryStage 6\n:  :        :  :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=530]\n:  :        :  :              +- *(7) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29), partial_count(distinct ss_list_price#29)], output=[sum#374, count#375L, count#377L, count#380L])\n:  :        :  :                 +- *(7) HashAggregate(keys=[ss_list_price#29], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n:  :        :  :                    +- AQEShuffleRead coalesced\n:  :        :  :                       +- ShuffleQueryStage 0\n:  :        :  :                          +- Exchange hashpartitioning(ss_list_price#29, 200), ENSURE_REQUIREMENTS, [plan_id=225]\n:  :        :  :                             +- *(1) HashAggregate(keys=[ss_list_price#29], functions=[partial_avg(UnscaledValue(ss_list_price#29)), partial_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n:  :        :  :                                +- *(1) Project [ss_list_price#29]\n:  :        :  :                                   +- *(1) Filter (((isnotnull(ss_quantity#27) AND (ss_quantity#27 >= 0)) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00))))\n:  :        :  :                                      +- *(1) ColumnarToRow\n:  :        :  :                                         +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#27,ss_wholesale_cost#28,ss_list_price#29,ss_coupon_amt#36,ss_sold_date_sk#40] Batched: true, DataFilters: [isnotnull(ss_quantity#27), (ss_quantity#27 >= 0), (ss_quantity#27 <= 5), ((((ss_list_price#29 >=..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,0), LessThanOrEqual(ss_quantity,5), Or(Or..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n:  :        :  +- *(14) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)], output=[B2_LP#201, B2_CNT#202L, B2_CNTD#203L])\n:  :        :     +- ShuffleQueryStage 8\n:  :        :        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=704]\n:  :        :           +- *(9) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227), partial_count(distinct ss_list_price#227)], output=[sum#384, count#385L, count#387L, count#390L])\n:  :        :              +- *(9) HashAggregate(keys=[ss_list_price#227], functions=[merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n:  :        :                 +- AQEShuffleRead coalesced\n:  :        :                    +- ShuffleQueryStage 1\n:  :        :                       +- Exchange hashpartitioning(ss_list_price#227, 200), ENSURE_REQUIREMENTS, [plan_id=270]\n:  :        :                          +- *(2) HashAggregate(keys=[ss_list_price#227], functions=[partial_avg(UnscaledValue(ss_list_price#227)), partial_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n:  :        :                             +- *(2) Project [ss_list_price#227]\n:  :        :                                +- *(2) Filter (((isnotnull(ss_quantity#225) AND (ss_quantity#225 >= 6)) AND (ss_quantity#225 <= 10)) AND ((((ss_list_price#227 >= 91.00) AND (ss_list_price#227 <= 101.00)) OR ((ss_coupon_amt#234 >= 1430.00) AND (ss_coupon_amt#234 <= 2430.00))) OR ((ss_wholesale_cost#226 >= 32.00) AND (ss_wholesale_cost#226 <= 52.00))))\n:  :        :                                   +- *(2) ColumnarToRow\n:  :        :                                      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#225,ss_wholesale_cost#226,ss_list_price#227,ss_coupon_amt#234,ss_sold_date_sk#238] Batched: true, DataFilters: [isnotnull(ss_quantity#225), (ss_quantity#225 >= 6), (ss_quantity#225 <= 10), ((((ss_list_price#2..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,6), LessThanOrEqual(ss_quantity,10), Or(O..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n:  :        +- BroadcastQueryStage 12\n:  :           +- BroadcastExchange IdentityBroadcastMode, [plan_id=972]\n:  :              +- *(13) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)], output=[B3_LP#204, B3_CNT#205L, B3_CNTD#206L])\n:  :                 +- ShuffleQueryStage 7\n:  :                    +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=639]\n:  :                       +- *(8) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250), partial_count(distinct ss_list_price#250)], output=[sum#394, count#395L, count#397L, count#400L])\n:  :                          +- *(8) HashAggregate(keys=[ss_list_price#250], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n:  :                             +- AQEShuffleRead coalesced\n:  :                                +- ShuffleQueryStage 2\n:  :                                   +- Exchange hashpartitioning(ss_list_price#250, 200), ENSURE_REQUIREMENTS, [plan_id=317]\n:  :                                      +- *(3) HashAggregate(keys=[ss_list_price#250], functions=[partial_avg(UnscaledValue(ss_list_price#250)), partial_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n:  :                                         +- *(3) Project [ss_list_price#250]\n:  :                                            +- *(3) Filter (((isnotnull(ss_quantity#248) AND (ss_quantity#248 >= 11)) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00))))\n:  :                                               +- *(3) ColumnarToRow\n:  :                                                  +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#248,ss_wholesale_cost#249,ss_list_price#250,ss_coupon_amt#257,ss_sold_date_sk#261] Batched: true, DataFilters: [isnotnull(ss_quantity#248), (ss_quantity#248 >= 11), (ss_quantity#248 <= 15), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,11), LessThanOrEqual(ss_quantity,15), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n:  +- HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)], output=[B4_LP#207, B4_CNT#208L, B4_CNTD#209L])\n:     +- ShuffleQueryStage 9\n:        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=768]\n:           +- *(10) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#273)), merge_count(ss_list_price#273), partial_count(distinct ss_list_price#273)], output=[sum#404, count#405L, count#407L, count#410L])\n:              +- *(10) HashAggregate(keys=[ss_list_price#273], functions=[merge_avg(UnscaledValue(ss_list_price#273)), merge_count(ss_list_price#273)], output=[ss_list_price#273, sum#404, count#405L, count#407L])\n:                 +- AQEShuffleRead coalesced\n:                    +- ShuffleQueryStage 3\n:                       +- Exchange hashpartitioning(ss_list_price#273, 200), ENSURE_REQUIREMENTS, [plan_id=364]\n:                          +- *(4) HashAggregate(keys=[ss_list_price#273], functions=[partial_avg(UnscaledValue(ss_list_price#273)), partial_count(ss_list_price#273)], output=[ss_list_price#273, sum#404, count#405L, count#407L])\n:                             +- *(4) Project [ss_list_price#273]\n:                                +- *(4) Filter (((isnotnull(ss_quantity#271) AND (ss_quantity#271 >= 16)) AND (ss_quantity#271 <= 20)) AND ((((ss_list_price#273 >= 142.00) AND (ss_list_price#273 <= 152.00)) OR ((ss_coupon_amt#280 >= 3054.00) AND (ss_coupon_amt#280 <= 4054.00))) OR ((ss_wholesale_cost#272 >= 80.00) AND (ss_wholesale_cost#272 <= 100.00))))\n:                                   +- *(4) ColumnarToRow\n:                                      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#271,ss_wholesale_cost#272,ss_list_price#273,ss_coupon_amt#280,ss_sold_date_sk#284] Batched: true, DataFilters: [isnotnull(ss_quantity#271), (ss_quantity#271 >= 16), (ss_quantity#271 <= 20), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,16), LessThanOrEqual(ss_quantity,20), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n+- BroadcastQueryStage 14\n   +- BroadcastExchange IdentityBroadcastMode, [plan_id=1099]\n      +- *(15) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)], output=[B5_LP#210, B5_CNT#211L, B5_CNTD#212L])\n         +- ShuffleQueryStage 10\n            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=827]\n               +- *(11) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296), partial_count(distinct ss_list_price#296)], output=[sum#414, count#415L, count#417L, count#420L])\n                  +- *(11) HashAggregate(keys=[ss_list_price#296], functions=[merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n                     +- AQEShuffleRead coalesced\n                        +- ShuffleQueryStage 4\n                           +- Exchange hashpartitioning(ss_list_price#296, 200), ENSURE_REQUIREMENTS, [plan_id=411]\n                              +- *(5) HashAggregate(keys=[ss_list_price#296], functions=[partial_avg(UnscaledValue(ss_list_price#296)), partial_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n                                 +- *(5) Project [ss_list_price#296]\n                                    +- *(5) Filter (((isnotnull(ss_quantity#294) AND (ss_quantity#294 >= 21)) AND (ss_quantity#294 <= 25)) AND ((((ss_list_price#296 >= 135.00) AND (ss_list_price#296 <= 145.00)) OR ((ss_coupon_amt#303 >= 14180.00) AND (ss_coupon_amt#303 <= 15180.00))) OR ((ss_wholesale_cost#295 >= 38.00) AND (ss_wholesale_cost#295 <= 58.00))))\n                                       +- *(5) ColumnarToRow\n                                          +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#294,ss_wholesale_cost#295,ss_list_price#296,ss_coupon_amt#303,ss_sold_date_sk#307] Batched: true, DataFilters: [isnotnull(ss_quantity#294), (ss_quantity#294 >= 21), (ss_quantity#294 <= 25), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,25), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 152,
        "inputRowCount" : 3
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "9" : [ 80 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 15,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 31 ],
      "Objectives" : {
        "DurationInMs" : 71,
        "TotalTasksDurationInMs" : 65,
        "IOBytes" : {
          "Total" : 74,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 74,
            "SW" : 0
          }
        }
      }
    },
    "11" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -77505962,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 40,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 333133377,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [sum#374, count#375L, count#377L, count#380L] Keys: [] Functions [3]: [avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#29))#336, count(ss_list_price#29)#337L, count(ss_list_price#29)#338L] Results [3]: [cast((avg(UnscaledValue(ss_list_price#29))#336 / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29)#337L AS B1_CNT#199L, count(ss_list_price#29)#338L AS B1_CNTD#200L] "
          },
          "1" : {
            "sign" : 1613536479,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [sum#374, count#375L, count#377L, count#380L] Arguments: 6 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "ShuffleQueryStage",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)], output=[B1_LP#198, B1_CNT#199L, B1_CNTD#200L])\n+- ShuffleQueryStage 6\n   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=530]\n      +- *(7) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29), partial_count(distinct ss_list_price#29)], output=[sum#374, count#375L, count#377L, count#380L])\n         +- *(7) HashAggregate(keys=[ss_list_price#29], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n            +- AQEShuffleRead coalesced\n               +- ShuffleQueryStage 0\n                  +- Exchange hashpartitioning(ss_list_price#29, 200), ENSURE_REQUIREMENTS, [plan_id=225]\n                     +- *(1) HashAggregate(keys=[ss_list_price#29], functions=[partial_avg(UnscaledValue(ss_list_price#29)), partial_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n                        +- *(1) Project [ss_list_price#29]\n                           +- *(1) Filter (((isnotnull(ss_quantity#27) AND (ss_quantity#27 >= 0)) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00))))\n                              +- *(1) ColumnarToRow\n                                 +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#27,ss_wholesale_cost#28,ss_list_price#29,ss_coupon_amt#36,ss_sold_date_sk#40] Batched: true, DataFilters: [isnotnull(ss_quantity#27), (ss_quantity#27 >= 0), (ss_quantity#27 <= 5), ((((ss_list_price#29 >=..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,0), LessThanOrEqual(ss_quantity,5), Or(Or..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 40,
        "inputRowCount" : 1
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "6" : [ 80 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 7,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "QueryStageOptimizationId" : 11,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 19 ],
      "Objectives" : {
        "DurationInMs" : 141,
        "TotalTasksDurationInMs" : 135,
        "IOBytes" : {
          "Total" : 74,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 74,
            "SW" : 0
          }
        }
      }
    },
    "9" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1635563970,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 53048400,
                "rowCount" : 1326210
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 609747801,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#273, sum#404, count#405L, count#407L] Keys: [] Functions [3]: [merge_avg(UnscaledValue(ss_list_price#273)), merge_count(ss_list_price#273), partial_count(distinct ss_list_price#273)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#273))#345, count(ss_list_price#273)#346L, count(ss_list_price#273)#347L] Results [4]: [sum#404, count#405L, count#407L, count#410L] "
          },
          "1" : {
            "sign" : -616450683,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 53048400,
            "rowCount" : 1326210,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#273, sum#404, count#405L, count#407L] Keys [1]: [ss_list_price#273] Functions [2]: [merge_avg(UnscaledValue(ss_list_price#273)), merge_count(ss_list_price#273)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#273))#345, count(ss_list_price#273)#346L] Results [4]: [ss_list_price#273, sum#404, count#405L, count#407L] "
          },
          "2" : {
            "sign" : 1661503494,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [ss_list_price#273, sum#404, count#405L, count#407L] Arguments: 3 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "ShuffleQueryStage",
          "toId" : 1,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#273)), merge_count(ss_list_price#273), partial_count(distinct ss_list_price#273)], output=[sum#404, count#405L, count#407L, count#410L])\n+- HashAggregate(keys=[ss_list_price#273], functions=[merge_avg(UnscaledValue(ss_list_price#273)), merge_count(ss_list_price#273)], output=[ss_list_price#273, sum#404, count#405L, count#407L])\n   +- ShuffleQueryStage 3\n      +- Exchange hashpartitioning(ss_list_price#273, 200), ENSURE_REQUIREMENTS, [plan_id=364]\n         +- *(4) HashAggregate(keys=[ss_list_price#273], functions=[partial_avg(UnscaledValue(ss_list_price#273)), partial_count(ss_list_price#273)], output=[ss_list_price#273, sum#404, count#405L, count#407L])\n            +- *(4) Project [ss_list_price#273]\n               +- *(4) Filter (((isnotnull(ss_quantity#271) AND (ss_quantity#271 >= 16)) AND (ss_quantity#271 <= 20)) AND ((((ss_list_price#273 >= 142.00) AND (ss_list_price#273 <= 152.00)) OR ((ss_coupon_amt#280 >= 3054.00) AND (ss_coupon_amt#280 <= 4054.00))) OR ((ss_wholesale_cost#272 >= 80.00) AND (ss_wholesale_cost#272 <= 100.00))))\n                  +- *(4) ColumnarToRow\n                     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#271,ss_wholesale_cost#272,ss_list_price#273,ss_coupon_amt#280,ss_sold_date_sk#284] Batched: true, DataFilters: [isnotnull(ss_quantity#271), (ss_quantity#271 >= 16), (ss_quantity#271 <= 20), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,16), LessThanOrEqual(ss_quantity,20), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 53048400,
        "inputRowCount" : 1326210
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "3" : [ 117429, 87433, 93294, 98793, 110094, 129220, 124486, 119395, 91589, 101958, 94034, 125545, 99955, 119225, 109882, 126664, 103161, 108198, 94841, 103947, 110944, 94685, 92476, 96901, 96135, 107725, 97425, 112637, 115700, 121395, 100887, 99995, 106434, 122615, 98348, 121500, 84109, 101470, 117861, 94413, 99917, 119838, 113967, 90208, 98065, 117038, 93217, 116374, 129244, 122882, 107793, 105320, 106350, 126059, 99090, 105187, 101880, 110171, 86243, 108772, 94150, 121197, 100992, 93995, 121308, 95760, 100672, 91249, 106765, 126636, 114218, 124028, 96750, 101475, 133759, 103104, 125240, 95763, 117916, 112931, 92216, 113301, 91658, 101994, 113024, 104645, 103872, 102023, 118524, 117271, 112153, 103883, 93984, 91359, 110329, 110065, 104838, 105325, 125953, 121461, 106757, 109083, 94061, 124034, 104444, 73513, 107906, 113849, 114115, 105029, 93587, 119013, 137616, 101609, 103139, 107188, 111733, 120863, 112322, 103236, 86349, 130197, 102352, 91253, 134174, 102315, 95366, 107079, 111903, 118144, 112390, 126095, 104378, 107478, 103074, 100682, 116129, 108465, 97607, 96446, 93401, 97817, 101987, 100035, 125922, 107668, 100025, 98930, 107670, 127850, 121498, 89370, 111217, 102962, 110390, 120819, 98010, 92018, 92392, 94788, 105939, 107633, 103628, 110719, 89920, 112872, 116492, 101364, 107622, 92658, 90733, 103931, 94229, 97303, 99551, 108254, 98087, 130275, 119594, 98038, 125413, 84420, 122130, 90993, 88156, 97482, 123322, 118225, 131439, 125769, 97061, 103679, 112882, 120442, 96712, 111244, 114098, 99649, 122849, 113240 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 11,
        "FinishedTasksTotalTimeInMs" : 12108.0,
        "FinishedTasksDistributionInMs" : [ 542.0, 608.0, 867.0, 1054.0, 2751.0 ]
      },
      "QueryStageOptimizationId" : 9,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 14 ],
      "Objectives" : {
        "DurationInMs" : 9812,
        "TotalTasksDurationInMs" : 686,
        "IOBytes" : {
          "Total" : 20434248,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 20434174,
            "SW" : 74
          }
        }
      }
    },
    "13" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -727590668,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 80,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 80,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "1" : {
            "sign" : -449665902,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 56,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 56,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          },
          "2" : {
            "sign" : 682730074,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 40,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11 "
          },
          "3" : {
            "sign" : -1627946789,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 40,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 39261840,
                "rowCount" : 981546
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]) "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]), BroadcastQueryStage 11\n:  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)])\n+- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : 524553557,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 39261840,
            "rowCount" : 981546,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [sum#384, count#385L, count#387L, count#390L] Arguments: 8 "
          },
          "5" : {
            "sign" : 1836560414,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [3]: [B3_LP#204, B3_CNT#205L, B3_CNTD#206L] Arguments: 12 "
          },
          "1" : {
            "sign" : -1373929896,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastNestedLoopJoinExec",
            "sizeInBytes" : 56,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastNestedLoopJoin Join type: Cross Join condition: None "
          },
          "0" : {
            "sign" : 965947787,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastNestedLoopJoinExec",
            "sizeInBytes" : 80,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastNestedLoopJoin Join type: Cross Join condition: None "
          },
          "2" : {
            "sign" : -381887115,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [3]: [B1_LP#198, B1_CNT#199L, B1_CNTD#200L] Arguments: 11 "
          },
          "3" : {
            "sign" : 1467456747,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [sum#384, count#385L, count#387L, count#390L] Keys: [] Functions [3]: [avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#227))#339, count(ss_list_price#227)#340L, count(ss_list_price#227)#341L] Results [3]: [cast((avg(UnscaledValue(ss_list_price#227))#339 / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227)#340L AS B2_CNT#202L, count(ss_list_price#227)#341L AS B2_CNTD#203L] "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "BroadcastQueryStage",
          "toId" : 1,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "ShuffleQueryStage",
          "toId" : 3,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "HashAggregate",
          "toId" : 1,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "BroadcastNestedLoopJoin",
          "toId" : 0,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "BroadcastQueryStage",
          "toId" : 0,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "BroadcastNestedLoopJoin BuildRight, Cross\n:- BroadcastNestedLoopJoin BuildLeft, Cross\n:  :- BroadcastQueryStage 11\n:  :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=878]\n:  :     +- *(12) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)], output=[B1_LP#198, B1_CNT#199L, B1_CNTD#200L])\n:  :        +- ShuffleQueryStage 6\n:  :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=530]\n:  :              +- *(7) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29), partial_count(distinct ss_list_price#29)], output=[sum#374, count#375L, count#377L, count#380L])\n:  :                 +- *(7) HashAggregate(keys=[ss_list_price#29], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n:  :                    +- AQEShuffleRead coalesced\n:  :                       +- ShuffleQueryStage 0\n:  :                          +- Exchange hashpartitioning(ss_list_price#29, 200), ENSURE_REQUIREMENTS, [plan_id=225]\n:  :                             +- *(1) HashAggregate(keys=[ss_list_price#29], functions=[partial_avg(UnscaledValue(ss_list_price#29)), partial_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n:  :                                +- *(1) Project [ss_list_price#29]\n:  :                                   +- *(1) Filter (((isnotnull(ss_quantity#27) AND (ss_quantity#27 >= 0)) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00))))\n:  :                                      +- *(1) ColumnarToRow\n:  :                                         +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#27,ss_wholesale_cost#28,ss_list_price#29,ss_coupon_amt#36,ss_sold_date_sk#40] Batched: true, DataFilters: [isnotnull(ss_quantity#27), (ss_quantity#27 >= 0), (ss_quantity#27 <= 5), ((((ss_list_price#29 >=..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,0), LessThanOrEqual(ss_quantity,5), Or(Or..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n:  +- HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)], output=[B2_LP#201, B2_CNT#202L, B2_CNTD#203L])\n:     +- ShuffleQueryStage 8\n:        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=704]\n:           +- *(9) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227), partial_count(distinct ss_list_price#227)], output=[sum#384, count#385L, count#387L, count#390L])\n:              +- *(9) HashAggregate(keys=[ss_list_price#227], functions=[merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n:                 +- AQEShuffleRead coalesced\n:                    +- ShuffleQueryStage 1\n:                       +- Exchange hashpartitioning(ss_list_price#227, 200), ENSURE_REQUIREMENTS, [plan_id=270]\n:                          +- *(2) HashAggregate(keys=[ss_list_price#227], functions=[partial_avg(UnscaledValue(ss_list_price#227)), partial_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n:                             +- *(2) Project [ss_list_price#227]\n:                                +- *(2) Filter (((isnotnull(ss_quantity#225) AND (ss_quantity#225 >= 6)) AND (ss_quantity#225 <= 10)) AND ((((ss_list_price#227 >= 91.00) AND (ss_list_price#227 <= 101.00)) OR ((ss_coupon_amt#234 >= 1430.00) AND (ss_coupon_amt#234 <= 2430.00))) OR ((ss_wholesale_cost#226 >= 32.00) AND (ss_wholesale_cost#226 <= 52.00))))\n:                                   +- *(2) ColumnarToRow\n:                                      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#225,ss_wholesale_cost#226,ss_list_price#227,ss_coupon_amt#234,ss_sold_date_sk#238] Batched: true, DataFilters: [isnotnull(ss_quantity#225), (ss_quantity#225 >= 6), (ss_quantity#225 <= 10), ((((ss_list_price#2..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,6), LessThanOrEqual(ss_quantity,10), Or(O..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n+- BroadcastQueryStage 12\n   +- BroadcastExchange IdentityBroadcastMode, [plan_id=972]\n      +- *(13) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)], output=[B3_LP#204, B3_CNT#205L, B3_CNTD#206L])\n         +- ShuffleQueryStage 7\n            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=639]\n               +- *(8) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250), partial_count(distinct ss_list_price#250)], output=[sum#394, count#395L, count#397L, count#400L])\n                  +- *(8) HashAggregate(keys=[ss_list_price#250], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n                     +- AQEShuffleRead coalesced\n                        +- ShuffleQueryStage 2\n                           +- Exchange hashpartitioning(ss_list_price#250, 200), ENSURE_REQUIREMENTS, [plan_id=317]\n                              +- *(3) HashAggregate(keys=[ss_list_price#250], functions=[partial_avg(UnscaledValue(ss_list_price#250)), partial_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n                                 +- *(3) Project [ss_list_price#250]\n                                    +- *(3) Filter (((isnotnull(ss_quantity#248) AND (ss_quantity#248 >= 11)) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00))))\n                                       +- *(3) ColumnarToRow\n                                          +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#248,ss_wholesale_cost#249,ss_list_price#250,ss_coupon_amt#257,ss_sold_date_sk#261] Batched: true, DataFilters: [isnotnull(ss_quantity#248), (ss_quantity#248 >= 11), (ss_quantity#248 <= 15), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,11), LessThanOrEqual(ss_quantity,15), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 104,
        "inputRowCount" : 3
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "8" : [ 80 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 5,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "QueryStageOptimizationId" : 13,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 25 ],
      "Objectives" : {
        "DurationInMs" : 196,
        "TotalTasksDurationInMs" : 191,
        "IOBytes" : {
          "Total" : 74,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 74,
            "SW" : 0
          }
        }
      }
    },
    "16" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 312764127,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 47700280,
                "rowCount" : 1192507
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 1305265213,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 47700280,
            "rowCount" : 1192507,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#319, sum#424, count#425L, count#427L] Keys: [] Functions [3]: [merge_avg(UnscaledValue(ss_list_price#319)), merge_count(ss_list_price#319), partial_count(distinct ss_list_price#319)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#319))#351, count(ss_list_price#319)#352L, count(ss_list_price#319)#353L] Results [4]: [sum#424, count#425L, count#427L, count#430L] "
          },
          "1" : {
            "sign" : -323590008,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 47700280,
            "rowCount" : 1192507,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#319, sum#424, count#425L, count#427L] Keys [1]: [ss_list_price#319] Functions [2]: [merge_avg(UnscaledValue(ss_list_price#319)), merge_count(ss_list_price#319)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#319))#351, count(ss_list_price#319)#352L] Results [4]: [ss_list_price#319, sum#424, count#425L, count#427L] "
          },
          "2" : {
            "sign" : -1705565819,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [ss_list_price#319, sum#424, count#425L, count#427L] Arguments: 5 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "ShuffleQueryStage",
          "toId" : 1,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#319)), merge_count(ss_list_price#319), partial_count(distinct ss_list_price#319)], output=[sum#424, count#425L, count#427L, count#430L])\n+- HashAggregate(keys=[ss_list_price#319], functions=[merge_avg(UnscaledValue(ss_list_price#319)), merge_count(ss_list_price#319)], output=[ss_list_price#319, sum#424, count#425L, count#427L])\n   +- ShuffleQueryStage 5\n      +- Exchange hashpartitioning(ss_list_price#319, 200), ENSURE_REQUIREMENTS, [plan_id=458]\n         +- *(6) HashAggregate(keys=[ss_list_price#319], functions=[partial_avg(UnscaledValue(ss_list_price#319)), partial_count(ss_list_price#319)], output=[ss_list_price#319, sum#424, count#425L, count#427L])\n            +- *(6) Project [ss_list_price#319]\n               +- *(6) Filter (((isnotnull(ss_quantity#317) AND (ss_quantity#317 >= 26)) AND (ss_quantity#317 <= 30)) AND ((((ss_list_price#319 >= 28.00) AND (ss_list_price#319 <= 38.00)) OR ((ss_coupon_amt#326 >= 2513.00) AND (ss_coupon_amt#326 <= 3513.00))) OR ((ss_wholesale_cost#318 >= 42.00) AND (ss_wholesale_cost#318 <= 62.00))))\n                  +- *(6) ColumnarToRow\n                     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#317,ss_wholesale_cost#318,ss_list_price#319,ss_coupon_amt#326,ss_sold_date_sk#330] Batched: true, DataFilters: [isnotnull(ss_quantity#317), (ss_quantity#317 >= 26), (ss_quantity#317 <= 30), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,26), LessThanOrEqual(ss_quantity,30), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 47700280,
        "inputRowCount" : 1192507
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "5" : [ 83542, 102652, 92648, 96368, 108187, 93939, 115430, 91490, 98070, 101774, 87926, 121000, 113579, 113857, 100451, 98586, 99290, 93677, 74875, 97944, 109907, 110841, 94595, 101946, 108971, 93307, 101115, 93436, 102185, 93805, 89948, 109084, 111956, 108700, 95611, 108250, 86402, 102746, 105063, 103344, 91407, 90553, 98304, 101286, 113854, 99932, 94609, 90333, 117597, 100515, 88253, 95908, 78214, 100693, 105874, 101224, 119202, 84897, 90325, 90933, 109528, 92499, 98098, 99786, 111407, 99958, 91817, 98678, 94854, 109164, 101236, 117167, 80607, 90001, 98472, 96553, 109594, 85433, 118536, 91747, 89779, 109796, 101997, 96146, 102028, 101289, 108592, 103400, 99791, 105373, 108285, 94585, 91736, 100909, 106387, 77552, 98570, 88860, 109505, 112439, 77934, 124182, 99676, 90996, 101759, 90195, 121277, 98238, 112903, 109797, 92467, 104752, 90842, 98087, 104406, 95871, 99298, 97373, 109008, 82956, 100656, 96366, 91889, 84868, 135396, 112442, 97750, 119423, 113584, 103747, 101150, 116056, 101737, 118382, 99451, 112626, 99163, 112494, 96009, 97826, 108179, 96259, 95602, 96292, 105301, 97256, 112652, 107038, 103718, 115554, 112657, 104599, 91897, 99873, 114436, 106979, 104011, 100393, 97040, 78110, 98002, 81813, 110603, 95506, 93053, 97520, 84051, 113392, 109205, 99831, 90389, 105988, 70942, 101020, 106458, 118507, 119368, 129790, 103424, 99136, 98980, 101374, 106637, 86850, 93511, 80908, 102706, 90655, 124908, 106806, 108367, 99127, 89247, 109019, 87646, 117004, 98582, 78843, 93616, 105117 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 16,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 33 ],
      "Objectives" : {
        "DurationInMs" : 407,
        "TotalTasksDurationInMs" : 402,
        "IOBytes" : {
          "Total" : 19216422,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 19216348,
            "SW" : 74
          }
        }
      }
    },
    "5" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -1797273391,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L] "
          },
          "1" : {
            "sign" : -910080635,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 122517936,
                "rowCount" : 7657371
              },
              "compileTime" : {
                "sizeInBytes" : 122517936,
                "rowCount" : 7657371
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_list_price#319] "
          },
          "2" : {
            "sign" : 1905180683,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 1163920392,
                "rowCount" : 7657371
              },
              "compileTime" : {
                "sizeInBytes" : 1163920392,
                "rowCount" : 7657371
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#317) AND (((ss_quantity#317 >= 26) AND (ss_quantity#317 <= 30)) AND ((((ss_list_price#319 >= 28.00) AND (ss_list_price#319 <= 38.00)) OR ((ss_coupon_amt#326 >= 2513.00) AND (ss_coupon_amt#326 <= 3513.00))) OR ((ss_wholesale_cost#318 >= 42.00) AND (ss_wholesale_cost#318 <= 62.00))))) "
          },
          "3" : {
            "sign" : -2019690649,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              },
              "compileTime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#308, ss_item_sk#309, ss_customer_sk#310, ss_cdemo_sk#311, ss_hdemo_sk#312, ss_addr_sk#313, ss_store_sk#314, ss_promo_sk#315, ss_ticket_number#316L, ss_quantity#317, ss_wholesale_cost#318, ss_list_price#319, ss_sales_price#320, ss_ext_discount_amt#321, ss_ext_sales_price#322, ss_ext_wholesale_cost#323, ss_ext_list_price#324, ss_ext_tax#325, ss_coupon_amt#326, ss_net_paid#327, ss_net_paid_inc_tax#328, ss_net_profit#329, ss_sold_date_sk#330], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalRelation",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L]\n+- Project [ss_list_price#319]\n   +- Filter (isnotnull(ss_quantity#317) AND (((ss_quantity#317 >= 26) AND (ss_quantity#317 <= 30)) AND ((((ss_list_price#319 >= 28.00) AND (ss_list_price#319 <= 38.00)) OR ((ss_coupon_amt#326 >= 2513.00) AND (ss_coupon_amt#326 <= 3513.00))) OR ((ss_wholesale_cost#318 >= 42.00) AND (ss_wholesale_cost#318 <= 62.00)))))\n      +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#308,ss_item_sk#309,ss_customer_sk#310,ss_cdemo_sk#311,ss_hdemo_sk#312,ss_addr_sk#313,ss_store_sk#314,ss_promo_sk#315,ss_ticket_number#316L,ss_quantity#317,ss_wholesale_cost#318,ss_list_price#319,ss_sales_price#320,ss_ext_discount_amt#321,ss_ext_sales_price#322,ss_ext_wholesale_cost#323,ss_ext_list_price#324,ss_ext_tax#325,ss_coupon_amt#326,ss_net_paid#327,ss_net_paid_inc_tax#328,ss_net_profit#329,ss_sold_date_sk#330] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 403336028,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [1]: [ss_list_price#319] Keys [1]: [ss_list_price#319] Functions [2]: [partial_avg(UnscaledValue(ss_list_price#319)), partial_count(ss_list_price#319)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#319))#351, count(ss_list_price#319)#352L] Results [4]: [ss_list_price#319, sum#424, count#425L, count#427L] "
          },
          "1" : {
            "sign" : 999834931,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 122517936,
            "rowCount" : 7657371,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [ss_list_price#319] Input [5]: [ss_quantity#317, ss_wholesale_cost#318, ss_list_price#319, ss_coupon_amt#326, ss_sold_date_sk#330] "
          },
          "2" : {
            "sign" : 1400653069,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 122517936,
            "rowCount" : 7657371,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [5]: [ss_quantity#317, ss_wholesale_cost#318, ss_list_price#319, ss_coupon_amt#326, ss_sold_date_sk#330] Condition : (((isnotnull(ss_quantity#317) AND (ss_quantity#317 >= 26)) AND (ss_quantity#317 <= 30)) AND ((((ss_list_price#319 >= 28.00) AND (ss_list_price#319 <= 38.00)) OR ((ss_coupon_amt#326 >= 2513.00) AND (ss_coupon_amt#326 <= 3513.00))) OR ((ss_wholesale_cost#318 >= 42.00) AND (ss_wholesale_cost#318 <= 62.00)))) "
          },
          "3" : {
            "sign" : -2039033633,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 122517936,
            "rowCount" : 7657371,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [5]: [ss_quantity#317, ss_wholesale_cost#318, ss_list_price#319, ss_coupon_amt#326, ss_sold_date_sk#330] Batched: true Location: CatalogFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales] PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,26), LessThanOrEqual(ss_quantity,30), Or(Or(And(GreaterThanOrEqual(ss_list_price,28.00),LessThanOrEqual(ss_list_price,38.00)),And(GreaterThanOrEqual(ss_coupon_amt,2513.00),LessThanOrEqual(ss_coupon_amt,3513.00))),And(GreaterThanOrEqual(ss_wholesale_cost,42.00),LessThanOrEqual(ss_wholesale_cost,62.00)))] ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:decimal(7,2)> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[ss_list_price#319], functions=[partial_avg(UnscaledValue(ss_list_price#319)), partial_count(ss_list_price#319)], output=[ss_list_price#319, sum#424, count#425L, count#427L])\n+- Project [ss_list_price#319]\n   +- Filter (((isnotnull(ss_quantity#317) AND (ss_quantity#317 >= 26)) AND (ss_quantity#317 <= 30)) AND ((((ss_list_price#319 >= 28.00) AND (ss_list_price#319 <= 38.00)) OR ((ss_coupon_amt#326 >= 2513.00) AND (ss_coupon_amt#326 <= 3513.00))) OR ((ss_wholesale_cost#318 >= 42.00) AND (ss_wholesale_cost#318 <= 62.00))))\n      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#317,ss_wholesale_cost#318,ss_list_price#319,ss_coupon_amt#326,ss_sold_date_sk#330] Batched: true, DataFilters: [isnotnull(ss_quantity#317), (ss_quantity#317 >= 26), (ss_quantity#317 <= 30), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,26), LessThanOrEqual(ss_quantity,30), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 122517936,
        "inputRowCount" : 7657371
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 5,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 6 ],
      "Objectives" : {
        "DurationInMs" : 55643,
        "TotalTasksDurationInMs" : 101609,
        "IOBytes" : {
          "Total" : 2443804226,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 0,
            "SW" : 19216348
          }
        }
      }
    },
    "10" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -519389093,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 44240960,
                "rowCount" : 1106024
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 1506407477,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#296, sum#414, count#415L, count#417L] Keys: [] Functions [3]: [merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296), partial_count(distinct ss_list_price#296)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#296))#348, count(ss_list_price#296)#349L, count(ss_list_price#296)#350L] Results [4]: [sum#414, count#415L, count#417L, count#420L] "
          },
          "1" : {
            "sign" : -1745651134,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#296, sum#414, count#415L, count#417L] Keys [1]: [ss_list_price#296] Functions [2]: [merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#296))#348, count(ss_list_price#296)#349L] Results [4]: [ss_list_price#296, sum#414, count#415L, count#417L] "
          },
          "2" : {
            "sign" : 1229536328,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [ss_list_price#296, sum#414, count#415L, count#417L] Arguments: 4 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "ShuffleQueryStage",
          "toId" : 1,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296), partial_count(distinct ss_list_price#296)], output=[sum#414, count#415L, count#417L, count#420L])\n+- HashAggregate(keys=[ss_list_price#296], functions=[merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n   +- ShuffleQueryStage 4\n      +- Exchange hashpartitioning(ss_list_price#296, 200), ENSURE_REQUIREMENTS, [plan_id=411]\n         +- *(5) HashAggregate(keys=[ss_list_price#296], functions=[partial_avg(UnscaledValue(ss_list_price#296)), partial_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n            +- *(5) Project [ss_list_price#296]\n               +- *(5) Filter (((isnotnull(ss_quantity#294) AND (ss_quantity#294 >= 21)) AND (ss_quantity#294 <= 25)) AND ((((ss_list_price#296 >= 135.00) AND (ss_list_price#296 <= 145.00)) OR ((ss_coupon_amt#303 >= 14180.00) AND (ss_coupon_amt#303 <= 15180.00))) OR ((ss_wholesale_cost#295 >= 38.00) AND (ss_wholesale_cost#295 <= 58.00))))\n                  +- *(5) ColumnarToRow\n                     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#294,ss_wholesale_cost#295,ss_list_price#296,ss_coupon_amt#303,ss_sold_date_sk#307] Batched: true, DataFilters: [isnotnull(ss_quantity#294), (ss_quantity#294 >= 21), (ss_quantity#294 <= 25), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,25), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 44240960,
        "inputRowCount" : 1106024
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "4" : [ 69932, 77634, 88124, 93321, 102279, 98986, 111541, 97137, 85490, 101251, 76498, 108833, 100450, 102323, 79822, 99619, 96979, 80850, 75015, 95598, 89997, 100585, 73979, 97558, 89462, 101270, 97439, 84869, 92766, 102098, 87709, 104152, 106663, 112997, 80631, 112979, 85501, 87430, 113066, 90010, 79337, 84643, 89256, 93732, 97555, 90970, 86598, 95619, 102501, 107184, 98923, 95011, 74330, 98451, 93184, 100494, 115455, 92799, 98056, 88172, 100851, 83043, 89822, 91265, 106214, 89825, 97928, 93973, 88172, 100982, 91259, 99239, 67249, 79800, 97279, 88140, 97131, 80447, 118191, 81822, 73562, 98591, 92832, 94115, 86801, 99168, 91870, 91962, 95188, 101624, 93594, 82020, 84285, 89686, 88231, 81329, 90780, 74619, 113176, 92155, 67502, 111517, 97707, 82037, 95509, 99564, 107257, 93231, 109251, 93437, 82433, 90339, 81227, 91315, 102366, 94780, 99499, 93704, 112717, 67886, 93527, 101346, 77752, 76902, 131308, 83582, 90006, 116358, 113105, 100428, 98478, 115260, 85873, 98316, 86411, 91058, 93817, 88646, 101446, 93847, 100601, 95948, 91523, 90246, 99095, 84232, 97185, 92819, 98509, 104075, 104944, 90452, 88468, 89414, 97106, 100887, 93307, 95813, 84487, 82560, 94669, 81784, 92948, 91540, 80003, 85685, 80070, 97149, 92529, 98181, 83477, 98711, 73964, 106059, 97757, 112747, 109983, 119939, 93893, 90318, 101112, 88060, 104888, 76349, 80209, 63552, 95540, 92375, 112029, 108925, 91693, 83177, 86771, 99275, 77005, 107344, 76229, 71824, 91995, 99480 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 3,
        "FinishedTasksTotalTimeInMs" : 1413.0,
        "FinishedTasksDistributionInMs" : [ 436.0, 436.0, 483.0, 494.0, 494.0 ]
      },
      "QueryStageOptimizationId" : 10,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 16 ],
      "Objectives" : {
        "DurationInMs" : 5216,
        "TotalTasksDurationInMs" : 678,
        "IOBytes" : {
          "Total" : 17814893,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 17814819,
            "SW" : 74
          }
        }
      }
    },
    "6" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -77505962,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32045280,
                "rowCount" : 801132
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -704183143,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 32045280,
            "rowCount" : 801132,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#29, sum#374, count#375L, count#377L] Keys: [] Functions [3]: [merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29), partial_count(distinct ss_list_price#29)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#29))#336, count(ss_list_price#29)#337L, count(ss_list_price#29)#338L] Results [4]: [sum#374, count#375L, count#377L, count#380L] "
          },
          "1" : {
            "sign" : 1041736300,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 32045280,
            "rowCount" : 801132,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#29, sum#374, count#375L, count#377L] Keys [1]: [ss_list_price#29] Functions [2]: [merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#29))#336, count(ss_list_price#29)#337L] Results [4]: [ss_list_price#29, sum#374, count#375L, count#377L] "
          },
          "2" : {
            "sign" : -894617139,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [ss_list_price#29, sum#374, count#375L, count#377L] Arguments: 0 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "ShuffleQueryStage",
          "toId" : 1,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29), partial_count(distinct ss_list_price#29)], output=[sum#374, count#375L, count#377L, count#380L])\n+- HashAggregate(keys=[ss_list_price#29], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n   +- ShuffleQueryStage 0\n      +- Exchange hashpartitioning(ss_list_price#29, 200), ENSURE_REQUIREMENTS, [plan_id=225]\n         +- *(1) HashAggregate(keys=[ss_list_price#29], functions=[partial_avg(UnscaledValue(ss_list_price#29)), partial_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n            +- *(1) Project [ss_list_price#29]\n               +- *(1) Filter (((isnotnull(ss_quantity#27) AND (ss_quantity#27 >= 0)) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00))))\n                  +- *(1) ColumnarToRow\n                     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#27,ss_wholesale_cost#28,ss_list_price#29,ss_coupon_amt#36,ss_sold_date_sk#40] Batched: true, DataFilters: [isnotnull(ss_quantity#27), (ss_quantity#27 >= 0), (ss_quantity#27 <= 5), ((((ss_list_price#29 >=..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,0), LessThanOrEqual(ss_quantity,5), Or(Or..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 32045280,
        "inputRowCount" : 801132
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "0" : [ 62518, 74448, 70267, 72833, 70703, 56503, 74750, 59552, 76239, 92635, 68244, 84844, 90536, 79006, 84231, 69139, 65348, 66288, 71622, 81196, 92102, 88765, 68106, 86808, 89146, 70905, 59839, 70001, 76558, 68269, 67809, 68918, 79867, 81463, 68188, 76344, 78561, 79013, 61531, 84862, 77282, 61846, 58040, 83429, 86646, 56784, 62631, 76375, 70973, 63041, 77662, 64267, 54141, 58767, 66162, 87419, 81306, 64333, 64384, 65694, 65227, 64790, 69134, 82501, 67854, 71992, 64987, 72421, 71760, 81607, 69411, 94964, 75852, 54879, 58356, 67254, 74425, 60358, 75859, 58126, 72393, 75019, 80974, 75791, 64983, 74069, 73252, 72005, 61650, 73460, 63479, 69945, 74039, 67686, 74504, 53232, 55242, 59265, 84987, 69690, 63930, 85656, 67461, 64146, 70134, 67010, 79168, 78926, 60080, 81857, 71099, 69373, 71659, 85311, 68618, 73058, 72467, 77671, 77904, 76245, 73822, 83980, 81152, 66726, 77360, 81244, 74329, 91422, 66601, 74536, 62685, 86937, 74493, 82283, 67991, 89722, 62294, 77744, 74972, 75396, 88385, 86723, 66912, 73075, 65594, 69197, 76652, 82813, 73716, 67774, 78293, 73304, 57354, 76202, 74470, 76134, 98319, 75590, 85709, 63072, 72187, 57063, 76326, 73983, 73016, 66965, 56402, 74329, 74316, 84109, 73548, 81592, 54279, 65221, 65258, 90168, 94755, 81087, 77051, 80118, 67980, 72281, 77121, 79485, 59109, 57895, 73466, 68463, 90475, 78740, 83122, 73944, 62357, 82829, 67338, 76146, 78101, 74173, 73511, 81771 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 165,
        "FinishedTasksTotalTimeInMs" : 131827.0,
        "FinishedTasksDistributionInMs" : [ 168.0, 387.0, 460.0, 686.0, 5825.0 ]
      },
      "QueryStageOptimizationId" : 6,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 8 ],
      "Objectives" : {
        "DurationInMs" : 24732,
        "TotalTasksDurationInMs" : 580,
        "IOBytes" : {
          "Total" : 13942531,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 13942457,
            "SW" : 74
          }
        }
      }
    },
    "1" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 616594918,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L] "
          },
          "1" : {
            "sign" : 1654642509,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 131358864,
                "rowCount" : 8209929
              },
              "compileTime" : {
                "sizeInBytes" : 131358864,
                "rowCount" : 8209929
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_list_price#227] "
          },
          "2" : {
            "sign" : -1164012835,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 1247909208,
                "rowCount" : 8209929
              },
              "compileTime" : {
                "sizeInBytes" : 1247909208,
                "rowCount" : 8209929
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#225) AND (((ss_quantity#225 >= 6) AND (ss_quantity#225 <= 10)) AND ((((ss_list_price#227 >= 91.00) AND (ss_list_price#227 <= 101.00)) OR ((ss_coupon_amt#234 >= 1430.00) AND (ss_coupon_amt#234 <= 2430.00))) OR ((ss_wholesale_cost#226 >= 32.00) AND (ss_wholesale_cost#226 <= 52.00))))) "
          },
          "3" : {
            "sign" : -245342126,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              },
              "compileTime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#216, ss_item_sk#217, ss_customer_sk#218, ss_cdemo_sk#219, ss_hdemo_sk#220, ss_addr_sk#221, ss_store_sk#222, ss_promo_sk#223, ss_ticket_number#224L, ss_quantity#225, ss_wholesale_cost#226, ss_list_price#227, ss_sales_price#228, ss_ext_discount_amt#229, ss_ext_sales_price#230, ss_ext_wholesale_cost#231, ss_ext_list_price#232, ss_ext_tax#233, ss_coupon_amt#234, ss_net_paid#235, ss_net_paid_inc_tax#236, ss_net_profit#237, ss_sold_date_sk#238], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalRelation",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [cast((avg(UnscaledValue(ss_list_price#227)) / 100.0) as decimal(11,6)) AS B2_LP#201, count(ss_list_price#227) AS B2_CNT#202L, count(distinct ss_list_price#227) AS B2_CNTD#203L]\n+- Project [ss_list_price#227]\n   +- Filter (isnotnull(ss_quantity#225) AND (((ss_quantity#225 >= 6) AND (ss_quantity#225 <= 10)) AND ((((ss_list_price#227 >= 91.00) AND (ss_list_price#227 <= 101.00)) OR ((ss_coupon_amt#234 >= 1430.00) AND (ss_coupon_amt#234 <= 2430.00))) OR ((ss_wholesale_cost#226 >= 32.00) AND (ss_wholesale_cost#226 <= 52.00)))))\n      +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#216,ss_item_sk#217,ss_customer_sk#218,ss_cdemo_sk#219,ss_hdemo_sk#220,ss_addr_sk#221,ss_store_sk#222,ss_promo_sk#223,ss_ticket_number#224L,ss_quantity#225,ss_wholesale_cost#226,ss_list_price#227,ss_sales_price#228,ss_ext_discount_amt#229,ss_ext_sales_price#230,ss_ext_wholesale_cost#231,ss_ext_list_price#232,ss_ext_tax#233,ss_coupon_amt#234,ss_net_paid#235,ss_net_paid_inc_tax#236,ss_net_profit#237,ss_sold_date_sk#238] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 1199851246,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [1]: [ss_list_price#227] Keys [1]: [ss_list_price#227] Functions [2]: [partial_avg(UnscaledValue(ss_list_price#227)), partial_count(ss_list_price#227)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#227))#339, count(ss_list_price#227)#340L] Results [4]: [ss_list_price#227, sum#384, count#385L, count#387L] "
          },
          "1" : {
            "sign" : -810664898,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 131358864,
            "rowCount" : 8209929,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [ss_list_price#227] Input [5]: [ss_quantity#225, ss_wholesale_cost#226, ss_list_price#227, ss_coupon_amt#234, ss_sold_date_sk#238] "
          },
          "2" : {
            "sign" : 1504965154,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 131358864,
            "rowCount" : 8209929,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [5]: [ss_quantity#225, ss_wholesale_cost#226, ss_list_price#227, ss_coupon_amt#234, ss_sold_date_sk#238] Condition : (((isnotnull(ss_quantity#225) AND (ss_quantity#225 >= 6)) AND (ss_quantity#225 <= 10)) AND ((((ss_list_price#227 >= 91.00) AND (ss_list_price#227 <= 101.00)) OR ((ss_coupon_amt#234 >= 1430.00) AND (ss_coupon_amt#234 <= 2430.00))) OR ((ss_wholesale_cost#226 >= 32.00) AND (ss_wholesale_cost#226 <= 52.00)))) "
          },
          "3" : {
            "sign" : 1800493965,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 131358864,
            "rowCount" : 8209929,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [5]: [ss_quantity#225, ss_wholesale_cost#226, ss_list_price#227, ss_coupon_amt#234, ss_sold_date_sk#238] Batched: true Location: CatalogFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales] PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,6), LessThanOrEqual(ss_quantity,10), Or(Or(And(GreaterThanOrEqual(ss_list_price,91.00),LessThanOrEqual(ss_list_price,101.00)),And(GreaterThanOrEqual(ss_coupon_amt,1430.00),LessThanOrEqual(ss_coupon_amt,2430.00))),And(GreaterThanOrEqual(ss_wholesale_cost,32.00),LessThanOrEqual(ss_wholesale_cost,52.00)))] ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:decimal(7,2)> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[ss_list_price#227], functions=[partial_avg(UnscaledValue(ss_list_price#227)), partial_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n+- Project [ss_list_price#227]\n   +- Filter (((isnotnull(ss_quantity#225) AND (ss_quantity#225 >= 6)) AND (ss_quantity#225 <= 10)) AND ((((ss_list_price#227 >= 91.00) AND (ss_list_price#227 <= 101.00)) OR ((ss_coupon_amt#234 >= 1430.00) AND (ss_coupon_amt#234 <= 2430.00))) OR ((ss_wholesale_cost#226 >= 32.00) AND (ss_wholesale_cost#226 <= 52.00))))\n      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#225,ss_wholesale_cost#226,ss_list_price#227,ss_coupon_amt#234,ss_sold_date_sk#238] Batched: true, DataFilters: [isnotnull(ss_quantity#225), (ss_quantity#225 >= 6), (ss_quantity#225 <= 10), ((((ss_list_price#2..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,6), LessThanOrEqual(ss_quantity,10), Or(O..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 131358864,
        "inputRowCount" : 8209929
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 1,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 2 ],
      "Objectives" : {
        "DurationInMs" : 35138,
        "TotalTasksDurationInMs" : 174654,
        "IOBytes" : {
          "Total" : 2441127166,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 0,
            "SW" : 16539288
          }
        }
      }
    },
    "17" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1008267833,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 181261064,
                "rowCount" : 1192507
              },
              "compileTime" : {
                "sizeInBytes" : 181261064,
                "rowCount" : 1192507
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Cross "
          }
        },
        "links" : [ ],
        "rawPlan" : "Join Cross\n:- Join Cross\n:  :- Join Cross\n:  :  :- LogicalQueryStage Join Cross, BroadcastQueryStage 13\n:  :  +- LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)])\n:  +- LogicalQueryStage LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), BroadcastQueryStage 14\n+- LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#319)) / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319) AS B6_CNT#214L, count(distinct ss_list_price#319) AS B6_CNTD#215L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -963014231,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastNestedLoopJoinExec",
            "sizeInBytes" : 181261064,
            "rowCount" : 1192507,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastNestedLoopJoin Join type: Cross Join condition: None "
          },
          "1" : {
            "sign" : -2133115758,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 128,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [15]: [B1_LP#198, B1_CNT#199L, B1_CNTD#200L, B2_LP#201, B2_CNT#202L, B2_CNTD#203L, B3_LP#204, B3_CNT#205L, B3_CNTD#206L, B4_LP#207, B4_CNT#208L, B4_CNTD#209L, B5_LP#210, B5_CNT#211L, B5_CNTD#212L] Arguments: 15 "
          },
          "2" : {
            "sign" : -966614337,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [sum#424, count#425L, count#427L, count#430L] Keys: [] Functions [3]: [avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#319))#351, count(ss_list_price#319)#352L, count(ss_list_price#319)#353L] Results [3]: [cast((avg(UnscaledValue(ss_list_price#319))#351 / 100.0) as decimal(11,6)) AS B6_LP#213, count(ss_list_price#319)#352L AS B6_CNT#214L, count(ss_list_price#319)#353L AS B6_CNTD#215L] "
          },
          "3" : {
            "sign" : -714102648,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 47700280,
            "rowCount" : 1192507,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [sum#424, count#425L, count#427L, count#430L] Arguments: 16 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "BroadcastQueryStage",
          "toId" : 0,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "ShuffleQueryStage",
          "toId" : 2,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "BroadcastNestedLoopJoin",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "BroadcastNestedLoopJoin BuildLeft, Cross\n:- BroadcastQueryStage 15\n:  +- BroadcastExchange IdentityBroadcastMode, [plan_id=1193]\n:     +- *(16) BroadcastNestedLoopJoin BuildRight, Cross\n:        :- *(16) BroadcastNestedLoopJoin BuildLeft, Cross\n:        :  :- BroadcastQueryStage 13\n:        :  :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=1058]\n:        :  :     +- *(14) BroadcastNestedLoopJoin BuildRight, Cross\n:        :  :        :- *(14) BroadcastNestedLoopJoin BuildLeft, Cross\n:        :  :        :  :- BroadcastQueryStage 11\n:        :  :        :  :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=878]\n:        :  :        :  :     +- *(12) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#29)), count(ss_list_price#29), count(distinct ss_list_price#29)], output=[B1_LP#198, B1_CNT#199L, B1_CNTD#200L])\n:        :  :        :  :        +- ShuffleQueryStage 6\n:        :  :        :  :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=530]\n:        :  :        :  :              +- *(7) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29), partial_count(distinct ss_list_price#29)], output=[sum#374, count#375L, count#377L, count#380L])\n:        :  :        :  :                 +- *(7) HashAggregate(keys=[ss_list_price#29], functions=[merge_avg(UnscaledValue(ss_list_price#29)), merge_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n:        :  :        :  :                    +- AQEShuffleRead coalesced\n:        :  :        :  :                       +- ShuffleQueryStage 0\n:        :  :        :  :                          +- Exchange hashpartitioning(ss_list_price#29, 200), ENSURE_REQUIREMENTS, [plan_id=225]\n:        :  :        :  :                             +- *(1) HashAggregate(keys=[ss_list_price#29], functions=[partial_avg(UnscaledValue(ss_list_price#29)), partial_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n:        :  :        :  :                                +- *(1) Project [ss_list_price#29]\n:        :  :        :  :                                   +- *(1) Filter (((isnotnull(ss_quantity#27) AND (ss_quantity#27 >= 0)) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00))))\n:        :  :        :  :                                      +- *(1) ColumnarToRow\n:        :  :        :  :                                         +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#27,ss_wholesale_cost#28,ss_list_price#29,ss_coupon_amt#36,ss_sold_date_sk#40] Batched: true, DataFilters: [isnotnull(ss_quantity#27), (ss_quantity#27 >= 0), (ss_quantity#27 <= 5), ((((ss_list_price#29 >=..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,0), LessThanOrEqual(ss_quantity,5), Or(Or..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n:        :  :        :  +- *(14) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#227)), count(ss_list_price#227), count(distinct ss_list_price#227)], output=[B2_LP#201, B2_CNT#202L, B2_CNTD#203L])\n:        :  :        :     +- ShuffleQueryStage 8\n:        :  :        :        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=704]\n:        :  :        :           +- *(9) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227), partial_count(distinct ss_list_price#227)], output=[sum#384, count#385L, count#387L, count#390L])\n:        :  :        :              +- *(9) HashAggregate(keys=[ss_list_price#227], functions=[merge_avg(UnscaledValue(ss_list_price#227)), merge_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n:        :  :        :                 +- AQEShuffleRead coalesced\n:        :  :        :                    +- ShuffleQueryStage 1\n:        :  :        :                       +- Exchange hashpartitioning(ss_list_price#227, 200), ENSURE_REQUIREMENTS, [plan_id=270]\n:        :  :        :                          +- *(2) HashAggregate(keys=[ss_list_price#227], functions=[partial_avg(UnscaledValue(ss_list_price#227)), partial_count(ss_list_price#227)], output=[ss_list_price#227, sum#384, count#385L, count#387L])\n:        :  :        :                             +- *(2) Project [ss_list_price#227]\n:        :  :        :                                +- *(2) Filter (((isnotnull(ss_quantity#225) AND (ss_quantity#225 >= 6)) AND (ss_quantity#225 <= 10)) AND ((((ss_list_price#227 >= 91.00) AND (ss_list_price#227 <= 101.00)) OR ((ss_coupon_amt#234 >= 1430.00) AND (ss_coupon_amt#234 <= 2430.00))) OR ((ss_wholesale_cost#226 >= 32.00) AND (ss_wholesale_cost#226 <= 52.00))))\n:        :  :        :                                   +- *(2) ColumnarToRow\n:        :  :        :                                      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#225,ss_wholesale_cost#226,ss_list_price#227,ss_coupon_amt#234,ss_sold_date_sk#238] Batched: true, DataFilters: [isnotnull(ss_quantity#225), (ss_quantity#225 >= 6), (ss_quantity#225 <= 10), ((((ss_list_price#2..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,6), LessThanOrEqual(ss_quantity,10), Or(O..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n:        :  :        +- BroadcastQueryStage 12\n:        :  :           +- BroadcastExchange IdentityBroadcastMode, [plan_id=972]\n:        :  :              +- *(13) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)], output=[B3_LP#204, B3_CNT#205L, B3_CNTD#206L])\n:        :  :                 +- ShuffleQueryStage 7\n:        :  :                    +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=639]\n:        :  :                       +- *(8) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250), partial_count(distinct ss_list_price#250)], output=[sum#394, count#395L, count#397L, count#400L])\n:        :  :                          +- *(8) HashAggregate(keys=[ss_list_price#250], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n:        :  :                             +- AQEShuffleRead coalesced\n:        :  :                                +- ShuffleQueryStage 2\n:        :  :                                   +- Exchange hashpartitioning(ss_list_price#250, 200), ENSURE_REQUIREMENTS, [plan_id=317]\n:        :  :                                      +- *(3) HashAggregate(keys=[ss_list_price#250], functions=[partial_avg(UnscaledValue(ss_list_price#250)), partial_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n:        :  :                                         +- *(3) Project [ss_list_price#250]\n:        :  :                                            +- *(3) Filter (((isnotnull(ss_quantity#248) AND (ss_quantity#248 >= 11)) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00))))\n:        :  :                                               +- *(3) ColumnarToRow\n:        :  :                                                  +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#248,ss_wholesale_cost#249,ss_list_price#250,ss_coupon_amt#257,ss_sold_date_sk#261] Batched: true, DataFilters: [isnotnull(ss_quantity#248), (ss_quantity#248 >= 11), (ss_quantity#248 <= 15), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,11), LessThanOrEqual(ss_quantity,15), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n:        :  +- *(16) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#273)), count(ss_list_price#273), count(distinct ss_list_price#273)], output=[B4_LP#207, B4_CNT#208L, B4_CNTD#209L])\n:        :     +- ShuffleQueryStage 9\n:        :        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=768]\n:        :           +- *(10) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#273)), merge_count(ss_list_price#273), partial_count(distinct ss_list_price#273)], output=[sum#404, count#405L, count#407L, count#410L])\n:        :              +- *(10) HashAggregate(keys=[ss_list_price#273], functions=[merge_avg(UnscaledValue(ss_list_price#273)), merge_count(ss_list_price#273)], output=[ss_list_price#273, sum#404, count#405L, count#407L])\n:        :                 +- AQEShuffleRead coalesced\n:        :                    +- ShuffleQueryStage 3\n:        :                       +- Exchange hashpartitioning(ss_list_price#273, 200), ENSURE_REQUIREMENTS, [plan_id=364]\n:        :                          +- *(4) HashAggregate(keys=[ss_list_price#273], functions=[partial_avg(UnscaledValue(ss_list_price#273)), partial_count(ss_list_price#273)], output=[ss_list_price#273, sum#404, count#405L, count#407L])\n:        :                             +- *(4) Project [ss_list_price#273]\n:        :                                +- *(4) Filter (((isnotnull(ss_quantity#271) AND (ss_quantity#271 >= 16)) AND (ss_quantity#271 <= 20)) AND ((((ss_list_price#273 >= 142.00) AND (ss_list_price#273 <= 152.00)) OR ((ss_coupon_amt#280 >= 3054.00) AND (ss_coupon_amt#280 <= 4054.00))) OR ((ss_wholesale_cost#272 >= 80.00) AND (ss_wholesale_cost#272 <= 100.00))))\n:        :                                   +- *(4) ColumnarToRow\n:        :                                      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#271,ss_wholesale_cost#272,ss_list_price#273,ss_coupon_amt#280,ss_sold_date_sk#284] Batched: true, DataFilters: [isnotnull(ss_quantity#271), (ss_quantity#271 >= 16), (ss_quantity#271 <= 20), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,16), LessThanOrEqual(ss_quantity,20), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n:        +- BroadcastQueryStage 14\n:           +- BroadcastExchange IdentityBroadcastMode, [plan_id=1099]\n:              +- *(15) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)], output=[B5_LP#210, B5_CNT#211L, B5_CNTD#212L])\n:                 +- ShuffleQueryStage 10\n:                    +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=827]\n:                       +- *(11) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296), partial_count(distinct ss_list_price#296)], output=[sum#414, count#415L, count#417L, count#420L])\n:                          +- *(11) HashAggregate(keys=[ss_list_price#296], functions=[merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n:                             +- AQEShuffleRead coalesced\n:                                +- ShuffleQueryStage 4\n:                                   +- Exchange hashpartitioning(ss_list_price#296, 200), ENSURE_REQUIREMENTS, [plan_id=411]\n:                                      +- *(5) HashAggregate(keys=[ss_list_price#296], functions=[partial_avg(UnscaledValue(ss_list_price#296)), partial_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n:                                         +- *(5) Project [ss_list_price#296]\n:                                            +- *(5) Filter (((isnotnull(ss_quantity#294) AND (ss_quantity#294 >= 21)) AND (ss_quantity#294 <= 25)) AND ((((ss_list_price#296 >= 135.00) AND (ss_list_price#296 <= 145.00)) OR ((ss_coupon_amt#303 >= 14180.00) AND (ss_coupon_amt#303 <= 15180.00))) OR ((ss_wholesale_cost#295 >= 38.00) AND (ss_wholesale_cost#295 <= 58.00))))\n:                                               +- *(5) ColumnarToRow\n:                                                  +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#294,ss_wholesale_cost#295,ss_list_price#296,ss_coupon_amt#303,ss_sold_date_sk#307] Batched: true, DataFilters: [isnotnull(ss_quantity#294), (ss_quantity#294 >= 21), (ss_quantity#294 <= 25), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,25), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n+- HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#319)), count(ss_list_price#319), count(distinct ss_list_price#319)], output=[B6_LP#213, B6_CNT#214L, B6_CNTD#215L])\n   +- ShuffleQueryStage 16\n      +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=1212]\n         +- *(17) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#319)), merge_count(ss_list_price#319), partial_count(distinct ss_list_price#319)], output=[sum#424, count#425L, count#427L, count#430L])\n            +- *(17) HashAggregate(keys=[ss_list_price#319], functions=[merge_avg(UnscaledValue(ss_list_price#319)), merge_count(ss_list_price#319)], output=[ss_list_price#319, sum#424, count#425L, count#427L])\n               +- AQEShuffleRead coalesced\n                  +- ShuffleQueryStage 5\n                     +- Exchange hashpartitioning(ss_list_price#319, 200), ENSURE_REQUIREMENTS, [plan_id=458]\n                        +- *(6) HashAggregate(keys=[ss_list_price#319], functions=[partial_avg(UnscaledValue(ss_list_price#319)), partial_count(ss_list_price#319)], output=[ss_list_price#319, sum#424, count#425L, count#427L])\n                           +- *(6) Project [ss_list_price#319]\n                              +- *(6) Filter (((isnotnull(ss_quantity#317) AND (ss_quantity#317 >= 26)) AND (ss_quantity#317 <= 30)) AND ((((ss_list_price#319 >= 28.00) AND (ss_list_price#319 <= 38.00)) OR ((ss_coupon_amt#326 >= 2513.00) AND (ss_coupon_amt#326 <= 3513.00))) OR ((ss_wholesale_cost#318 >= 42.00) AND (ss_wholesale_cost#318 <= 62.00))))\n                                 +- *(6) ColumnarToRow\n                                    +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#317,ss_wholesale_cost#318,ss_list_price#319,ss_coupon_amt#326,ss_sold_date_sk#330] Batched: true, DataFilters: [isnotnull(ss_quantity#317), (ss_quantity#317 >= 26), (ss_quantity#317 <= 30), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,26), LessThanOrEqual(ss_quantity,30), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 168,
        "inputRowCount" : 2
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "11" : [ 80 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 17,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 36 ],
      "Objectives" : {
        "DurationInMs" : 57,
        "TotalTasksDurationInMs" : 51,
        "IOBytes" : {
          "Total" : 74,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 74,
            "SW" : 0
          }
        }
      }
    },
    "14" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1915343924,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 40,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 44240960,
                "rowCount" : 1106024
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#296)) / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296) AS B5_CNT#211L, count(distinct ss_list_price#296) AS B5_CNTD#212L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)]), HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -409083570,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 40,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [sum#414, count#415L, count#417L, count#420L] Keys: [] Functions [3]: [avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#296))#348, count(ss_list_price#296)#349L, count(ss_list_price#296)#350L] Results [3]: [cast((avg(UnscaledValue(ss_list_price#296))#348 / 100.0) as decimal(11,6)) AS B5_LP#210, count(ss_list_price#296)#349L AS B5_CNT#211L, count(ss_list_price#296)#350L AS B5_CNTD#212L] "
          },
          "1" : {
            "sign" : -1914954549,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 44240960,
            "rowCount" : 1106024,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [sum#414, count#415L, count#417L, count#420L] Arguments: 10 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "ShuffleQueryStage",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#296)), count(ss_list_price#296), count(distinct ss_list_price#296)], output=[B5_LP#210, B5_CNT#211L, B5_CNTD#212L])\n+- ShuffleQueryStage 10\n   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=827]\n      +- *(11) HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296), partial_count(distinct ss_list_price#296)], output=[sum#414, count#415L, count#417L, count#420L])\n         +- *(11) HashAggregate(keys=[ss_list_price#296], functions=[merge_avg(UnscaledValue(ss_list_price#296)), merge_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n            +- AQEShuffleRead coalesced\n               +- ShuffleQueryStage 4\n                  +- Exchange hashpartitioning(ss_list_price#296, 200), ENSURE_REQUIREMENTS, [plan_id=411]\n                     +- *(5) HashAggregate(keys=[ss_list_price#296], functions=[partial_avg(UnscaledValue(ss_list_price#296)), partial_count(ss_list_price#296)], output=[ss_list_price#296, sum#414, count#415L, count#417L])\n                        +- *(5) Project [ss_list_price#296]\n                           +- *(5) Filter (((isnotnull(ss_quantity#294) AND (ss_quantity#294 >= 21)) AND (ss_quantity#294 <= 25)) AND ((((ss_list_price#296 >= 135.00) AND (ss_list_price#296 <= 145.00)) OR ((ss_coupon_amt#303 >= 14180.00) AND (ss_coupon_amt#303 <= 15180.00))) OR ((ss_wholesale_cost#295 >= 38.00) AND (ss_wholesale_cost#295 <= 58.00))))\n                              +- *(5) ColumnarToRow\n                                 +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#294,ss_wholesale_cost#295,ss_list_price#296,ss_coupon_amt#303,ss_sold_date_sk#307] Batched: true, DataFilters: [isnotnull(ss_quantity#294), (ss_quantity#294 >= 21), (ss_quantity#294 <= 25), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,25), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 40,
        "inputRowCount" : 1
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "10" : [ 80 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 3,
        "FinishedTasksNum" : 158,
        "FinishedTasksTotalTimeInMs" : 78029.0,
        "FinishedTasksDistributionInMs" : [ 225.0, 343.0, 385.0, 449.0, 2480.0 ]
      },
      "QueryStageOptimizationId" : 14,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 28 ],
      "Objectives" : {
        "DurationInMs" : 137,
        "TotalTasksDurationInMs" : 134,
        "IOBytes" : {
          "Total" : 74,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 74,
            "SW" : 0
          }
        }
      }
    },
    "0" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1340382426,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L] "
          },
          "1" : {
            "sign" : 1385135785,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 98010800,
                "rowCount" : 6125675
              },
              "compileTime" : {
                "sizeInBytes" : 98010800,
                "rowCount" : 6125675
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_list_price#29] "
          },
          "2" : {
            "sign" : -785224445,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 931102600,
                "rowCount" : 6125675
              },
              "compileTime" : {
                "sizeInBytes" : 931102600,
                "rowCount" : 6125675
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#27) AND (((ss_quantity#27 >= 0) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00))))) "
          },
          "3" : {
            "sign" : -913851183,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              },
              "compileTime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#18, ss_item_sk#19, ss_customer_sk#20, ss_cdemo_sk#21, ss_hdemo_sk#22, ss_addr_sk#23, ss_store_sk#24, ss_promo_sk#25, ss_ticket_number#26L, ss_quantity#27, ss_wholesale_cost#28, ss_list_price#29, ss_sales_price#30, ss_ext_discount_amt#31, ss_ext_sales_price#32, ss_ext_wholesale_cost#33, ss_ext_list_price#34, ss_ext_tax#35, ss_coupon_amt#36, ss_net_paid#37, ss_net_paid_inc_tax#38, ss_net_profit#39, ss_sold_date_sk#40], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalRelation",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [cast((avg(UnscaledValue(ss_list_price#29)) / 100.0) as decimal(11,6)) AS B1_LP#198, count(ss_list_price#29) AS B1_CNT#199L, count(distinct ss_list_price#29) AS B1_CNTD#200L]\n+- Project [ss_list_price#29]\n   +- Filter (isnotnull(ss_quantity#27) AND (((ss_quantity#27 >= 0) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00)))))\n      +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#18,ss_item_sk#19,ss_customer_sk#20,ss_cdemo_sk#21,ss_hdemo_sk#22,ss_addr_sk#23,ss_store_sk#24,ss_promo_sk#25,ss_ticket_number#26L,ss_quantity#27,ss_wholesale_cost#28,ss_list_price#29,ss_sales_price#30,ss_ext_discount_amt#31,ss_ext_sales_price#32,ss_ext_wholesale_cost#33,ss_ext_list_price#34,ss_ext_tax#35,ss_coupon_amt#36,ss_net_paid#37,ss_net_paid_inc_tax#38,ss_net_profit#39,ss_sold_date_sk#40] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 604263791,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [1]: [ss_list_price#29] Keys [1]: [ss_list_price#29] Functions [2]: [partial_avg(UnscaledValue(ss_list_price#29)), partial_count(ss_list_price#29)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#29))#336, count(ss_list_price#29)#337L] Results [4]: [ss_list_price#29, sum#374, count#375L, count#377L] "
          },
          "1" : {
            "sign" : 1118085678,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 98010800,
            "rowCount" : 6125675,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [ss_list_price#29] Input [5]: [ss_quantity#27, ss_wholesale_cost#28, ss_list_price#29, ss_coupon_amt#36, ss_sold_date_sk#40] "
          },
          "2" : {
            "sign" : -1432700856,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 98010800,
            "rowCount" : 6125675,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [5]: [ss_quantity#27, ss_wholesale_cost#28, ss_list_price#29, ss_coupon_amt#36, ss_sold_date_sk#40] Condition : (((isnotnull(ss_quantity#27) AND (ss_quantity#27 >= 0)) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00)))) "
          },
          "3" : {
            "sign" : 2004123254,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 98010800,
            "rowCount" : 6125675,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [5]: [ss_quantity#27, ss_wholesale_cost#28, ss_list_price#29, ss_coupon_amt#36, ss_sold_date_sk#40] Batched: true Location: CatalogFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales] PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,0), LessThanOrEqual(ss_quantity,5), Or(Or(And(GreaterThanOrEqual(ss_list_price,11.00),LessThanOrEqual(ss_list_price,21.00)),And(GreaterThanOrEqual(ss_coupon_amt,460.00),LessThanOrEqual(ss_coupon_amt,1460.00))),And(GreaterThanOrEqual(ss_wholesale_cost,14.00),LessThanOrEqual(ss_wholesale_cost,34.00)))] ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:decimal(7,2)> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[ss_list_price#29], functions=[partial_avg(UnscaledValue(ss_list_price#29)), partial_count(ss_list_price#29)], output=[ss_list_price#29, sum#374, count#375L, count#377L])\n+- Project [ss_list_price#29]\n   +- Filter (((isnotnull(ss_quantity#27) AND (ss_quantity#27 >= 0)) AND (ss_quantity#27 <= 5)) AND ((((ss_list_price#29 >= 11.00) AND (ss_list_price#29 <= 21.00)) OR ((ss_coupon_amt#36 >= 460.00) AND (ss_coupon_amt#36 <= 1460.00))) OR ((ss_wholesale_cost#28 >= 14.00) AND (ss_wholesale_cost#28 <= 34.00))))\n      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#27,ss_wholesale_cost#28,ss_list_price#29,ss_coupon_amt#36,ss_sold_date_sk#40] Batched: true, DataFilters: [isnotnull(ss_quantity#27), (ss_quantity#27 >= 0), (ss_quantity#27 <= 5), ((((ss_list_price#29 >=..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,0), LessThanOrEqual(ss_quantity,5), Or(Or..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 98010800,
        "inputRowCount" : 6125675
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 0,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 1 ],
      "Objectives" : {
        "DurationInMs" : 25925,
        "TotalTasksDurationInMs" : 249761,
        "IOBytes" : {
          "Total" : 2438530335,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 0,
            "SW" : 13942457
          }
        }
      }
    },
    "2" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -184908522,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L] "
          },
          "1" : {
            "sign" : -464774483,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 116407088,
                "rowCount" : 7275443
              },
              "compileTime" : {
                "sizeInBytes" : 116407088,
                "rowCount" : 7275443
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_list_price#250] "
          },
          "2" : {
            "sign" : -858865675,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 1105867336,
                "rowCount" : 7275443
              },
              "compileTime" : {
                "sizeInBytes" : 1105867336,
                "rowCount" : 7275443
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#248) AND (((ss_quantity#248 >= 11) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00))))) "
          },
          "3" : {
            "sign" : -1297916055,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              },
              "compileTime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#239, ss_item_sk#240, ss_customer_sk#241, ss_cdemo_sk#242, ss_hdemo_sk#243, ss_addr_sk#244, ss_store_sk#245, ss_promo_sk#246, ss_ticket_number#247L, ss_quantity#248, ss_wholesale_cost#249, ss_list_price#250, ss_sales_price#251, ss_ext_discount_amt#252, ss_ext_sales_price#253, ss_ext_wholesale_cost#254, ss_ext_list_price#255, ss_ext_tax#256, ss_coupon_amt#257, ss_net_paid#258, ss_net_paid_inc_tax#259, ss_net_profit#260, ss_sold_date_sk#261], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalRelation",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L]\n+- Project [ss_list_price#250]\n   +- Filter (isnotnull(ss_quantity#248) AND (((ss_quantity#248 >= 11) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00)))))\n      +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#239,ss_item_sk#240,ss_customer_sk#241,ss_cdemo_sk#242,ss_hdemo_sk#243,ss_addr_sk#244,ss_store_sk#245,ss_promo_sk#246,ss_ticket_number#247L,ss_quantity#248,ss_wholesale_cost#249,ss_list_price#250,ss_sales_price#251,ss_ext_discount_amt#252,ss_ext_sales_price#253,ss_ext_wholesale_cost#254,ss_ext_list_price#255,ss_ext_tax#256,ss_coupon_amt#257,ss_net_paid#258,ss_net_paid_inc_tax#259,ss_net_profit#260,ss_sold_date_sk#261] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -362126081,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [1]: [ss_list_price#250] Keys [1]: [ss_list_price#250] Functions [2]: [partial_avg(UnscaledValue(ss_list_price#250)), partial_count(ss_list_price#250)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#250))#342, count(ss_list_price#250)#343L] Results [4]: [ss_list_price#250, sum#394, count#395L, count#397L] "
          },
          "1" : {
            "sign" : 212164854,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 116407088,
            "rowCount" : 7275443,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [ss_list_price#250] Input [5]: [ss_quantity#248, ss_wholesale_cost#249, ss_list_price#250, ss_coupon_amt#257, ss_sold_date_sk#261] "
          },
          "2" : {
            "sign" : 1535918666,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 116407088,
            "rowCount" : 7275443,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [5]: [ss_quantity#248, ss_wholesale_cost#249, ss_list_price#250, ss_coupon_amt#257, ss_sold_date_sk#261] Condition : (((isnotnull(ss_quantity#248) AND (ss_quantity#248 >= 11)) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00)))) "
          },
          "3" : {
            "sign" : 283228312,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 116407088,
            "rowCount" : 7275443,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [5]: [ss_quantity#248, ss_wholesale_cost#249, ss_list_price#250, ss_coupon_amt#257, ss_sold_date_sk#261] Batched: true Location: CatalogFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales] PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,11), LessThanOrEqual(ss_quantity,15), Or(Or(And(GreaterThanOrEqual(ss_list_price,66.00),LessThanOrEqual(ss_list_price,76.00)),And(GreaterThanOrEqual(ss_coupon_amt,920.00),LessThanOrEqual(ss_coupon_amt,1920.00))),And(GreaterThanOrEqual(ss_wholesale_cost,4.00),LessThanOrEqual(ss_wholesale_cost,24.00)))] ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:decimal(7,2)> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[ss_list_price#250], functions=[partial_avg(UnscaledValue(ss_list_price#250)), partial_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n+- Project [ss_list_price#250]\n   +- Filter (((isnotnull(ss_quantity#248) AND (ss_quantity#248 >= 11)) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00))))\n      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#248,ss_wholesale_cost#249,ss_list_price#250,ss_coupon_amt#257,ss_sold_date_sk#261] Batched: true, DataFilters: [isnotnull(ss_quantity#248), (ss_quantity#248 >= 11), (ss_quantity#248 <= 15), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,11), LessThanOrEqual(ss_quantity,15), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 116407088,
        "inputRowCount" : 7275443
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 2,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 3 ],
      "Objectives" : {
        "DurationInMs" : 34678,
        "TotalTasksDurationInMs" : 111576,
        "IOBytes" : {
          "Total" : 2439622674,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 0,
            "SW" : 15034796
          }
        }
      }
    },
    "7" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 424799646,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 35130000,
                "rowCount" : 878250
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [cast((avg(UnscaledValue(ss_list_price#250)) / 100.0) as decimal(11,6)) AS B3_LP#204, count(ss_list_price#250) AS B3_CNT#205L, count(distinct ss_list_price#250) AS B3_CNTD#206L], HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_list_price#250)), count(ss_list_price#250), count(distinct ss_list_price#250)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -918803318,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#250, sum#394, count#395L, count#397L] Keys: [] Functions [3]: [merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250), partial_count(distinct ss_list_price#250)] Aggregate Attributes [3]: [avg(UnscaledValue(ss_list_price#250))#342, count(ss_list_price#250)#343L, count(ss_list_price#250)#344L] Results [4]: [sum#394, count#395L, count#397L, count#400L] "
          },
          "1" : {
            "sign" : -1101768100,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 35130000,
            "rowCount" : 878250,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_list_price#250, sum#394, count#395L, count#397L] Keys [1]: [ss_list_price#250] Functions [2]: [merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#250))#342, count(ss_list_price#250)#343L] Results [4]: [ss_list_price#250, sum#394, count#395L, count#397L] "
          },
          "2" : {
            "sign" : -549463683,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [ss_list_price#250, sum#394, count#395L, count#397L] Arguments: 2 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "ShuffleQueryStage",
          "toId" : 1,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250), partial_count(distinct ss_list_price#250)], output=[sum#394, count#395L, count#397L, count#400L])\n+- HashAggregate(keys=[ss_list_price#250], functions=[merge_avg(UnscaledValue(ss_list_price#250)), merge_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n   +- ShuffleQueryStage 2\n      +- Exchange hashpartitioning(ss_list_price#250, 200), ENSURE_REQUIREMENTS, [plan_id=317]\n         +- *(3) HashAggregate(keys=[ss_list_price#250], functions=[partial_avg(UnscaledValue(ss_list_price#250)), partial_count(ss_list_price#250)], output=[ss_list_price#250, sum#394, count#395L, count#397L])\n            +- *(3) Project [ss_list_price#250]\n               +- *(3) Filter (((isnotnull(ss_quantity#248) AND (ss_quantity#248 >= 11)) AND (ss_quantity#248 <= 15)) AND ((((ss_list_price#250 >= 66.00) AND (ss_list_price#250 <= 76.00)) OR ((ss_coupon_amt#257 >= 920.00) AND (ss_coupon_amt#257 <= 1920.00))) OR ((ss_wholesale_cost#249 >= 4.00) AND (ss_wholesale_cost#249 <= 24.00))))\n                  +- *(3) ColumnarToRow\n                     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#248,ss_wholesale_cost#249,ss_list_price#250,ss_coupon_amt#257,ss_sold_date_sk#261] Batched: true, DataFilters: [isnotnull(ss_quantity#248), (ss_quantity#248 >= 11), (ss_quantity#248 <= 15), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,11), LessThanOrEqual(ss_quantity,15), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 35130000,
        "inputRowCount" : 878250
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "2" : [ 69226, 88429, 80070, 93401, 71648, 69160, 78952, 73191, 82103, 92465, 84570, 89174, 84935, 89479, 85434, 76201, 65794, 82156, 68048, 84231, 95993, 85249, 81376, 83225, 87386, 88994, 50483, 73343, 83496, 67774, 70866, 74959, 87877, 77924, 68771, 86012, 80764, 78871, 69622, 93196, 74318, 70599, 73889, 88613, 70363, 75657, 72591, 77924, 82156, 87563, 79459, 68607, 66411, 63620, 70833, 86306, 97251, 64319, 61196, 74366, 69476, 74526, 75910, 89662, 88572, 73651, 74093, 82629, 72428, 87971, 72186, 105318, 85426, 68669, 78254, 83015, 95509, 65710, 75522, 61149, 90209, 94798, 95570, 92186, 65191, 64791, 77524, 81616, 72959, 76220, 69878, 70805, 76038, 70310, 84728, 74450, 63211, 64413, 86200, 87546, 58102, 83731, 71540, 77355, 68103, 63145, 86930, 101228, 71350, 84552, 67457, 73896, 72350, 82767, 77144, 82425, 78797, 78470, 81492, 73785, 75114, 90208, 74533, 69410, 101413, 86409, 82716, 83051, 80389, 79225, 70296, 88700, 75705, 77679, 66675, 91410, 82233, 79200, 74983, 82127, 98804, 95429, 74155, 79873, 69020, 81820, 75345, 72637, 73555, 81327, 82775, 97560, 67437, 94025, 87250, 85744, 95671, 75773, 83728, 72221, 79539, 64905, 83555, 86144, 77756, 74957, 71294, 83778, 78194, 75743, 85935, 85049, 61177, 73474, 79729, 83422, 87823, 89503, 76904, 70638, 71295, 64670, 78728, 81266, 74846, 64711, 80277, 77156, 106311, 80980, 80930, 79887, 67202, 88570, 74695, 88838, 76061, 76366, 77639, 68862 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 210,
        "FinishedTasksTotalTimeInMs" : 192243.0,
        "FinishedTasksDistributionInMs" : [ 168.0, 366.0, 441.0, 603.0, 12439.0 ]
      },
      "QueryStageOptimizationId" : 7,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 10 ],
      "Objectives" : {
        "DurationInMs" : 15279,
        "TotalTasksDurationInMs" : 621,
        "IOBytes" : {
          "Total" : 15034870,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 15034796,
            "SW" : 74
          }
        }
      }
    },
    "3" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -1261157858,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 32,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L] "
          },
          "1" : {
            "sign" : 758798782,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 64115024,
                "rowCount" : 4007189
              },
              "compileTime" : {
                "sizeInBytes" : 64115024,
                "rowCount" : 4007189
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_list_price#273] "
          },
          "2" : {
            "sign" : -1256505151,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 609092728,
                "rowCount" : 4007189
              },
              "compileTime" : {
                "sizeInBytes" : 609092728,
                "rowCount" : 4007189
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_quantity#271) AND (((ss_quantity#271 >= 16) AND (ss_quantity#271 <= 20)) AND ((((ss_list_price#273 >= 142.00) AND (ss_list_price#273 <= 152.00)) OR ((ss_coupon_amt#280 >= 3054.00) AND (ss_coupon_amt#280 <= 4054.00))) OR ((ss_wholesale_cost#272 >= 80.00) AND (ss_wholesale_cost#272 <= 100.00))))) "
          },
          "3" : {
            "sign" : 1813746155,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              },
              "compileTime" : {
                "sizeInBytes" : 43776970976,
                "rowCount" : 288006388
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#262, ss_item_sk#263, ss_customer_sk#264, ss_cdemo_sk#265, ss_hdemo_sk#266, ss_addr_sk#267, ss_store_sk#268, ss_promo_sk#269, ss_ticket_number#270L, ss_quantity#271, ss_wholesale_cost#272, ss_list_price#273, ss_sales_price#274, ss_ext_discount_amt#275, ss_ext_sales_price#276, ss_ext_wholesale_cost#277, ss_ext_list_price#278, ss_ext_tax#279, ss_coupon_amt#280, ss_net_paid#281, ss_net_paid_inc_tax#282, ss_net_profit#283, ss_sold_date_sk#284], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalRelation",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [cast((avg(UnscaledValue(ss_list_price#273)) / 100.0) as decimal(11,6)) AS B4_LP#207, count(ss_list_price#273) AS B4_CNT#208L, count(distinct ss_list_price#273) AS B4_CNTD#209L]\n+- Project [ss_list_price#273]\n   +- Filter (isnotnull(ss_quantity#271) AND (((ss_quantity#271 >= 16) AND (ss_quantity#271 <= 20)) AND ((((ss_list_price#273 >= 142.00) AND (ss_list_price#273 <= 152.00)) OR ((ss_coupon_amt#280 >= 3054.00) AND (ss_coupon_amt#280 <= 4054.00))) OR ((ss_wholesale_cost#272 >= 80.00) AND (ss_wholesale_cost#272 <= 100.00)))))\n      +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#262,ss_item_sk#263,ss_customer_sk#264,ss_cdemo_sk#265,ss_hdemo_sk#266,ss_addr_sk#267,ss_store_sk#268,ss_promo_sk#269,ss_ticket_number#270L,ss_quantity#271,ss_wholesale_cost#272,ss_list_price#273,ss_sales_price#274,ss_ext_discount_amt#275,ss_ext_sales_price#276,ss_ext_wholesale_cost#277,ss_ext_list_price#278,ss_ext_tax#279,ss_coupon_amt#280,ss_net_paid#281,ss_net_paid_inc_tax#282,ss_net_profit#283,ss_sold_date_sk#284] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 852640970,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 32,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [1]: [ss_list_price#273] Keys [1]: [ss_list_price#273] Functions [2]: [partial_avg(UnscaledValue(ss_list_price#273)), partial_count(ss_list_price#273)] Aggregate Attributes [2]: [avg(UnscaledValue(ss_list_price#273))#345, count(ss_list_price#273)#346L] Results [4]: [ss_list_price#273, sum#404, count#405L, count#407L] "
          },
          "1" : {
            "sign" : 40442009,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 64115024,
            "rowCount" : 4007189,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [ss_list_price#273] Input [5]: [ss_quantity#271, ss_wholesale_cost#272, ss_list_price#273, ss_coupon_amt#280, ss_sold_date_sk#284] "
          },
          "2" : {
            "sign" : 1572050312,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 64115024,
            "rowCount" : 4007189,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [5]: [ss_quantity#271, ss_wholesale_cost#272, ss_list_price#273, ss_coupon_amt#280, ss_sold_date_sk#284] Condition : (((isnotnull(ss_quantity#271) AND (ss_quantity#271 >= 16)) AND (ss_quantity#271 <= 20)) AND ((((ss_list_price#273 >= 142.00) AND (ss_list_price#273 <= 152.00)) OR ((ss_coupon_amt#280 >= 3054.00) AND (ss_coupon_amt#280 <= 4054.00))) OR ((ss_wholesale_cost#272 >= 80.00) AND (ss_wholesale_cost#272 <= 100.00)))) "
          },
          "3" : {
            "sign" : -1468614116,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 64115024,
            "rowCount" : 4007189,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [5]: [ss_quantity#271, ss_wholesale_cost#272, ss_list_price#273, ss_coupon_amt#280, ss_sold_date_sk#284] Batched: true Location: CatalogFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales] PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,16), LessThanOrEqual(ss_quantity,20), Or(Or(And(GreaterThanOrEqual(ss_list_price,142.00),LessThanOrEqual(ss_list_price,152.00)),And(GreaterThanOrEqual(ss_coupon_amt,3054.00),LessThanOrEqual(ss_coupon_amt,4054.00))),And(GreaterThanOrEqual(ss_wholesale_cost,80.00),LessThanOrEqual(ss_wholesale_cost,100.00)))] ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:decimal(7,2)> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[ss_list_price#273], functions=[partial_avg(UnscaledValue(ss_list_price#273)), partial_count(ss_list_price#273)], output=[ss_list_price#273, sum#404, count#405L, count#407L])\n+- Project [ss_list_price#273]\n   +- Filter (((isnotnull(ss_quantity#271) AND (ss_quantity#271 >= 16)) AND (ss_quantity#271 <= 20)) AND ((((ss_list_price#273 >= 142.00) AND (ss_list_price#273 <= 152.00)) OR ((ss_coupon_amt#280 >= 3054.00) AND (ss_coupon_amt#280 <= 4054.00))) OR ((ss_wholesale_cost#272 >= 80.00) AND (ss_wholesale_cost#272 <= 100.00))))\n      +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_quantity#271,ss_wholesale_cost#272,ss_list_price#273,ss_coupon_amt#280,ss_sold_date_sk#284] Batched: true, DataFilters: [isnotnull(ss_quantity#271), (ss_quantity#271 >= 16), (ss_quantity#271 <= 20), ((((ss_list_price#..., Format: Parquet, Location: CatalogFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,16), LessThanOrEqual(ss_quantity,20), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:decimal(7,2),ss_list_price:decimal(7,2),ss_coupon_amt:de...\n"
      },
      "IM" : {
        "inputSizeInBytes" : 64115024,
        "inputRowCount" : 4007189
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 3,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 4 ],
      "Objectives" : {
        "DurationInMs" : 39938,
        "TotalTasksDurationInMs" : 84171,
        "IOBytes" : {
          "Total" : 2445022052,
          "Details" : {
            "IR" : 2424587878,
            "IW" : 0,
            "SR" : 0,
            "SW" : 20434174
          }
        }
      }
    }
  },
  "SQLStartTimeInMs" : 1702226809916,
  "SQLEndTimeInMs" : 1702226875383,
  "Objectives" : {
    "DurationInMs" : 65467,
    "IOBytes" : {
      "Total" : 14753491920,
      "Details" : {
        "IR" : 14547527268,
        "IW" : 0,
        "SR" : 102982326,
        "SW" : 102982326
      }
    }
  }
}
