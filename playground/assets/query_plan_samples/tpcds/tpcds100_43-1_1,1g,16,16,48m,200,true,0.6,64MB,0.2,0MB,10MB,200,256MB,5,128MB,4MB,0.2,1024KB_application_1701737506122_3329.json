{
  "CompileTimeLQP" : {
    "LQP" : {
      "operators" : {
        "12" : {
          "sign" : 1921179994,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 39926379296,
          "rowCount" : 262673548,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#57) AND isnotnull(ss_store_sk#41)) AND dynamicpruning#106 [ss_sold_date_sk#57]) "
        },
        "8" : {
          "sign" : -121552870,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 18432,
          "rowCount" : 576,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_date_sk#7, d_day_name#21] "
        },
        "4" : {
          "sign" : 1998948853,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 46228243120,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63] "
        },
        "15" : {
          "sign" : -2044494719,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 82867,
          "rowCount" : 173,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58)) "
        },
        "11" : {
          "sign" : -2134675051,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 6304165152,
          "rowCount" : 262673548,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57] "
        },
        "9" : {
          "sign" : -461626410,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 141696,
          "rowCount" : 576,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7)) "
        },
        "13" : {
          "sign" : 1121573603,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 41806893656,
          "rowCount" : 275045353,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#35, ss_item_sk#36, ss_customer_sk#37, ss_cdemo_sk#38, ss_hdemo_sk#39, ss_addr_sk#40, ss_store_sk#41, ss_promo_sk#42, ss_ticket_number#43L, ss_quantity#44, ss_wholesale_cost#45, ss_list_price#46, ss_sales_price#47, ss_ext_discount_amt#48, ss_ext_sales_price#49, ss_ext_wholesale_cost#50, ss_ext_list_price#51, ss_ext_tax#52, ss_coupon_amt#53, ss_net_paid#54, ss_net_paid_inc_tax#55, ss_net_profit#56, ss_sold_date_sk#57], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "16" : {
          "sign" : 589222546,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#58, s_store_id#59, s_rec_start_date#60, s_rec_end_date#61, s_closed_date_sk#62, s_store_name#63, s_number_employees#64, s_floor_space#65, s_hours#66, s_manager#67, s_market_id#68, s_geography_class#69, s_market_desc#70, s_market_manager#71, s_division_id#72, s_division_name#73, s_company_id#74, s_company_name#75, s_street_number#76, s_street_name#77, s_street_type#78, s_suite_number#79, s_city#80, s_county#81, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "5" : {
          "sign" : 1345741229,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 50851067432,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#58 = ss_store_sk#41) "
        },
        "10" : {
          "sign" : 1611378979,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 17970054,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#7, d_date_id#8, d_date#9, d_month_seq#10, d_week_seq#11, d_quarter_seq#12, d_year#13, d_dow#14, d_moy#15, d_dom#16, d_qoy#17, d_fy_year#18, d_fy_quarter_seq#19, d_fy_week_seq#20, d_day_name#21, d_quarter_name#22, d_holiday#23, d_weekend#24, d_following_holiday#25, d_first_dom#26, d_last_dom#27, d_same_day_ly#28, d_same_day_lq#29, d_current_day#30, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "6" : {
          "sign" : -194399986,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 10621623400,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_day_name#21, ss_store_sk#41, ss_sales_price#47] "
        },
        "1" : {
          "sign" : -1783691161,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
          "sizeInBytes" : 49140,
          "rowCount" : 455,
          "isRuntime" : false,
          "predicate" : " (unknown) LocalLimit Arguments: 100 "
        },
        "14" : {
          "sign" : -1126954785,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 9688,
          "rowCount" : 173,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_store_sk#58, s_store_id#59, s_store_name#63] "
        },
        "0" : {
          "sign" : -1558868446,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
          "sizeInBytes" : 10400,
          "rowCount" : 100,
          "isRuntime" : false,
          "predicate" : " (unknown) GlobalLimit Arguments: 100 "
        },
        "2" : {
          "sign" : 132051576,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
          "sizeInBytes" : 49140,
          "rowCount" : 455,
          "isRuntime" : false,
          "predicate" : " (unknown) Sort Arguments: [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#0 ASC NULLS FIRST, mon_sales#1 ASC NULLS FIRST, tue_sales#2 ASC NULLS FIRST, wed_sales#3 ASC NULLS FIRST, thu_sales#4 ASC NULLS FIRST, fri_sales#5 ASC NULLS FIRST, sat_sales#6 ASC NULLS FIRST], true "
        },
        "7" : {
          "sign" : -1911093306,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 12745948080,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#7 = ss_sold_date_sk#57) "
        },
        "3" : {
          "sign" : 1231433057,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 49140,
          "rowCount" : 455,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#0, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#1, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#2, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#3, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#4, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#5, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#6] "
        }
      },
      "links" : [ {
        "fromId" : 10,
        "fromName" : "LogicalRelation",
        "toId" : 9,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 9,
        "fromName" : "Filter",
        "toId" : 8,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 8,
        "fromName" : "Project",
        "toId" : 7,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 13,
        "fromName" : "LogicalRelation",
        "toId" : 12,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 8,
        "fromName" : "Project",
        "toId" : 12,
        "toName" : "Filter",
        "linkType" : "Subquery"
      }, {
        "fromId" : 12,
        "fromName" : "Filter",
        "toId" : 11,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 11,
        "fromName" : "Project",
        "toId" : 7,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 7,
        "fromName" : "Join",
        "toId" : 6,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 6,
        "fromName" : "Project",
        "toId" : 5,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 16,
        "fromName" : "LogicalRelation",
        "toId" : 15,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 15,
        "fromName" : "Filter",
        "toId" : 14,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 14,
        "fromName" : "Project",
        "toId" : 5,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 5,
        "fromName" : "Join",
        "toId" : 4,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 4,
        "fromName" : "Project",
        "toId" : 3,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 3,
        "fromName" : "Aggregate",
        "toId" : 2,
        "toName" : "Sort",
        "linkType" : "Operator"
      }, {
        "fromId" : 2,
        "fromName" : "Sort",
        "toId" : 1,
        "toName" : "LocalLimit",
        "linkType" : "Operator"
      }, {
        "fromId" : 1,
        "fromName" : "LocalLimit",
        "toId" : 0,
        "toName" : "GlobalLimit",
        "linkType" : "Operator"
      } ],
      "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#0 ASC NULLS FIRST, mon_sales#1 ASC NULLS FIRST, tue_sales#2 ASC NULLS FIRST, wed_sales#3 ASC NULLS FIRST, thu_sales#4 ASC NULLS FIRST, fri_sales#5 ASC NULLS FIRST, sat_sales#6 ASC NULLS FIRST], true\n      +- Aggregate [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#0, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#1, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#2, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#3, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#4, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#5, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#6]\n         +- Project [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63]\n            +- Join Inner, (s_store_sk#58 = ss_store_sk#41)\n               :- Project [d_day_name#21, ss_store_sk#41, ss_sales_price#47]\n               :  +- Join Inner, (d_date_sk#7 = ss_sold_date_sk#57)\n               :     :- Project [d_date_sk#7, d_day_name#21]\n               :     :  +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n               :     :     +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_date_id#8,d_date#9,d_month_seq#10,d_week_seq#11,d_quarter_seq#12,d_year#13,d_dow#14,d_moy#15,d_dom#16,d_qoy#17,d_fy_year#18,d_fy_quarter_seq#19,d_fy_week_seq#20,d_day_name#21,d_quarter_name#22,d_holiday#23,d_weekend#24,d_following_holiday#25,d_first_dom#26,d_last_dom#27,d_same_day_ly#28,d_same_day_lq#29,d_current_day#30,... 4 more fields] parquet\n               :     +- Project [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57]\n               :        +- Filter ((isnotnull(ss_sold_date_sk#57) AND isnotnull(ss_store_sk#41)) AND dynamicpruning#106 [ss_sold_date_sk#57])\n               :           :  +- Project [d_date_sk#7, d_day_name#21]\n               :           :     +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n               :           :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_date_id#8,d_date#9,d_month_seq#10,d_week_seq#11,d_quarter_seq#12,d_year#13,d_dow#14,d_moy#15,d_dom#16,d_qoy#17,d_fy_year#18,d_fy_quarter_seq#19,d_fy_week_seq#20,d_day_name#21,d_quarter_name#22,d_holiday#23,d_weekend#24,d_following_holiday#25,d_first_dom#26,d_last_dom#27,d_same_day_ly#28,d_same_day_lq#29,d_current_day#30,... 4 more fields] parquet\n               :           +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#35,ss_item_sk#36,ss_customer_sk#37,ss_cdemo_sk#38,ss_hdemo_sk#39,ss_addr_sk#40,ss_store_sk#41,ss_promo_sk#42,ss_ticket_number#43L,ss_quantity#44,ss_wholesale_cost#45,ss_list_price#46,ss_sales_price#47,ss_ext_discount_amt#48,ss_ext_sales_price#49,ss_ext_wholesale_cost#50,ss_ext_list_price#51,ss_ext_tax#52,ss_coupon_amt#53,ss_net_paid#54,ss_net_paid_inc_tax#55,ss_net_profit#56,ss_sold_date_sk#57] parquet\n               +- Project [s_store_sk#58, s_store_id#59, s_store_name#63]\n                  +- Filter ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58))\n                     +- Relation spark_catalog.tpcds_100.store[s_store_sk#58,s_store_id#59,s_rec_start_date#60,s_rec_end_date#61,s_closed_date_sk#62,s_store_name#63,s_number_employees#64,s_floor_space#65,s_hours#66,s_manager#67,s_market_id#68,s_geography_class#69,s_market_desc#70,s_market_manager#71,s_division_id#72,s_division_name#73,s_company_id#74,s_company_name#75,s_street_number#76,s_street_name#77,s_street_type#78,s_suite_number#79,s_city#80,s_county#81,... 5 more fields] parquet\n"
    },
    "IM" : {
      "inputSizeInBytes" : 41825056268,
      "inputRowCount" : 275118804
    },
    "PD" : { },
    "Configuration" : {
      "theta_c" : [ {
        "spark.executor.memory" : "1g"
      }, {
        "spark.executor.cores" : "1"
      }, {
        "spark.executor.instances" : "16"
      }, {
        "spark.default.parallelism" : "16"
      }, {
        "spark.reducer.maxSizeInFlight" : "48m"
      }, {
        "spark.shuffle.sort.bypassMergeThreshold" : "200"
      }, {
        "spark.shuffle.compress" : "true"
      }, {
        "spark.memory.fraction" : "0.6"
      } ],
      "theta_p" : [ {
        "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
      }, {
        "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
      }, {
        "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
      }, {
        "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
      }, {
        "spark.sql.shuffle.partitions" : "200"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
      }, {
        "spark.sql.files.maxPartitionBytes" : "128MB"
      }, {
        "spark.sql.files.openCostInBytes" : "4MB"
      } ],
      "theta_s" : [ {
        "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
      }, {
        "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
      } ]
    }
  },
  "RuntimeLQPs" : {
    "1" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : -121552870,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 18432,
            "rowCount" : 576,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#7, d_day_name#21] "
          },
          "8" : {
            "sign" : -1175439362,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#7, d_day_name#21], BroadcastQueryStage 0 "
          },
          "4" : {
            "sign" : 1195793490,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1253289046101440,
            "rowCount" : 16490645343440,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63] "
          },
          "15" : {
            "sign" : -958470055,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051784,
            "rowCount" : 172,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#58, s_store_id#59, s_store_name#63], BroadcastQueryStage 1 "
          },
          "11" : {
            "sign" : 1121573603,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#35, ss_item_sk#36, ss_customer_sk#37, ss_cdemo_sk#38, ss_hdemo_sk#39, ss_addr_sk#40, ss_store_sk#41, ss_promo_sk#42, ss_ticket_number#43L, ss_quantity#44, ss_wholesale_cost#45, ss_list_price#46, ss_sales_price#47, ss_ext_discount_amt#48, ss_ext_sales_price#49, ss_ext_wholesale_cost#50, ss_ext_list_price#51, ss_ext_tax#52, ss_coupon_amt#53, ss_net_paid#54, ss_net_paid_inc_tax#55, ss_net_profit#56, ss_sold_date_sk#57], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "9" : {
            "sign" : -433007124,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57] "
          },
          "13" : {
            "sign" : -461626410,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 141696,
            "rowCount" : 576,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7)) "
          },
          "5" : {
            "sign" : -513649396,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 1385214208848960,
            "rowCount" : 16490645343440,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#58 = ss_store_sk#41) "
          },
          "10" : {
            "sign" : -1034235855,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#57) AND isnotnull(ss_store_sk#41)) AND dynamicpruning#130 [ss_sold_date_sk#57]) "
          },
          "6" : {
            "sign" : 716329279,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 3835033800800,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_day_name#21, ss_store_sk#41, ss_sales_price#47] "
          },
          "1" : {
            "sign" : -542580922,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 1715027115717760,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "14" : {
            "sign" : 1611378979,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#7, d_date_id#8, d_date#9, d_month_seq#10, d_week_seq#11, d_quarter_seq#12, d_year#13, d_dow#14, d_moy#15, d_dom#16, d_qoy#17, d_fy_year#18, d_fy_quarter_seq#19, d_fy_week_seq#20, d_day_name#21, d_quarter_name#22, d_holiday#23, d_weekend#24, d_following_holiday#25, d_first_dom#26, d_last_dom#27, d_same_day_ly#28, d_same_day_lq#29, d_current_day#30, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : -5149943,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 10400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 57418163,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 1715027115717760,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#107 ASC NULLS FIRST, mon_sales#108 ASC NULLS FIRST, tue_sales#109 ASC NULLS FIRST, wed_sales#110 ASC NULLS FIRST, thu_sales#111 ASC NULLS FIRST, fri_sales#112 ASC NULLS FIRST, sat_sales#113 ASC NULLS FIRST], true "
          },
          "7" : {
            "sign" : 88758085,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 4602040560960,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#7 = ss_sold_date_sk#57) "
          },
          "3" : {
            "sign" : 112640084,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 1715027115717760,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#107, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#108, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#109, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#110, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#111, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#112, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#113] "
          }
        },
        "links" : [ {
          "fromId" : 8,
          "fromName" : "LogicalQueryStage",
          "toId" : 7,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "LogicalRelation",
          "toId" : 10,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 10,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 10,
          "fromName" : "Filter",
          "toId" : 9,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Project",
          "toId" : 7,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Join",
          "toId" : 6,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Project",
          "toId" : 5,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "LogicalQueryStage",
          "toId" : 5,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Join",
          "toId" : 4,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Project",
          "toId" : 3,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Aggregate",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#107 ASC NULLS FIRST, mon_sales#108 ASC NULLS FIRST, tue_sales#109 ASC NULLS FIRST, wed_sales#110 ASC NULLS FIRST, thu_sales#111 ASC NULLS FIRST, fri_sales#112 ASC NULLS FIRST, sat_sales#113 ASC NULLS FIRST], true\n      +- Aggregate [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#107, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#108, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#109, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#110, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#111, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#112, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#113]\n         +- Project [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63]\n            +- Join Inner, (s_store_sk#58 = ss_store_sk#41)\n               :- Project [d_day_name#21, ss_store_sk#41, ss_sales_price#47]\n               :  +- Join Inner, (d_date_sk#7 = ss_sold_date_sk#57)\n               :     :- LogicalQueryStage Project [d_date_sk#7, d_day_name#21], BroadcastQueryStage 0\n               :     +- Project [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57]\n               :        +- Filter ((isnotnull(ss_sold_date_sk#57) AND isnotnull(ss_store_sk#41)) AND dynamicpruning#130 [ss_sold_date_sk#57])\n               :           :  +- Project [d_date_sk#7, d_day_name#21]\n               :           :     +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n               :           :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_date_id#8,d_date#9,d_month_seq#10,d_week_seq#11,d_quarter_seq#12,d_year#13,d_dow#14,d_moy#15,d_dom#16,d_qoy#17,d_fy_year#18,d_fy_quarter_seq#19,d_fy_week_seq#20,d_day_name#21,d_quarter_name#22,d_holiday#23,d_weekend#24,d_following_holiday#25,d_first_dom#26,d_last_dom#27,d_same_day_ly#28,d_same_day_lq#29,d_current_day#30,... 4 more fields] parquet\n               :           +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#35,ss_item_sk#36,ss_customer_sk#37,ss_cdemo_sk#38,ss_hdemo_sk#39,ss_addr_sk#40,ss_store_sk#41,ss_promo_sk#42,ss_ticket_number#43L,ss_quantity#44,ss_wholesale_cost#45,ss_list_price#46,ss_sales_price#47,ss_ext_discount_amt#48,ss_ext_sales_price#49,ss_ext_wholesale_cost#50,ss_ext_list_price#51,ss_ext_tax#52,ss_coupon_amt#53,ss_net_paid#54,ss_net_paid_inc_tax#55,ss_net_profit#56,ss_sold_date_sk#57] parquet\n               +- LogicalQueryStage Project [s_store_sk#58, s_store_id#59, s_store_name#63], BroadcastQueryStage 1\n"
      },
      "IM" : {
        "inputSizeInBytes" : 41808996936,
        "inputRowCount" : 275045890
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226983235,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 4069,
        "IOBytes" : {
          "Total" : 136493941,
          "Details" : {
            "IR" : 135908901,
            "IW" : 0,
            "SR" : 292520,
            "SW" : 292520
          }
        }
      }
    },
    "2" : {
      "LQP" : {
        "operators" : {
          "0" : {
            "sign" : 1253752910,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 10400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "1" : {
            "sign" : 2006139993,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 272896,
            "rowCount" : 2624,
            "isRuntime" : true,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 960736356,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 272896,
            "rowCount" : 2624,
            "isRuntime" : true,
            "predicate" : " (unknown) Sort Arguments: [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#107 ASC NULLS FIRST, mon_sales#108 ASC NULLS FIRST, tue_sales#109 ASC NULLS FIRST, wed_sales#110 ASC NULLS FIRST, thu_sales#111 ASC NULLS FIRST, fri_sales#112 ASC NULLS FIRST, sat_sales#113 ASC NULLS FIRST], true "
          },
          "3" : {
            "sign" : 2139848331,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 272896,
            "rowCount" : 2624,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#107, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#108, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#109, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#110, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#111, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#112, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#113], HashAggregate(keys=[s_store_name#63, s_store_id#59], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))]) "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalQueryStage",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#107 ASC NULLS FIRST, mon_sales#108 ASC NULLS FIRST, tue_sales#109 ASC NULLS FIRST, wed_sales#110 ASC NULLS FIRST, thu_sales#111 ASC NULLS FIRST, fri_sales#112 ASC NULLS FIRST, sat_sales#113 ASC NULLS FIRST], true\n      +- LogicalQueryStage Aggregate [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#107, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#108, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#109, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#110, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#111, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#112, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#113], HashAggregate(keys=[s_store_name#63, s_store_id#59], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 272896,
        "inputRowCount" : 2624
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702226986831,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 473,
        "IOBytes" : {
          "Total" : 292520,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 292520,
            "SW" : 0
          }
        }
      }
    }
  },
  "RuntimeQSs" : {
    "0" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -121552870,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 18432,
                "rowCount" : 576
              },
              "compileTime" : {
                "sizeInBytes" : 18432,
                "rowCount" : 576
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#7, d_day_name#21] "
          },
          "1" : {
            "sign" : -461626410,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 141696,
                "rowCount" : 576
              },
              "compileTime" : {
                "sizeInBytes" : 141696,
                "rowCount" : 576
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7)) "
          },
          "2" : {
            "sign" : 1611378979,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#7, d_date_id#8, d_date#9, d_month_seq#10, d_week_seq#11, d_quarter_seq#12, d_year#13, d_dow#14, d_moy#15, d_dom#16, d_qoy#17, d_fy_year#18, d_fy_quarter_seq#19, d_fy_week_seq#20, d_day_name#21, d_quarter_name#22, d_holiday#23, d_weekend#24, d_following_holiday#25, d_first_dom#26, d_last_dom#27, d_same_day_ly#28, d_same_day_lq#29, d_current_day#30, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_date_sk#7, d_day_name#21]\n+- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n   +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_date_id#8,d_date#9,d_month_seq#10,d_week_seq#11,d_quarter_seq#12,d_year#13,d_dow#14,d_moy#15,d_dom#16,d_qoy#17,d_fy_year#18,d_fy_quarter_seq#19,d_fy_week_seq#20,d_day_name#21,d_quarter_name#22,d_holiday#23,d_weekend#24,d_following_holiday#25,d_first_dom#26,d_last_dom#27,d_same_day_ly#28,d_same_day_lq#29,d_current_day#30,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 1560691772,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 18432,
            "rowCount" : 576,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [2]: [d_date_sk#7, d_day_name#21] Input [3]: [d_date_sk#7, d_year#13, d_day_name#21] "
          },
          "1" : {
            "sign" : 1073755648,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 18432,
            "rowCount" : 576,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [d_date_sk#7, d_year#13, d_day_name#21] Condition : ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7)) "
          },
          "2" : {
            "sign" : 1317394643,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 18432,
            "rowCount" : 576,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.date_dim Output [3]: [d_date_sk#7, d_year#13, d_day_name#21] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim] PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1998), IsNotNull(d_date_sk)] ReadSchema: struct<d_date_sk:int,d_year:int,d_day_name:string> "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.date_dim",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_date_sk#7, d_day_name#21]\n+- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n   +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_year#13,d_day_name#21] Batched: true, DataFilters: [isnotnull(d_year#13), (d_year#13 = 1998), isnotnull(d_date_sk#7)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1998), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_day_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 18432,
        "inputRowCount" : 576
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 0,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 1 ],
      "Objectives" : {
        "DurationInMs" : 1470,
        "TotalTasksDurationInMs" : 1461,
        "IOBytes" : {
          "Total" : 94128,
          "Details" : {
            "IR" : 94128,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "1" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -1126954785,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 9688,
                "rowCount" : 173
              },
              "compileTime" : {
                "sizeInBytes" : 9688,
                "rowCount" : 173
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#58, s_store_id#59, s_store_name#63] "
          },
          "1" : {
            "sign" : -2044494719,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 82867,
                "rowCount" : 173
              },
              "compileTime" : {
                "sizeInBytes" : 82867,
                "rowCount" : 173
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58)) "
          },
          "2" : {
            "sign" : 589222546,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#58, s_store_id#59, s_rec_start_date#60, s_rec_end_date#61, s_closed_date_sk#62, s_store_name#63, s_number_employees#64, s_floor_space#65, s_hours#66, s_manager#67, s_market_id#68, s_geography_class#69, s_market_desc#70, s_market_manager#71, s_division_id#72, s_division_name#73, s_company_id#74, s_company_name#75, s_street_number#76, s_street_name#77, s_street_type#78, s_suite_number#79, s_city#80, s_county#81, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_store_sk#58, s_store_id#59, s_store_name#63]\n+- Filter ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58))\n   +- Relation spark_catalog.tpcds_100.store[s_store_sk#58,s_store_id#59,s_rec_start_date#60,s_rec_end_date#61,s_closed_date_sk#62,s_store_name#63,s_number_employees#64,s_floor_space#65,s_hours#66,s_manager#67,s_market_id#68,s_geography_class#69,s_market_desc#70,s_market_manager#71,s_division_id#72,s_division_name#73,s_company_id#74,s_company_name#75,s_street_number#76,s_street_name#77,s_street_type#78,s_suite_number#79,s_city#80,s_county#81,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 96838257,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 9688,
            "rowCount" : 173,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [3]: [s_store_sk#58, s_store_id#59, s_store_name#63] Input [4]: [s_store_sk#58, s_store_id#59, s_store_name#63, s_gmt_offset#85] "
          },
          "1" : {
            "sign" : 1152245651,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 9688,
            "rowCount" : 173,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [4]: [s_store_sk#58, s_store_id#59, s_store_name#63, s_gmt_offset#85] Condition : ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58)) "
          },
          "2" : {
            "sign" : 1756154468,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 9688,
            "rowCount" : 173,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store Output [4]: [s_store_sk#58, s_store_id#59, s_store_name#63, s_gmt_offset#85] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store] PushedFilters: [IsNotNull(s_gmt_offset), EqualTo(s_gmt_offset,-6.00), IsNotNull(s_store_sk)] ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string,s_gmt_offset:decimal(5,2)> "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_store_sk#58, s_store_id#59, s_store_name#63]\n+- Filter ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58))\n   +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#58,s_store_id#59,s_store_name#63,s_gmt_offset#85] Batched: true, DataFilters: [isnotnull(s_gmt_offset#85), (s_gmt_offset#85 = -6.00), isnotnull(s_store_sk#58)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_gmt_offset), EqualTo(s_gmt_offset,-6.00), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string,s_gmt_offset:decimal(5,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 9688,
        "inputRowCount" : 173
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 1,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 2 ],
      "Objectives" : {
        "DurationInMs" : 1458,
        "TotalTasksDurationInMs" : 1454,
        "IOBytes" : {
          "Total" : 16072,
          "Details" : {
            "IR" : 16072,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "2" : {
      "QSLogical" : {
        "operators" : {
          "4" : {
            "sign" : 1964351901,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 12745948080,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 12745948080,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#7 = ss_sold_date_sk#57) "
          },
          "5" : {
            "sign" : -433007124,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57] "
          },
          "6" : {
            "sign" : -1034235855,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#57) AND isnotnull(ss_store_sk#41)) AND dynamicpruning#130 [ss_sold_date_sk#57]) "
          },
          "1" : {
            "sign" : 1559363518,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 46228243120,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 46228243120,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63] "
          },
          "0" : {
            "sign" : 1697763452,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 49140,
                "rowCount" : 455
              },
              "compileTime" : {
                "sizeInBytes" : 49140,
                "rowCount" : 455
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#107, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#108, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#109, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#110, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#111, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#112, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#113] "
          },
          "2" : {
            "sign" : -2001616828,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 50851067432,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 50851067432,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#58 = ss_store_sk#41) "
          },
          "7" : {
            "sign" : 1121573603,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              },
              "compileTime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#35, ss_item_sk#36, ss_customer_sk#37, ss_cdemo_sk#38, ss_hdemo_sk#39, ss_addr_sk#40, ss_store_sk#41, ss_promo_sk#42, ss_ticket_number#43L, ss_quantity#44, ss_wholesale_cost#45, ss_list_price#46, ss_sales_price#47, ss_ext_discount_amt#48, ss_ext_sales_price#49, ss_ext_wholesale_cost#50, ss_ext_list_price#51, ss_ext_tax#52, ss_coupon_amt#53, ss_net_paid#54, ss_net_paid_inc_tax#55, ss_net_profit#56, ss_sold_date_sk#57], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "3" : {
            "sign" : -313180059,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 10621623400,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 10621623400,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_day_name#21, ss_store_sk#41, ss_sales_price#47] "
          }
        },
        "links" : [ {
          "fromId" : 7,
          "fromName" : "LogicalRelation",
          "toId" : 6,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Filter",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#107, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#108, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#109, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#110, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#111, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#112, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#113]\n+- Project [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63]\n   +- Join Inner, (s_store_sk#58 = ss_store_sk#41)\n      :- Project [d_day_name#21, ss_store_sk#41, ss_sales_price#47]\n      :  +- Join Inner, (d_date_sk#7 = ss_sold_date_sk#57)\n      :     :- Project [d_date_sk#7, d_day_name#21]\n      :     :  +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n      :     :     +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_date_id#8,d_date#9,d_month_seq#10,d_week_seq#11,d_quarter_seq#12,d_year#13,d_dow#14,d_moy#15,d_dom#16,d_qoy#17,d_fy_year#18,d_fy_quarter_seq#19,d_fy_week_seq#20,d_day_name#21,d_quarter_name#22,d_holiday#23,d_weekend#24,d_following_holiday#25,d_first_dom#26,d_last_dom#27,d_same_day_ly#28,d_same_day_lq#29,d_current_day#30,... 4 more fields] parquet\n      :     +- Project [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57]\n      :        +- Filter ((isnotnull(ss_sold_date_sk#57) AND isnotnull(ss_store_sk#41)) AND dynamicpruning#130 [ss_sold_date_sk#57])\n      :           :  +- Project [d_date_sk#7, d_day_name#21]\n      :           :     +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n      :           :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_date_id#8,d_date#9,d_month_seq#10,d_week_seq#11,d_quarter_seq#12,d_year#13,d_dow#14,d_moy#15,d_dom#16,d_qoy#17,d_fy_year#18,d_fy_quarter_seq#19,d_fy_week_seq#20,d_day_name#21,d_quarter_name#22,d_holiday#23,d_weekend#24,d_following_holiday#25,d_first_dom#26,d_last_dom#27,d_same_day_ly#28,d_same_day_lq#29,d_current_day#30,... 4 more fields] parquet\n      :           +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#35,ss_item_sk#36,ss_customer_sk#37,ss_cdemo_sk#38,ss_hdemo_sk#39,ss_addr_sk#40,ss_store_sk#41,ss_promo_sk#42,ss_ticket_number#43L,ss_quantity#44,ss_wholesale_cost#45,ss_list_price#46,ss_sales_price#47,ss_ext_discount_amt#48,ss_ext_sales_price#49,ss_ext_wholesale_cost#50,ss_ext_list_price#51,ss_ext_tax#52,ss_coupon_amt#53,ss_net_paid#54,ss_net_paid_inc_tax#55,ss_net_profit#56,ss_sold_date_sk#57] parquet\n      +- Project [s_store_sk#58, s_store_id#59, s_store_name#63]\n         +- Filter ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58))\n            +- Relation spark_catalog.tpcds_100.store[s_store_sk#58,s_store_id#59,s_rec_start_date#60,s_rec_end_date#61,s_closed_date_sk#62,s_store_name#63,s_number_employees#64,s_floor_space#65,s_hours#66,s_manager#67,s_market_id#68,s_geography_class#69,s_market_desc#70,s_market_manager#71,s_division_id#72,s_division_name#73,s_company_id#74,s_company_name#75,s_street_number#76,s_street_name#77,s_street_type#78,s_suite_number#79,s_city#80,s_county#81,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "8" : {
            "sign" : -1363796297,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051784,
            "rowCount" : 172,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [3]: [s_store_sk#58, s_store_id#59, s_store_name#63] Arguments: 1 "
          },
          "4" : {
            "sign" : 1230202255,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 12745948080,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [d_date_sk#7] Right keys [1]: [ss_sold_date_sk#57] Join type: Inner Join condition: None "
          },
          "5" : {
            "sign" : -877531511,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [2]: [d_date_sk#7, d_day_name#21] Arguments: 0 "
          },
          "6" : {
            "sign" : 1305201872,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57] Condition : isnotnull(ss_store_sk#41) "
          },
          "1" : {
            "sign" : 1011744606,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 46228243120,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [4]: [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63] Input [6]: [d_day_name#21, ss_store_sk#41, ss_sales_price#47, s_store_sk#58, s_store_id#59, s_store_name#63] "
          },
          "0" : {
            "sign" : 1677003143,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 49140,
            "rowCount" : 455,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [4]: [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63] Keys [2]: [s_store_name#63, s_store_id#59] Functions [7]: [partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))] Aggregate Attributes [7]: [sum#131L, sum#132L, sum#133L, sum#134L, sum#135L, sum#136L, sum#137L] Results [9]: [s_store_name#63, s_store_id#59, sum#138L, sum#139L, sum#140L, sum#141L, sum#142L, sum#143L, sum#144L] "
          },
          "2" : {
            "sign" : -1336679612,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 50851067432,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_store_sk#41] Right keys [1]: [s_store_sk#58] Join type: Inner Join condition: None "
          },
          "7" : {
            "sign" : 36157312,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [3]: [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales/ss_sold_date_sk=2450816, ... 1822 entries] PartitionFilters: [isnotnull(ss_sold_date_sk#57), dynamicpruningexpression(ss_sold_date_sk#57 IN dynamicpruning#130)] PushedFilters: [IsNotNull(ss_store_sk)] ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)> "
          },
          "3" : {
            "sign" : -527900121,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 10621623400,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [3]: [d_day_name#21, ss_store_sk#41, ss_sales_price#47] Input [5]: [d_date_sk#7, d_day_name#21, ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "BroadcastQueryStage",
          "toId" : 4,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 6,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Filter",
          "toId" : 4,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "BroadcastHashJoin",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "BroadcastQueryStage",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "BroadcastHashJoin",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[s_store_name#63, s_store_id#59], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))], output=[s_store_name#63, s_store_id#59, sum#138L, sum#139L, sum#140L, sum#141L, sum#142L, sum#143L, sum#144L])\n+- Project [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63]\n   +- BroadcastHashJoin [ss_store_sk#41], [s_store_sk#58], Inner, BuildRight, false\n      :- Project [d_day_name#21, ss_store_sk#41, ss_sales_price#47]\n      :  +- BroadcastHashJoin [d_date_sk#7], [ss_sold_date_sk#57], Inner, BuildLeft, false\n      :     :- BroadcastQueryStage 0\n      :     :  +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=130]\n      :     :     +- *(1) Project [d_date_sk#7, d_day_name#21]\n      :     :        +- *(1) Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n      :     :           +- *(1) ColumnarToRow\n      :     :              +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_year#13,d_day_name#21] Batched: true, DataFilters: [isnotnull(d_year#13), (d_year#13 = 1998), isnotnull(d_date_sk#7)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1998), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_day_name:string>\n      :     +- Filter isnotnull(ss_store_sk#41)\n      :        +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#41,ss_sales_price#47,ss_sold_date_sk#57] Batched: true, DataFilters: [isnotnull(ss_store_sk#41)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#57), dynamicpruningexpression(ss_sold_date_sk#57 IN dynamicpruning#130)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n      :              +- SubqueryBroadcast dynamicpruning#130, 0, [d_date_sk#7], [id=#229]\n      :                 +- AdaptiveSparkPlan isFinalPlan=false\n      :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=226]\n      :                       +- Project [d_date_sk#7, d_day_name#21]\n      :                          +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n      :                             +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_year#13,d_day_name#21] Batched: true, DataFilters: [isnotnull(d_year#13), (d_year#13 = 1998), isnotnull(d_date_sk#7)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1998), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_day_name:string>\n      +- BroadcastQueryStage 1\n         +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=151]\n            +- *(2) Project [s_store_sk#58, s_store_id#59, s_store_name#63]\n               +- *(2) Filter ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58))\n                  +- *(2) ColumnarToRow\n                     +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#58,s_store_id#59,s_store_name#63,s_gmt_offset#85] Batched: true, DataFilters: [isnotnull(s_gmt_offset#85), (s_gmt_offset#85 = -6.00), isnotnull(s_store_sk#58)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_gmt_offset), EqualTo(s_gmt_offset,-6.00), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string,s_gmt_offset:decimal(5,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 6306268432,
        "inputRowCount" : 262674085
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 2,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 3 ],
      "Objectives" : {
        "DurationInMs" : 3167,
        "TotalTasksDurationInMs" : 46788,
        "IOBytes" : {
          "Total" : 136201421,
          "Details" : {
            "IR" : 135908901,
            "IW" : 0,
            "SR" : 0,
            "SW" : 292520
          }
        }
      }
    },
    "3" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1554856231,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 10400,
                "rowCount" : 100
              },
              "compileTime" : {
                "sizeInBytes" : 10400,
                "rowCount" : 100
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "1" : {
            "sign" : 1190079690,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 49140,
                "rowCount" : 455
              },
              "compileTime" : {
                "sizeInBytes" : 49140,
                "rowCount" : 455
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 535152061,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 49140,
                "rowCount" : 455
              },
              "compileTime" : {
                "sizeInBytes" : 49140,
                "rowCount" : 455
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#107 ASC NULLS FIRST, mon_sales#108 ASC NULLS FIRST, tue_sales#109 ASC NULLS FIRST, wed_sales#110 ASC NULLS FIRST, thu_sales#111 ASC NULLS FIRST, fri_sales#112 ASC NULLS FIRST, sat_sales#113 ASC NULLS FIRST], true "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#107 ASC NULLS FIRST, mon_sales#108 ASC NULLS FIRST, tue_sales#109 ASC NULLS FIRST, wed_sales#110 ASC NULLS FIRST, thu_sales#111 ASC NULLS FIRST, fri_sales#112 ASC NULLS FIRST, sat_sales#113 ASC NULLS FIRST], true\n      +- Aggregate [s_store_name#63, s_store_id#59], [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)),17,2) AS sun_sales#107, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)),17,2) AS mon_sales#108, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)),17,2) AS tue_sales#109, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)),17,2) AS wed_sales#110, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)),17,2) AS thu_sales#111, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)),17,2) AS fri_sales#112, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END)),17,2) AS sat_sales#113]\n         +- Project [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63]\n            +- Join Inner, (s_store_sk#58 = ss_store_sk#41)\n               :- Project [d_day_name#21, ss_store_sk#41, ss_sales_price#47]\n               :  +- Join Inner, (d_date_sk#7 = ss_sold_date_sk#57)\n               :     :- Project [d_date_sk#7, d_day_name#21]\n               :     :  +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n               :     :     +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_date_id#8,d_date#9,d_month_seq#10,d_week_seq#11,d_quarter_seq#12,d_year#13,d_dow#14,d_moy#15,d_dom#16,d_qoy#17,d_fy_year#18,d_fy_quarter_seq#19,d_fy_week_seq#20,d_day_name#21,d_quarter_name#22,d_holiday#23,d_weekend#24,d_following_holiday#25,d_first_dom#26,d_last_dom#27,d_same_day_ly#28,d_same_day_lq#29,d_current_day#30,... 4 more fields] parquet\n               :     +- Project [ss_store_sk#41, ss_sales_price#47, ss_sold_date_sk#57]\n               :        +- Filter ((isnotnull(ss_sold_date_sk#57) AND isnotnull(ss_store_sk#41)) AND dynamicpruning#130 [ss_sold_date_sk#57])\n               :           :  +- Project [d_date_sk#7, d_day_name#21]\n               :           :     +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n               :           :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_date_id#8,d_date#9,d_month_seq#10,d_week_seq#11,d_quarter_seq#12,d_year#13,d_dow#14,d_moy#15,d_dom#16,d_qoy#17,d_fy_year#18,d_fy_quarter_seq#19,d_fy_week_seq#20,d_day_name#21,d_quarter_name#22,d_holiday#23,d_weekend#24,d_following_holiday#25,d_first_dom#26,d_last_dom#27,d_same_day_ly#28,d_same_day_lq#29,d_current_day#30,... 4 more fields] parquet\n               :           +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#35,ss_item_sk#36,ss_customer_sk#37,ss_cdemo_sk#38,ss_hdemo_sk#39,ss_addr_sk#40,ss_store_sk#41,ss_promo_sk#42,ss_ticket_number#43L,ss_quantity#44,ss_wholesale_cost#45,ss_list_price#46,ss_sales_price#47,ss_ext_discount_amt#48,ss_ext_sales_price#49,ss_ext_wholesale_cost#50,ss_ext_list_price#51,ss_ext_tax#52,ss_coupon_amt#53,ss_net_paid#54,ss_net_paid_inc_tax#55,ss_net_profit#56,ss_sold_date_sk#57] parquet\n               +- Project [s_store_sk#58, s_store_id#59, s_store_name#63]\n                  +- Filter ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58))\n                     +- Relation spark_catalog.tpcds_100.store[s_store_sk#58,s_store_id#59,s_rec_start_date#60,s_rec_end_date#61,s_closed_date_sk#62,s_store_name#63,s_number_employees#64,s_floor_space#65,s_hours#66,s_manager#67,s_market_id#68,s_geography_class#69,s_market_desc#70,s_market_manager#71,s_division_id#72,s_division_name#73,s_company_id#74,s_company_name#75,s_street_number#76,s_street_name#77,s_street_type#78,s_suite_number#79,s_city#80,s_county#81,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1940368386,
            "className" : "org.apache.spark.sql.execution.TakeOrderedAndProjectExec",
            "sizeInBytes" : 10400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) TakeOrderedAndProject Input [9]: [s_store_name#63, s_store_id#59, sun_sales#107, mon_sales#108, tue_sales#109, wed_sales#110, thu_sales#111, fri_sales#112, sat_sales#113] Arguments: 100, [s_store_name#63 ASC NULLS FIRST, s_store_id#59 ASC NULLS FIRST, sun_sales#107 ASC NULLS FIRST, mon_sales#108 ASC NULLS FIRST, tue_sales#109 ASC NULLS FIRST, wed_sales#110 ASC NULLS FIRST, thu_sales#111 ASC NULLS FIRST, fri_sales#112 ASC NULLS FIRST, sat_sales#113 ASC NULLS FIRST], [s_store_name#63, s_store_id#59, sun_sales#107, mon_sales#108, tue_sales#109, wed_sales#110, thu_sales#111, fri_sales#112, sat_sales#113] "
          },
          "1" : {
            "sign" : -1558607095,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 272896,
            "rowCount" : 2624,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [9]: [s_store_name#63, s_store_id#59, sum#138L, sum#139L, sum#140L, sum#141L, sum#142L, sum#143L, sum#144L] Keys [2]: [s_store_name#63, s_store_id#59] Functions [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))] Aggregate Attributes [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END))#114L, sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END))#115L, sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END))#116L, sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END))#117L, sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END))#118L, sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END))#119L, sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))#120L] Results [9]: [s_store_name#63, s_store_id#59, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END))#114L,17,2) AS sun_sales#107, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END))#115L,17,2) AS mon_sales#108, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END))#116L,17,2) AS tue_sales#109, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END))#117L,17,2) AS wed_sales#110, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END))#118L,17,2) AS thu_sales#111, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END))#119L,17,2) AS fri_sales#112, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))#120L,17,2) AS sat_sales#113] "
          },
          "2" : {
            "sign" : -2138684715,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 49140,
            "rowCount" : 455,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [9]: [s_store_name#63, s_store_id#59, sum#138L, sum#139L, sum#140L, sum#141L, sum#142L, sum#143L, sum#144L] Arguments: 2 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "ShuffleQueryStage",
          "toId" : 1,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "HashAggregate",
          "toId" : 0,
          "toName" : "TakeOrderedAndProject",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "TakeOrderedAndProject(limit=100, orderBy=[s_store_name#63 ASC NULLS FIRST,s_store_id#59 ASC NULLS FIRST,sun_sales#107 ASC NULLS FIRST,mon_sales#108 ASC NULLS FIRST,tue_sales#109 ASC NULLS FIRST,wed_sales#110 ASC NULLS FIRST,thu_sales#111 ASC NULLS FIRST,fri_sales#112 ASC NULLS FIRST,sat_sales#113 ASC NULLS FIRST], output=[s_store_name#63,s_store_id#59,sun_sales#107,mon_sales#108,tue_sales#109,wed_sales#110,thu_sales#111,fri_sales#112,sat_sales#113])\n+- HashAggregate(keys=[s_store_name#63, s_store_id#59], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)), sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))], output=[s_store_name#63, s_store_id#59, sun_sales#107, mon_sales#108, tue_sales#109, wed_sales#110, thu_sales#111, fri_sales#112, sat_sales#113])\n   +- ShuffleQueryStage 2\n      +- Exchange hashpartitioning(s_store_name#63, s_store_id#59, 200), ENSURE_REQUIREMENTS, [plan_id=271]\n         +- *(3) HashAggregate(keys=[s_store_name#63, s_store_id#59], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Sunday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Monday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Tuesday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Wednesday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Thursday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Friday) THEN ss_sales_price#47 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#21 = Saturday) THEN ss_sales_price#47 END))], output=[s_store_name#63, s_store_id#59, sum#138L, sum#139L, sum#140L, sum#141L, sum#142L, sum#143L, sum#144L])\n            +- *(3) Project [d_day_name#21, ss_sales_price#47, s_store_id#59, s_store_name#63]\n               +- *(3) BroadcastHashJoin [ss_store_sk#41], [s_store_sk#58], Inner, BuildRight, false\n                  :- *(3) Project [d_day_name#21, ss_store_sk#41, ss_sales_price#47]\n                  :  +- *(3) BroadcastHashJoin [d_date_sk#7], [ss_sold_date_sk#57], Inner, BuildLeft, false\n                  :     :- BroadcastQueryStage 0\n                  :     :  +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=130]\n                  :     :     +- *(1) Project [d_date_sk#7, d_day_name#21]\n                  :     :        +- *(1) Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n                  :     :           +- *(1) ColumnarToRow\n                  :     :              +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_year#13,d_day_name#21] Batched: true, DataFilters: [isnotnull(d_year#13), (d_year#13 = 1998), isnotnull(d_date_sk#7)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1998), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_day_name:string>\n                  :     +- *(3) Filter isnotnull(ss_store_sk#41)\n                  :        +- *(3) ColumnarToRow\n                  :           +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#41,ss_sales_price#47,ss_sold_date_sk#57] Batched: true, DataFilters: [isnotnull(ss_store_sk#41)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#57), dynamicpruningexpression(ss_sold_date_sk#57 IN dynamicpruning#130)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n                  :                 +- SubqueryBroadcast dynamicpruning#130, 0, [d_date_sk#7], [id=#229]\n                  :                    +- AdaptiveSparkPlan isFinalPlan=true\n                                          +- == Final Plan ==\n                                             BroadcastQueryStage 1\n                                             +- ReusedExchange [d_date_sk#7, d_day_name#21], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=130]\n                                          +- == Initial Plan ==\n                                             BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=226]\n                                             +- Project [d_date_sk#7, d_day_name#21]\n                                                +- Filter ((isnotnull(d_year#13) AND (d_year#13 = 1998)) AND isnotnull(d_date_sk#7))\n                                                   +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#7,d_year#13,d_day_name#21] Batched: true, DataFilters: [isnotnull(d_year#13), (d_year#13 = 1998), isnotnull(d_date_sk#7)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1998), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_day_name:string>\n                  +- BroadcastQueryStage 1\n                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=151]\n                        +- *(2) Project [s_store_sk#58, s_store_id#59, s_store_name#63]\n                           +- *(2) Filter ((isnotnull(s_gmt_offset#85) AND (s_gmt_offset#85 = -6.00)) AND isnotnull(s_store_sk#58))\n                              +- *(2) ColumnarToRow\n                                 +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#58,s_store_id#59,s_store_name#63,s_gmt_offset#85] Batched: true, DataFilters: [isnotnull(s_gmt_offset#85), (s_gmt_offset#85 = -6.00), isnotnull(s_store_sk#58)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_gmt_offset), EqualTo(s_gmt_offset,-6.00), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string,s_gmt_offset:decimal(5,2)>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 272896,
        "inputRowCount" : 2624
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "0" : [ 0, 0, 0, 4106, 0, 0, 4185, 0, 6145, 4081, 0, 0, 0, 0, 4106, 0, 0, 0, 0, 0, 4107, 4119, 0, 4172, 4093, 0, 0, 4172, 0, 0, 0, 0, 0, 0, 4093, 0, 6063, 0, 4119, 0, 0, 9628, 0, 0, 0, 0, 0, 0, 4094, 0, 4171, 0, 0, 0, 0, 0, 0, 4094, 8039, 4159, 4081, 4119, 0, 4094, 0, 0, 4083, 4133, 0, 0, 4107, 0, 0, 4106, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4198, 6094, 0, 0, 4197, 0, 0, 4106, 0, 0, 6127, 0, 0, 0, 0, 0, 0, 0, 0, 6063, 0, 0, 0, 0, 0, 0, 4082, 0, 4081, 0, 0, 0, 4081, 0, 9426, 0, 0, 0, 0, 4081, 0, 0, 4094, 0, 4049, 0, 0, 0, 0, 0, 4049, 6037, 0, 0, 0, 0, 4069, 4093, 4049, 0, 0, 0, 4081, 0, 0, 0, 0, 0, 0, 0, 4159, 0, 4094, 0, 0, 0, 4093, 4081, 0, 4146, 0, 0, 0, 0, 4094, 0, 4081, 4093, 4172, 4119, 0, 6027, 0, 0, 0, 4094, 0, 4081, 0, 4197, 4081, 4159, 0, 4159, 4081, 0, 0, 0, 0, 4145, 0, 4119, 0, 4081, 0, 4094 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 3,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 5 ],
      "Objectives" : {
        "DurationInMs" : 280,
        "TotalTasksDurationInMs" : 270,
        "IOBytes" : {
          "Total" : 292520,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 292520,
            "SW" : 0
          }
        }
      }
    }
  },
  "SQLStartTimeInMs" : 1702226980845,
  "SQLEndTimeInMs" : 1702226987304,
  "Objectives" : {
    "DurationInMs" : 6459,
    "IOBytes" : {
      "Total" : 136604141,
      "Details" : {
        "IR" : 136019101,
        "IW" : 0,
        "SR" : 292520,
        "SW" : 292520
      }
    }
  }
}
