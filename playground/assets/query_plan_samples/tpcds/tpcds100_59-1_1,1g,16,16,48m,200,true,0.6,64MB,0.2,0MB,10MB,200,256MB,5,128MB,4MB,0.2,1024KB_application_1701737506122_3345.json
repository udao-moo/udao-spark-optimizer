{
  "CompileTimeLQP" : {
    "LQP" : {
      "operators" : {
        "34" : {
          "sign" : -981191832,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 108,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [bloom_filter_agg(xxhash64(d_week_seq#168, 42), 323, 8693, 0, 0) AS bloomFilter#226] "
        },
        "12" : {
          "sign" : 1122983647,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 6304165152,
          "rowCount" : 262673548,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
        },
        "8" : {
          "sign" : 1093101480,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 69342364680,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
        },
        "19" : {
          "sign" : 890895506,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 4032,
          "rowCount" : 336,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_week_seq#111] "
        },
        "23" : {
          "sign" : -124430594,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79)) "
        },
        "4" : {
          "sign" : 1709574549,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 56996174979200,
          "rowCount" : 284980874896,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#2 = s_store_id2#12) AND (d_week_seq1#1 = (d_week_seq2#11 - 52))) "
        },
        "40" : {
          "sign" : 1068787192,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#135, s_store_id#136, s_rec_start_date#137, s_rec_end_date#138, s_closed_date_sk#139, s_store_name#140, s_number_employees#141, s_floor_space#142, s_hours#143, s_manager#144, s_market_id#145, s_geography_class#146, s_market_desc#147, s_market_manager#148, s_division_id#149, s_division_name#150, s_company_id#151, s_company_name#152, s_street_number#153, s_street_name#154, s_street_type#155, s_suite_number#156, s_city#157, s_county#158, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "15" : {
          "sign" : -1416205796,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 2629764,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_date_sk#50, d_week_seq#54, d_day_name#64] "
        },
        "11" : {
          "sign" : -1875318253,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 13808110420,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
        },
        "9" : {
          "sign" : -551460611,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 131891760,
          "rowCount" : 1831830,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#20, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#21, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#22, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#23, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#24, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#25, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#26] "
        },
        "33" : {
          "sign" : -1716929301,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 17970054,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#227 [], xxhash64(d_week_seq#54, 42))) "
        },
        "22" : {
          "sign" : 893389056,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 22512,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_store_sk#78, s_store_id#79, s_store_name#83] "
        },
        "26" : {
          "sign" : 2017756636,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 53383600,
          "rowCount" : 533836,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#168 = d_week_seq#54) "
        },
        "37" : {
          "sign" : -148535994,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 17970054,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#164, d_date_id#165, d_date#166, d_month_seq#167, d_week_seq#168, d_quarter_seq#169, d_year#170, d_dow#171, d_moy#172, d_dom#173, d_qoy#174, d_fy_year#175, d_fy_quarter_seq#176, d_fy_week_seq#177, d_day_name#178, d_quarter_name#179, d_holiday#180, d_weekend#181, d_following_holiday#182, d_first_dom#183, d_last_dom#184, d_same_day_ly#185, d_same_day_lq#186, d_current_day#187, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "13" : {
          "sign" : 678988587,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 39926379296,
          "rowCount" : 262673548,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
        },
        "24" : {
          "sign" : -1870715280,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#78, s_store_id#79, s_rec_start_date#80, s_rec_end_date#81, s_closed_date_sk#82, s_store_name#83, s_number_employees#84, s_floor_space#85, s_hours#86, s_manager#87, s_market_id#88, s_geography_class#89, s_market_desc#90, s_market_manager#91, s_division_id#92, s_division_name#93, s_company_id#94, s_company_name#95, s_street_number#96, s_street_name#97, s_street_type#98, s_suite_number#99, s_city#100, s_county#101, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "35" : {
          "sign" : -1938007902,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 3876,
          "rowCount" : 323,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_week_seq#168] "
        },
        "16" : {
          "sign" : -1218301094,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 17970054,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#224 [], xxhash64(d_week_seq#54, 42))) "
        },
        "5" : {
          "sign" : -946969580,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 59789632,
          "rowCount" : 533836,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#0, d_week_seq#54 AS d_week_seq1#1, s_store_id#79 AS s_store_id1#2, sun_sales#20 AS sun_sales1#3, mon_sales#21 AS mon_sales1#4, tue_sales#22 AS tue_sales1#5, wed_sales#23 AS wed_sales1#6, thu_sales#24 AS thu_sales1#7, fri_sales#25 AS fri_sales1#8, sat_sales#26 AS sat_sales1#9] "
        },
        "10" : {
          "sign" : 1606278619,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 11683785740,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
        },
        "21" : {
          "sign" : 868046051,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 17970054,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#107, d_date_id#108, d_date#109, d_month_seq#110, d_week_seq#111, d_quarter_seq#112, d_year#113, d_dow#114, d_moy#115, d_dom#116, d_qoy#117, d_fy_year#118, d_fy_quarter_seq#119, d_fy_week_seq#120, d_day_name#121, d_quarter_name#122, d_holiday#123, d_weekend#124, d_following_holiday#125, d_first_dom#126, d_last_dom#127, d_same_day_ly#128, d_same_day_lq#129, d_current_day#130, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "32" : {
          "sign" : -263596823,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 2629764,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_date_sk#50, d_week_seq#54, d_day_name#64] "
        },
        "6" : {
          "sign" : -39581855,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 61924976,
          "rowCount" : 533836,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#111 = d_week_seq#54) "
        },
        "36" : {
          "sign" : 550008068,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 79458,
          "rowCount" : 323,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#167) AND ((d_month_seq#167 >= 1197) AND (d_month_seq#167 <= 1208))) AND isnotnull(d_week_seq#168)) "
        },
        "1" : {
          "sign" : 391800878,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
          "sizeInBytes" : 47876786982528,
          "rowCount" : 284980874896,
          "isRuntime" : false,
          "predicate" : " (unknown) LocalLimit Arguments: 100 "
        },
        "39" : {
          "sign" : -1950754100,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (isnotnull(s_store_sk#135) AND isnotnull(s_store_id#136)) "
        },
        "17" : {
          "sign" : 1727324964,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 17970054,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#50, d_date_id#51, d_date#52, d_month_seq#53, d_week_seq#54, d_quarter_seq#55, d_year#56, d_dow#57, d_moy#58, d_dom#59, d_qoy#60, d_fy_year#61, d_fy_quarter_seq#62, d_fy_week_seq#63, d_day_name#64, d_quarter_name#65, d_holiday#66, d_weekend#67, d_following_holiday#68, d_first_dom#69, d_last_dom#70, d_same_day_ly#71, d_same_day_lq#72, d_current_day#73, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "25" : {
          "sign" : -1716703113,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 51248256,
          "rowCount" : 533836,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#11, s_store_id#136 AS s_store_id2#12, sun_sales#20 AS sun_sales2#13, mon_sales#21 AS mon_sales2#14, tue_sales#22 AS tue_sales2#15, wed_sales#23 AS wed_sales2#16, thu_sales#24 AS thu_sales2#17, fri_sales#25 AS fri_sales2#18, sat_sales#26 AS sat_sales2#19] "
        },
        "14" : {
          "sign" : 122295656,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 41806893656,
          "rowCount" : 275045353,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "31" : {
          "sign" : -1055975516,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 13808110420,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
        },
        "0" : {
          "sign" : -715624665,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
          "sizeInBytes" : 16400,
          "rowCount" : 100,
          "isRuntime" : false,
          "predicate" : " (unknown) GlobalLimit Arguments: 100 "
        },
        "20" : {
          "sign" : -1043391664,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 82656,
          "rowCount" : 336,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#110) AND ((d_month_seq#110 >= 1185) AND (d_month_seq#110 <= 1196))) AND isnotnull(d_week_seq#111)) "
        },
        "27" : {
          "sign" : 768372875,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 55473891744,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#20, mon_sales#21, tue_sales#22, wed_sales#23, thu_sales#24, fri_sales#25, sat_sales#26, s_store_id#136] "
        },
        "2" : {
          "sign" : -172322819,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
          "sizeInBytes" : 47876786982528,
          "rowCount" : 284980874896,
          "isRuntime" : false,
          "predicate" : " (unknown) Sort Arguments: [s_store_name1#0 ASC NULLS FIRST, s_store_id1#2 ASC NULLS FIRST, d_week_seq1#1 ASC NULLS FIRST], true "
        },
        "38" : {
          "sign" : 706363657,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 16080,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_store_sk#135, s_store_id#136] "
        },
        "18" : {
          "sign" : -126195402,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 108,
          "rowCount" : 1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [bloom_filter_agg(xxhash64(d_week_seq#111, 42), 336, 9015, 0, 0) AS bloomFilter#223] "
        },
        "30" : {
          "sign" : 1444493224,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 11683785740,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
        },
        "7" : {
          "sign" : -2106377062,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 64719540368,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#20, mon_sales#21, tue_sales#22, wed_sales#23, thu_sales#24, fri_sales#25, sat_sales#26, s_store_id#79, s_store_name#83] "
        },
        "29" : {
          "sign" : -658468210,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 131891760,
          "rowCount" : 1831830,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#20, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#21, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#22, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#23, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#24, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#25, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#26] "
        },
        "3" : {
          "sign" : -1527705452,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 47876786982528,
          "rowCount" : 284980874896,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_store_name1#0, s_store_id1#2, d_week_seq1#1, (sun_sales1#3 / sun_sales2#13) AS (sun_sales1 / sun_sales2)#201, (mon_sales1#4 / mon_sales2#14) AS (mon_sales1 / mon_sales2)#202, (tue_sales1#5 / tue_sales2#15) AS (tue_sales1 / tue_sales2)#203, (wed_sales1#6 / wed_sales2#16) AS (wed_sales1 / wed_sales2)#204, (thu_sales1#7 / thu_sales2#17) AS (thu_sales1 / thu_sales2)#205, (fri_sales1#8 / fri_sales2#18) AS (fri_sales1 / fri_sales2)#206, (sat_sales1#9 / sat_sales2#19) AS (sat_sales1 / sat_sales2)#207] "
        },
        "28" : {
          "sign" : -865526330,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 60096716056,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#135) "
        }
      },
      "links" : [ {
        "fromId" : 14,
        "fromName" : "LogicalRelation",
        "toId" : 13,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 13,
        "fromName" : "Filter",
        "toId" : 12,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 12,
        "fromName" : "Project",
        "toId" : 11,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 17,
        "fromName" : "LogicalRelation",
        "toId" : 16,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 21,
        "fromName" : "LogicalRelation",
        "toId" : 20,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 20,
        "fromName" : "Filter",
        "toId" : 19,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 19,
        "fromName" : "Project",
        "toId" : 18,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 18,
        "fromName" : "Aggregate",
        "toId" : 16,
        "toName" : "Filter",
        "linkType" : "Subquery"
      }, {
        "fromId" : 16,
        "fromName" : "Filter",
        "toId" : 15,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 15,
        "fromName" : "Project",
        "toId" : 11,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 11,
        "fromName" : "Join",
        "toId" : 10,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 10,
        "fromName" : "Project",
        "toId" : 9,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 9,
        "fromName" : "Aggregate",
        "toId" : 8,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 24,
        "fromName" : "LogicalRelation",
        "toId" : 23,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 23,
        "fromName" : "Filter",
        "toId" : 22,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 22,
        "fromName" : "Project",
        "toId" : 8,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 8,
        "fromName" : "Join",
        "toId" : 7,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 7,
        "fromName" : "Project",
        "toId" : 6,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 19,
        "fromName" : "Project",
        "toId" : 6,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 6,
        "fromName" : "Join",
        "toId" : 5,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 5,
        "fromName" : "Project",
        "toId" : 4,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 12,
        "fromName" : "Project",
        "toId" : 31,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 17,
        "fromName" : "LogicalRelation",
        "toId" : 33,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 37,
        "fromName" : "LogicalRelation",
        "toId" : 36,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 36,
        "fromName" : "Filter",
        "toId" : 35,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 35,
        "fromName" : "Project",
        "toId" : 34,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 34,
        "fromName" : "Aggregate",
        "toId" : 33,
        "toName" : "Filter",
        "linkType" : "Subquery"
      }, {
        "fromId" : 33,
        "fromName" : "Filter",
        "toId" : 32,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 32,
        "fromName" : "Project",
        "toId" : 31,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 31,
        "fromName" : "Join",
        "toId" : 30,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 30,
        "fromName" : "Project",
        "toId" : 29,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 29,
        "fromName" : "Aggregate",
        "toId" : 28,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 40,
        "fromName" : "LogicalRelation",
        "toId" : 39,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 39,
        "fromName" : "Filter",
        "toId" : 38,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 38,
        "fromName" : "Project",
        "toId" : 28,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 28,
        "fromName" : "Join",
        "toId" : 27,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 27,
        "fromName" : "Project",
        "toId" : 26,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 35,
        "fromName" : "Project",
        "toId" : 26,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 26,
        "fromName" : "Join",
        "toId" : 25,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 25,
        "fromName" : "Project",
        "toId" : 4,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 4,
        "fromName" : "Join",
        "toId" : 3,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 3,
        "fromName" : "Project",
        "toId" : 2,
        "toName" : "Sort",
        "linkType" : "Operator"
      }, {
        "fromId" : 2,
        "fromName" : "Sort",
        "toId" : 1,
        "toName" : "LocalLimit",
        "linkType" : "Operator"
      }, {
        "fromId" : 1,
        "fromName" : "LocalLimit",
        "toId" : 0,
        "toName" : "GlobalLimit",
        "linkType" : "Operator"
      } ],
      "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#0 ASC NULLS FIRST, s_store_id1#2 ASC NULLS FIRST, d_week_seq1#1 ASC NULLS FIRST], true\n      +- Project [s_store_name1#0, s_store_id1#2, d_week_seq1#1, (sun_sales1#3 / sun_sales2#13) AS (sun_sales1 / sun_sales2)#201, (mon_sales1#4 / mon_sales2#14) AS (mon_sales1 / mon_sales2)#202, (tue_sales1#5 / tue_sales2#15) AS (tue_sales1 / tue_sales2)#203, (wed_sales1#6 / wed_sales2#16) AS (wed_sales1 / wed_sales2)#204, (thu_sales1#7 / thu_sales2#17) AS (thu_sales1 / thu_sales2)#205, (fri_sales1#8 / fri_sales2#18) AS (fri_sales1 / fri_sales2)#206, (sat_sales1#9 / sat_sales2#19) AS (sat_sales1 / sat_sales2)#207]\n         +- Join Inner, ((s_store_id1#2 = s_store_id2#12) AND (d_week_seq1#1 = (d_week_seq2#11 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#0, d_week_seq#54 AS d_week_seq1#1, s_store_id#79 AS s_store_id1#2, sun_sales#20 AS sun_sales1#3, mon_sales#21 AS mon_sales1#4, tue_sales#22 AS tue_sales1#5, wed_sales#23 AS wed_sales1#6, thu_sales#24 AS thu_sales1#7, fri_sales#25 AS fri_sales1#8, sat_sales#26 AS sat_sales1#9]\n            :  +- Join Inner, (d_week_seq#111 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#20, mon_sales#21, tue_sales#22, wed_sales#23, thu_sales#24, fri_sales#25, sat_sales#26, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#20, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#21, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#22, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#23, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#24, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#25, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#26]\n            :     :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n            :     :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n            :     :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n            :     :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n            :     :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n            :     :     :        +- Project [d_date_sk#50, d_week_seq#54, d_day_name#64]\n            :     :     :           +- Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#224 [], xxhash64(d_week_seq#54, 42)))\n            :     :     :              :  +- Aggregate [bloom_filter_agg(xxhash64(d_week_seq#111, 42), 336, 9015, 0, 0) AS bloomFilter#223]\n            :     :     :              :     +- Project [d_week_seq#111]\n            :     :     :              :        +- Filter ((isnotnull(d_month_seq#110) AND ((d_month_seq#110 >= 1185) AND (d_month_seq#110 <= 1196))) AND isnotnull(d_week_seq#111))\n            :     :     :              :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#107,d_date_id#108,d_date#109,d_month_seq#110,d_week_seq#111,d_quarter_seq#112,d_year#113,d_dow#114,d_moy#115,d_dom#116,d_qoy#117,d_fy_year#118,d_fy_quarter_seq#119,d_fy_week_seq#120,d_day_name#121,d_quarter_name#122,d_holiday#123,d_weekend#124,d_following_holiday#125,d_first_dom#126,d_last_dom#127,d_same_day_ly#128,d_same_day_lq#129,d_current_day#130,... 4 more fields] parquet\n            :     :     :              +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_date_id#51,d_date#52,d_month_seq#53,d_week_seq#54,d_quarter_seq#55,d_year#56,d_dow#57,d_moy#58,d_dom#59,d_qoy#60,d_fy_year#61,d_fy_quarter_seq#62,d_fy_week_seq#63,d_day_name#64,d_quarter_name#65,d_holiday#66,d_weekend#67,d_following_holiday#68,d_first_dom#69,d_last_dom#70,d_same_day_ly#71,d_same_day_lq#72,d_current_day#73,... 4 more fields] parquet\n            :     :     +- Project [s_store_sk#78, s_store_id#79, s_store_name#83]\n            :     :        +- Filter (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79))\n            :     :           +- Relation spark_catalog.tpcds_100.store[s_store_sk#78,s_store_id#79,s_rec_start_date#80,s_rec_end_date#81,s_closed_date_sk#82,s_store_name#83,s_number_employees#84,s_floor_space#85,s_hours#86,s_manager#87,s_market_id#88,s_geography_class#89,s_market_desc#90,s_market_manager#91,s_division_id#92,s_division_name#93,s_company_id#94,s_company_name#95,s_street_number#96,s_street_name#97,s_street_type#98,s_suite_number#99,s_city#100,s_county#101,... 5 more fields] parquet\n            :     +- Project [d_week_seq#111]\n            :        +- Filter ((isnotnull(d_month_seq#110) AND ((d_month_seq#110 >= 1185) AND (d_month_seq#110 <= 1196))) AND isnotnull(d_week_seq#111))\n            :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#107,d_date_id#108,d_date#109,d_month_seq#110,d_week_seq#111,d_quarter_seq#112,d_year#113,d_dow#114,d_moy#115,d_dom#116,d_qoy#117,d_fy_year#118,d_fy_quarter_seq#119,d_fy_week_seq#120,d_day_name#121,d_quarter_name#122,d_holiday#123,d_weekend#124,d_following_holiday#125,d_first_dom#126,d_last_dom#127,d_same_day_ly#128,d_same_day_lq#129,d_current_day#130,... 4 more fields] parquet\n            +- Project [d_week_seq#54 AS d_week_seq2#11, s_store_id#136 AS s_store_id2#12, sun_sales#20 AS sun_sales2#13, mon_sales#21 AS mon_sales2#14, tue_sales#22 AS tue_sales2#15, wed_sales#23 AS wed_sales2#16, thu_sales#24 AS thu_sales2#17, fri_sales#25 AS fri_sales2#18, sat_sales#26 AS sat_sales2#19]\n               +- Join Inner, (d_week_seq#168 = d_week_seq#54)\n                  :- Project [d_week_seq#54, sun_sales#20, mon_sales#21, tue_sales#22, wed_sales#23, thu_sales#24, fri_sales#25, sat_sales#26, s_store_id#136]\n                  :  +- Join Inner, (ss_store_sk#33 = s_store_sk#135)\n                  :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#20, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#21, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#22, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#23, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#24, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#25, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#26]\n                  :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n                  :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n                  :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n                  :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n                  :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n                  :     :        +- Project [d_date_sk#50, d_week_seq#54, d_day_name#64]\n                  :     :           +- Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#227 [], xxhash64(d_week_seq#54, 42)))\n                  :     :              :  +- Aggregate [bloom_filter_agg(xxhash64(d_week_seq#168, 42), 323, 8693, 0, 0) AS bloomFilter#226]\n                  :     :              :     +- Project [d_week_seq#168]\n                  :     :              :        +- Filter ((isnotnull(d_month_seq#167) AND ((d_month_seq#167 >= 1197) AND (d_month_seq#167 <= 1208))) AND isnotnull(d_week_seq#168))\n                  :     :              :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#164,d_date_id#165,d_date#166,d_month_seq#167,d_week_seq#168,d_quarter_seq#169,d_year#170,d_dow#171,d_moy#172,d_dom#173,d_qoy#174,d_fy_year#175,d_fy_quarter_seq#176,d_fy_week_seq#177,d_day_name#178,d_quarter_name#179,d_holiday#180,d_weekend#181,d_following_holiday#182,d_first_dom#183,d_last_dom#184,d_same_day_ly#185,d_same_day_lq#186,d_current_day#187,... 4 more fields] parquet\n                  :     :              +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_date_id#51,d_date#52,d_month_seq#53,d_week_seq#54,d_quarter_seq#55,d_year#56,d_dow#57,d_moy#58,d_dom#59,d_qoy#60,d_fy_year#61,d_fy_quarter_seq#62,d_fy_week_seq#63,d_day_name#64,d_quarter_name#65,d_holiday#66,d_weekend#67,d_following_holiday#68,d_first_dom#69,d_last_dom#70,d_same_day_ly#71,d_same_day_lq#72,d_current_day#73,... 4 more fields] parquet\n                  :     +- Project [s_store_sk#135, s_store_id#136]\n                  :        +- Filter (isnotnull(s_store_sk#135) AND isnotnull(s_store_id#136))\n                  :           +- Relation spark_catalog.tpcds_100.store[s_store_sk#135,s_store_id#136,s_rec_start_date#137,s_rec_end_date#138,s_closed_date_sk#139,s_store_name#140,s_number_employees#141,s_floor_space#142,s_hours#143,s_manager#144,s_market_id#145,s_geography_class#146,s_market_desc#147,s_market_manager#148,s_division_id#149,s_division_name#150,s_company_id#151,s_company_name#152,s_street_number#153,s_street_name#154,s_street_type#155,s_suite_number#156,s_city#157,s_county#158,... 5 more fields] parquet\n                  +- Project [d_week_seq#168]\n                     +- Filter ((isnotnull(d_month_seq#167) AND ((d_month_seq#167 >= 1197) AND (d_month_seq#167 <= 1208))) AND isnotnull(d_week_seq#168))\n                        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#164,d_date_id#165,d_date#166,d_month_seq#167,d_week_seq#168,d_quarter_seq#169,d_year#170,d_dow#171,d_moy#172,d_dom#173,d_qoy#174,d_fy_year#175,d_fy_quarter_seq#176,d_fy_week_seq#177,d_day_name#178,d_quarter_name#179,d_holiday#180,d_weekend#181,d_following_holiday#182,d_first_dom#183,d_last_dom#184,d_same_day_ly#185,d_same_day_lq#186,d_current_day#187,... 4 more fields] parquet\n"
    },
    "IM" : {
      "inputSizeInBytes" : 83686052644,
      "inputRowCount" : 550383706
    },
    "PD" : { },
    "Configuration" : {
      "theta_c" : [ {
        "spark.executor.memory" : "1g"
      }, {
        "spark.executor.cores" : "1"
      }, {
        "spark.executor.instances" : "16"
      }, {
        "spark.default.parallelism" : "16"
      }, {
        "spark.reducer.maxSizeInFlight" : "48m"
      }, {
        "spark.shuffle.sort.bypassMergeThreshold" : "200"
      }, {
        "spark.shuffle.compress" : "true"
      }, {
        "spark.memory.fraction" : "0.6"
      } ],
      "theta_p" : [ {
        "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
      }, {
        "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
      }, {
        "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
      }, {
        "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
      }, {
        "spark.sql.shuffle.partitions" : "200"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
      }, {
        "spark.sql.files.maxPartitionBytes" : "128MB"
      }, {
        "spark.sql.files.openCostInBytes" : "4MB"
      } ],
      "theta_s" : [ {
        "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
      }, {
        "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
      } ]
    }
  },
  "RuntimeLQPs" : {
    "12" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : 1909637285,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 7540258401792,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "5" : {
            "sign" : -2041546065,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 59789632,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239], ShuffleQueryStage 9 "
          },
          "6" : {
            "sign" : 1959290580,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 35651584,
            "rowCount" : 73566,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8, BroadcastQueryStage 10 "
          },
          "1" : {
            "sign" : -2049039549,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 6597726101568,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "0" : {
            "sign" : 392389838,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 1091883748,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 6597726101568,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "3" : {
            "sign" : 1311330248,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6597726101568,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- LogicalQueryStage Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239], ShuffleQueryStage 9\n            +- LogicalQueryStage LogicalQueryStage Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8, BroadcastQueryStage 10\n"
      },
      "IM" : {
        "inputSizeInBytes" : 95441216,
        "inputRowCount" : 607402
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227181172,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 2391,
        "IOBytes" : {
          "Total" : 4205506,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 3520298,
            "SW" : 685208
          }
        }
      }
    },
    "8" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 1122983647,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
          },
          "8" : {
            "sign" : -1724215008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 7379936237063803392,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          },
          "19" : {
            "sign" : -659531460,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 24795914663520,
            "rowCount" : 269520811560,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#318 = d_week_seq#54) "
          },
          "23" : {
            "sign" : -1831807767,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4 "
          },
          "4" : {
            "sign" : 1014177923,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 164844542908279140835674584770887795840,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "15" : {
            "sign" : -1544469812,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051544,
            "rowCount" : 371,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0 "
          },
          "11" : {
            "sign" : 2062469607,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 5067498088016,
            "rowCount" : 97451886308,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "9" : {
            "sign" : 402242688,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 7016535814176,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "22" : {
            "sign" : -1307870132,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256], HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))]) "
          },
          "13" : {
            "sign" : 678988587,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
          },
          "24" : {
            "sign" : 734062518,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 366,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#318], BroadcastQueryStage 5 "
          },
          "16" : {
            "sign" : -523930085,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1 "
          },
          "5" : {
            "sign" : -1513905076,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6950236723083335952071678,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "10" : {
            "sign" : 1741726381,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4287882997552,
            "rowCount" : 97451886308,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "21" : {
            "sign" : -1297019688,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 70693983360,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#285) "
          },
          "6" : {
            "sign" : 453692002,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 7207652898012348394741000,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "1" : {
            "sign" : -1002072341,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 143800558707222229239631020757582970839,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : 1284763110,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#261], BroadcastQueryStage 2 "
          },
          "14" : {
            "sign" : 122295656,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : 1831969708,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -335718870,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 64802818080,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] "
          },
          "2" : {
            "sign" : 1426507266,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 143800558707222229239631020757582970839,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : -1601950037,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 23717831417280,
            "rowCount" : 269520811560,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] "
          },
          "7" : {
            "sign" : -1273149737,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6870975117266299709,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : 703719024,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 143800558707222229239631020757582970839,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "LogicalQueryStage",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Aggregate",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "LogicalQueryStage",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "LogicalQueryStage",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "Join",
          "toId" : 20,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Project",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "LogicalQueryStage",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Join",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n            :  +- Join Inner, (d_week_seq#261 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n            :     :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n            :     :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n            :     :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n            :     :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n            :     :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n            :     :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0\n            :     :     +- LogicalQueryStage Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1\n            :     +- LogicalQueryStage Project [d_week_seq#261], BroadcastQueryStage 2\n            +- Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n               +- Join Inner, (d_week_seq#318 = d_week_seq#54)\n                  :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n                  :  +- Join Inner, (ss_store_sk#33 = s_store_sk#285)\n                  :     :- LogicalQueryStage Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256], HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))])\n                  :     +- LogicalQueryStage Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4\n                  +- LogicalQueryStage Project [d_week_seq#318], BroadcastQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 41944038544,
        "inputRowCount" : 276879089
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 1,
        "FinishedTasksTotalTimeInMs" : 1176.0,
        "FinishedTasksDistributionInMs" : [ 1176.0, 1176.0, 1176.0, 1176.0, 1176.0 ]
      },
      "StartTimeInMs" : 1702227166213,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 17350,
        "IOBytes" : {
          "Total" : 1385969632,
          "Details" : {
            "IR" : 1372059172,
            "IW" : 0,
            "SR" : 6955230,
            "SW" : 6955230
          }
        }
      }
    },
    "4" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 1122983647,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
          },
          "8" : {
            "sign" : -1724215008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 85421896560,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          },
          "19" : {
            "sign" : -960740485,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 24795914663520,
            "rowCount" : 269520811560,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#318 = d_week_seq#54) "
          },
          "23" : {
            "sign" : 1741726474,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "4" : {
            "sign" : 2038535682,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13619282854713130747152000,
            "rowCount" : 72442993908048567804000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "15" : {
            "sign" : -1544469812,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0 "
          },
          "11" : {
            "sign" : 2062469607,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "9" : {
            "sign" : 402242688,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "22" : {
            "sign" : 402242781,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "26" : {
            "sign" : -1831807767,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4 "
          },
          "13" : {
            "sign" : 678988587,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
          },
          "24" : {
            "sign" : 2062469700,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "16" : {
            "sign" : -523930085,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1 "
          },
          "5" : {
            "sign" : -1513905076,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 29028716917200,
            "rowCount" : 268784415900,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "10" : {
            "sign" : 1741726381,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "21" : {
            "sign" : 614652153,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 70693983360,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#285) "
          },
          "6" : {
            "sign" : 453692002,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 30103854580800,
            "rowCount" : 268784415900,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "1" : {
            "sign" : 322236372,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 11880651000919965119856000,
            "rowCount" : 72442993908048567804000,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : 1284763110,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#261], BroadcastQueryStage 2 "
          },
          "25" : {
            "sign" : -1544469719,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3 "
          },
          "14" : {
            "sign" : 122295656,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : 70206379,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -1367437049,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 64802818080,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] "
          },
          "27" : {
            "sign" : 734062518,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 366,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#318], BroadcastQueryStage 5 "
          },
          "2" : {
            "sign" : -958092351,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 11880651000919965119856000,
            "rowCount" : 72442993908048567804000,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 1519898900,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 23717831417280,
            "rowCount" : 269520811560,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] "
          },
          "7" : {
            "sign" : -1273149737,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 79530731280,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : 2095321,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11880651000919965119856000,
            "rowCount" : 72442993908048567804000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "LogicalQueryStage",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Aggregate",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "LogicalQueryStage",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Join",
          "toId" : 23,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Project",
          "toId" : 22,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Aggregate",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "LogicalQueryStage",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "Join",
          "toId" : 20,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Project",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 27,
          "fromName" : "LogicalQueryStage",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Join",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n            :  +- Join Inner, (d_week_seq#261 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n            :     :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n            :     :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n            :     :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n            :     :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n            :     :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n            :     :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0\n            :     :     +- LogicalQueryStage Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1\n            :     +- LogicalQueryStage Project [d_week_seq#261], BroadcastQueryStage 2\n            +- Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n               +- Join Inner, (d_week_seq#318 = d_week_seq#54)\n                  :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n                  :  +- Join Inner, (ss_store_sk#33 = s_store_sk#285)\n                  :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n                  :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n                  :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n                  :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n                  :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n                  :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n                  :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3\n                  :     +- LogicalQueryStage Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4\n                  +- LogicalQueryStage Project [d_week_seq#318], BroadcastQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 83623248424,
        "inputRowCount" : 550238339
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 2,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227163487,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 20076,
        "IOBytes" : {
          "Total" : 1387032802,
          "Details" : {
            "IR" : 1373117882,
            "IW" : 0,
            "SR" : 6957460,
            "SW" : 6957460
          }
        }
      }
    },
    "11" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : 603652736,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 7540258401792,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "5" : {
            "sign" : -2041546065,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 59789632,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239], ShuffleQueryStage 9 "
          },
          "6" : {
            "sign" : -1645591697,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 7062336,
            "rowCount" : 73566,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8 "
          },
          "1" : {
            "sign" : -1076008290,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 6597726101568,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "0" : {
            "sign" : 895089129,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 150979455,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 6597726101568,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "3" : {
            "sign" : -532882077,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6597726101568,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- LogicalQueryStage Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239], ShuffleQueryStage 9\n            +- LogicalQueryStage Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8\n"
      },
      "IM" : {
        "inputSizeInBytes" : 66851968,
        "inputRowCount" : 607402
      },
      "PD" : {
        "4" : [ 2478, 2999, 3991, 3628, 3628, 3628, 2999, 3628, 2726, 3298, 2253, 2999, 4390, 2726, 2726, 3298, 2999, 3628, 2726, 2726, 3298, 2726, 3628, 2999, 3628, 3298, 3991, 2999, 3298, 3298, 3298, 3628, 3298, 3628, 3298, 3628, 3298, 3628, 3298, 3991, 3991, 2726, 4390, 3298, 4830, 2999, 2726, 3628, 3298, 3628, 3298, 3628, 3298, 3991, 3628, 2726, 2726, 3298, 3991, 4390, 3628, 2726, 1862, 3298, 3298, 4390, 2726, 3991, 2999, 3298, 4390, 3298, 3298, 2999, 3298, 3298, 2999, 3991, 2999, 3628, 2726, 2048, 3991, 3991, 3628, 2478, 3991, 3628, 3991, 4390, 3298, 3628, 2999, 3628, 3628, 3628, 2478, 2999, 2726, 3298, 3628, 3628, 2726, 3628, 4390, 3298, 3298, 2999, 3298, 3298, 3628, 3628, 3298, 3298, 3628, 3628, 3628, 3628, 3298, 2726, 2726, 2999, 2478, 3298, 3628, 3298, 3628, 3298, 2999, 3298, 3991, 3298, 2478, 3628, 2478, 4390, 3298, 3991, 3628, 3628, 2999, 3628, 2999, 3628, 3298, 3628, 3628, 2999, 3298, 3628, 3298, 2726, 2726, 3991, 3298, 2999, 3628, 3991, 2726, 3298, 3991, 3628, 3298, 3628, 3628, 3298, 4390, 2478, 3298, 2726, 2726, 2999, 3298, 3628, 3991, 3298, 4390, 2726, 3991, 3628, 3628, 2726, 3628, 3991, 3991, 3298, 3628, 2999, 2726, 3298, 3298, 4390, 3991, 2478, 3628, 3628, 4830, 3298, 2726, 2999 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227180917,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 2646,
        "IOBytes" : {
          "Total" : 4850480,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 4165272,
            "SW" : 685208
          }
        }
      }
    },
    "9" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : -1601950037,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 910864785600,
            "rowCount" : 10350736200,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] "
          },
          "8" : {
            "sign" : -1838180546,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 85421896560,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          },
          "4" : {
            "sign" : 1554809633,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 523037917726573289040000,
            "rowCount" : 2782116583651985580000,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "15" : {
            "sign" : -1297019688,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2714947200,
            "rowCount" : 28280700,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#285) "
          },
          "11" : {
            "sign" : 1284763110,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#261], BroadcastQueryStage 2 "
          },
          "9" : {
            "sign" : -1307870132,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256], HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))]) "
          },
          "13" : {
            "sign" : -659531460,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 952267730400,
            "rowCount" : 10350736200,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#318 = d_week_seq#54) "
          },
          "16" : {
            "sign" : -1831807767,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4 "
          },
          "5" : {
            "sign" : -1937189416,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 29028716917200,
            "rowCount" : 268784415900,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "10" : {
            "sign" : -523930085,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1 "
          },
          "6" : {
            "sign" : -668487036,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 30103854580800,
            "rowCount" : 268784415900,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "1" : {
            "sign" : 1949795523,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 456267119718925635120000,
            "rowCount" : 2782116583651985580000,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : 734062518,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 366,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#318], BroadcastQueryStage 5 "
          },
          "14" : {
            "sign" : -335718870,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2488701600,
            "rowCount" : 28280700,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] "
          },
          "0" : {
            "sign" : -1678706230,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 248706912,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 456267119718925635120000,
            "rowCount" : 2782116583651985580000,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "7" : {
            "sign" : -1284572009,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 79530731280,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : -1237414712,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 456267119718925635120000,
            "rowCount" : 2782116583651985580000,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 15,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalQueryStage",
          "toId" : 15,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Join",
          "toId" : 14,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Project",
          "toId" : 13,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 13,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Join",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n            :  +- Join Inner, (d_week_seq#261 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- LogicalQueryStage Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256], HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))])\n            :     :     +- LogicalQueryStage Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1\n            :     +- LogicalQueryStage Project [d_week_seq#261], BroadcastQueryStage 2\n            +- Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n               +- Join Inner, (d_week_seq#318 = d_week_seq#54)\n                  :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n                  :  +- Join Inner, (ss_store_sk#33 = s_store_sk#285)\n                  :     :- LogicalQueryStage Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256], HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))])\n                  :     +- LogicalQueryStage Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4\n                  +- LogicalQueryStage Project [d_week_seq#318], BroadcastQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 141721344,
        "inputRowCount" : 1903715
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227177934,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 5629,
        "IOBytes" : {
          "Total" : 697150088,
          "Details" : {
            "IR" : 686029586,
            "IW" : 0,
            "SR" : 6955230,
            "SW" : 4165272
          }
        }
      }
    },
    "13" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : 1909637285,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 1014667882920,
            "rowCount" : 5397169590,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "5" : {
            "sign" : -2041546065,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 8216880,
            "rowCount" : 73365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239], ShuffleQueryStage 9 "
          },
          "6" : {
            "sign" : 1959290580,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 35651584,
            "rowCount" : 73566,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: LogicalQueryStage Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8, BroadcastQueryStage 10 "
          },
          "1" : {
            "sign" : -2049039549,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 885135812760,
            "rowCount" : 5397169590,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "0" : {
            "sign" : 392389838,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 1091883748,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 885135812760,
            "rowCount" : 5397169590,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "3" : {
            "sign" : 1311330248,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 885135812760,
            "rowCount" : 5397169590,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- LogicalQueryStage Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239], ShuffleQueryStage 9\n            +- LogicalQueryStage LogicalQueryStage Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8, BroadcastQueryStage 10\n"
      },
      "IM" : {
        "inputSizeInBytes" : 43868464,
        "inputRowCount" : 146931
      },
      "PD" : {
        "5" : [ 2726, 3298, 4390, 3628, 3991, 3991, 3298, 3991, 2999, 3298, 2478, 3298, 4390, 3298, 2999, 3298, 2999, 3991, 2999, 2999, 3298, 2999, 3991, 3298, 3628, 3628, 4390, 3298, 3628, 3628, 3628, 3991, 3628, 3991, 3628, 3628, 3628, 3991, 3628, 3991, 3991, 2999, 4830, 3628, 4830, 3298, 2999, 3991, 3298, 3628, 3298, 3628, 3298, 3991, 3991, 2726, 3298, 3628, 4390, 4830, 3628, 2999, 1862, 3298, 3628, 4830, 2999, 3991, 3298, 3298, 4390, 3628, 3628, 3298, 3298, 3628, 3298, 4390, 3298, 3628, 2999, 2253, 3991, 3991, 3991, 2726, 4390, 3991, 3991, 4390, 3628, 3991, 3298, 3628, 3991, 3628, 2726, 3298, 2999, 3628, 3991, 3991, 2999, 3991, 4830, 3628, 3628, 3298, 3628, 3628, 3628, 3991, 3628, 3628, 3991, 3991, 3628, 3991, 3298, 2999, 2999, 3298, 2478, 3628, 3991, 3298, 3628, 3628, 3298, 3298, 3991, 3298, 2726, 3991, 2478, 4830, 3628, 4390, 3991, 3628, 3298, 3628, 3298, 3628, 3628, 3991, 3991, 3298, 3628, 3991, 3628, 2999, 2999, 4390, 3628, 3298, 3628, 3991, 2999, 3628, 4390, 3991, 3298, 3991, 3991, 3628, 4390, 2726, 3298, 2999, 2999, 2999, 3628, 3991, 4390, 3298, 4390, 2999, 3991, 3628, 3991, 2999, 3991, 3991, 3991, 3628, 3628, 2999, 2999, 3298, 3628, 4830, 3991, 2478, 3991, 3991, 5313, 3298, 2999, 2999 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227181407,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 2156,
        "IOBytes" : {
          "Total" : 685208,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 685208,
            "SW" : 0
          }
        }
      }
    },
    "5" : {
      "LQP" : {
        "operators" : {
          "0" : {
            "sign" : 682973872,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1160,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370], ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370], ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 1160,
        "inputRowCount" : 1
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227163565,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 19998,
        "IOBytes" : {
          "Total" : 1386929433,
          "Details" : {
            "IR" : 1373015649,
            "IW" : 0,
            "SR" : 6957460,
            "SW" : 6956324
          }
        }
      }
    },
    "10" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : -1645591697,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 51248256,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8 "
          },
          "8" : {
            "sign" : -1838180546,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 3252442104,
            "rowCount" : 28038294,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          },
          "4" : {
            "sign" : -666802907,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 1070800040207187360,
            "rowCount" : 5463265511261160,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "11" : {
            "sign" : 1284763110,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#261], BroadcastQueryStage 2 "
          },
          "9" : {
            "sign" : -1307870132,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 5579760,
            "rowCount" : 69747,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256], HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))]) "
          },
          "5" : {
            "sign" : -1937189416,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1105269549480,
            "rowCount" : 10233977310,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "10" : {
            "sign" : -523930085,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1 "
          },
          "6" : {
            "sign" : -668487036,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 1146205458720,
            "rowCount" : 10233977310,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "1" : {
            "sign" : -55686265,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 895975543846830240,
            "rowCount" : 5463265511261160,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "0" : {
            "sign" : -1276321842,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : -1368011548,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 895975543846830240,
            "rowCount" : 5463265511261160,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "7" : {
            "sign" : -1284572009,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 3028135752,
            "rowCount" : 28038294,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : 1174540236,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 895975543846830240,
            "rowCount" : 5463265511261160,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 9,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n            :  +- Join Inner, (d_week_seq#261 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- LogicalQueryStage Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256], HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))])\n            :     :     +- LogicalQueryStage Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1\n            :     +- LogicalQueryStage Project [d_week_seq#261], BroadcastQueryStage 2\n            +- LogicalQueryStage Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8\n"
      },
      "IM" : {
        "inputSizeInBytes" : 58928808,
        "inputRowCount" : 604350
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227180825,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 2738,
        "IOBytes" : {
          "Total" : 8285412,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 6955230,
            "SW" : 1330182
          }
        }
      }
    },
    "6" : {
      "LQP" : {
        "operators" : {
          "0" : {
            "sign" : 537328781,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1120,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373], ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373], ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 1120,
        "inputRowCount" : 1
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227163608,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 19955,
        "IOBytes" : {
          "Total" : 1386826106,
          "Details" : {
            "IR" : 1372913416,
            "IW" : 0,
            "SR" : 6957460,
            "SW" : 6955230
          }
        }
      }
    },
    "1" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 1122983647,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
          },
          "8" : {
            "sign" : -1724215008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 69342364680,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          },
          "19" : {
            "sign" : -960740485,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 49112912,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#318 = d_week_seq#54) "
          },
          "23" : {
            "sign" : 1741726474,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "4" : {
            "sign" : 2038535682,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 54716327980032,
            "rowCount" : 284980874896,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "15" : {
            "sign" : -1544469812,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0 "
          },
          "11" : {
            "sign" : 2062469607,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "9" : {
            "sign" : 402242688,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "22" : {
            "sign" : 402242781,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "26" : {
            "sign" : -1831807767,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4 "
          },
          "13" : {
            "sign" : 678988587,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
          },
          "24" : {
            "sign" : 2062469700,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "16" : {
            "sign" : -523930085,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 22512,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1 "
          },
          "5" : {
            "sign" : -1513905076,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 59789632,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "10" : {
            "sign" : 1741726381,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "21" : {
            "sign" : 614652153,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 70693983360,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#285) "
          },
          "6" : {
            "sign" : 453692002,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 61924976,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "1" : {
            "sign" : 322236372,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 47876786982528,
            "rowCount" : 284980874896,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : 1284763110,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#261], BroadcastQueryStage 2 "
          },
          "25" : {
            "sign" : -1544469719,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3 "
          },
          "14" : {
            "sign" : 122295656,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : 70206379,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -1367437049,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 64802818080,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] "
          },
          "27" : {
            "sign" : 734062518,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#318], BroadcastQueryStage 5 "
          },
          "2" : {
            "sign" : -958092351,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 47876786982528,
            "rowCount" : 284980874896,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 1519898900,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 46977568,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] "
          },
          "7" : {
            "sign" : -1273149737,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 64719540368,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : 2095321,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 47876786982528,
            "rowCount" : 284980874896,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "LogicalQueryStage",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Aggregate",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "LogicalQueryStage",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Join",
          "toId" : 23,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Project",
          "toId" : 22,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Aggregate",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "LogicalQueryStage",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "Join",
          "toId" : 20,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Project",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 27,
          "fromName" : "LogicalQueryStage",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Join",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n            :  +- Join Inner, (d_week_seq#261 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n            :     :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n            :     :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n            :     :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n            :     :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n            :     :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n            :     :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0\n            :     :     +- LogicalQueryStage Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1\n            :     +- LogicalQueryStage Project [d_week_seq#261], BroadcastQueryStage 2\n            +- Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n               +- Join Inner, (d_week_seq#318 = d_week_seq#54)\n                  :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n                  :  +- Join Inner, (ss_store_sk#33 = s_store_sk#285)\n                  :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n                  :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n                  :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n                  :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n                  :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n                  :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n                  :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3\n                  :     +- LogicalQueryStage Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4\n                  +- LogicalQueryStage Project [d_week_seq#318], BroadcastQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 83620129052,
        "inputRowCount" : 550238267
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 5,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227163294,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 20269,
        "IOBytes" : {
          "Total" : 1387253200,
          "Details" : {
            "IR" : 1373338280,
            "IW" : 0,
            "SR" : 6957460,
            "SW" : 6957460
          }
        }
      }
    },
    "2" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 1122983647,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
          },
          "8" : {
            "sign" : -1724215008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 85421896560,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          },
          "19" : {
            "sign" : -960740485,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 49112912,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#318 = d_week_seq#54) "
          },
          "23" : {
            "sign" : 1741726474,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "4" : {
            "sign" : 2038535682,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 53576404480448,
            "rowCount" : 284980874896,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "15" : {
            "sign" : -1544469812,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0 "
          },
          "11" : {
            "sign" : 2062469607,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "9" : {
            "sign" : 402242688,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "22" : {
            "sign" : 402242781,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "26" : {
            "sign" : -1831807767,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4 "
          },
          "13" : {
            "sign" : 678988587,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
          },
          "24" : {
            "sign" : 2062469700,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "16" : {
            "sign" : -523930085,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1 "
          },
          "5" : {
            "sign" : -1513905076,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 57654288,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "10" : {
            "sign" : 1741726381,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "21" : {
            "sign" : 614652153,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 70693983360,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#285) "
          },
          "6" : {
            "sign" : 453692002,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 59789632,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "1" : {
            "sign" : 322236372,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 46736863482944,
            "rowCount" : 284980874896,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : 1284763110,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#261], BroadcastQueryStage 2 "
          },
          "25" : {
            "sign" : -1544469719,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3 "
          },
          "14" : {
            "sign" : 122295656,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : 70206379,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -1367437049,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 64802818080,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] "
          },
          "27" : {
            "sign" : 734062518,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#318], BroadcastQueryStage 5 "
          },
          "2" : {
            "sign" : -958092351,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 46736863482944,
            "rowCount" : 284980874896,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 1519898900,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 46977568,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] "
          },
          "7" : {
            "sign" : -1273149737,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 79530731280,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : 2095321,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 46736863482944,
            "rowCount" : 284980874896,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "LogicalQueryStage",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Aggregate",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "LogicalQueryStage",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Join",
          "toId" : 23,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Project",
          "toId" : 22,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Aggregate",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "LogicalQueryStage",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "Join",
          "toId" : 20,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Project",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 27,
          "fromName" : "LogicalQueryStage",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Join",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n            :  +- Join Inner, (d_week_seq#261 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n            :     :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n            :     :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n            :     :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n            :     :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n            :     :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n            :     :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0\n            :     :     +- LogicalQueryStage Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1\n            :     +- LogicalQueryStage Project [d_week_seq#261], BroadcastQueryStage 2\n            +- Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n               +- Join Inner, (d_week_seq#318 = d_week_seq#54)\n                  :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n                  :  +- Join Inner, (ss_store_sk#33 = s_store_sk#285)\n                  :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n                  :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n                  :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n                  :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n                  :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n                  :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n                  :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3\n                  :     +- LogicalQueryStage Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4\n                  +- LogicalQueryStage Project [d_week_seq#318], BroadcastQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 83621158332,
        "inputRowCount" : 550238267
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 3,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227163378,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 20185,
        "IOBytes" : {
          "Total" : 1387135035,
          "Details" : {
            "IR" : 1373220115,
            "IW" : 0,
            "SR" : 6957460,
            "SW" : 6957460
          }
        }
      }
    },
    "7" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 1122983647,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
          },
          "8" : {
            "sign" : -1724215008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 85421896560,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          },
          "19" : {
            "sign" : -960740485,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 7096423686623268945024000,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#318 = d_week_seq#54) "
          },
          "23" : {
            "sign" : 1741726474,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4287882997552,
            "rowCount" : 97451886308,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "4" : {
            "sign" : 2038535682,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 197043549352912736021166892781551243200,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "15" : {
            "sign" : -1544469812,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0 "
          },
          "11" : {
            "sign" : 2062469607,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "9" : {
            "sign" : 402242688,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "22" : {
            "sign" : 402242781,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 7016535814176,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "26" : {
            "sign" : -1831807767,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4 "
          },
          "13" : {
            "sign" : 678988587,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
          },
          "24" : {
            "sign" : 2062469700,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 5067498088016,
            "rowCount" : 97451886308,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "16" : {
            "sign" : -523930085,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1 "
          },
          "5" : {
            "sign" : -1513905076,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 29028716917200,
            "rowCount" : 268784415900,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "10" : {
            "sign" : 1741726381,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "21" : {
            "sign" : 614652153,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 7379936237063803392,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#285) "
          },
          "6" : {
            "sign" : 453692002,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 30103854580800,
            "rowCount" : 268784415900,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "1" : {
            "sign" : 322236372,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 171889053690838769720592395830714914280,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : 1284763110,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#261], BroadcastQueryStage 2 "
          },
          "25" : {
            "sign" : -1544469719,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051544,
            "rowCount" : 371,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3 "
          },
          "14" : {
            "sign" : 122295656,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : 70206379,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -1367437049,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6764941550641819776,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] "
          },
          "27" : {
            "sign" : 734062518,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 366,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#318], BroadcastQueryStage 5 "
          },
          "2" : {
            "sign" : -958092351,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 171889053690838769720592395830714914280,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 1519898900,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6787883526335300730022956,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] "
          },
          "7" : {
            "sign" : -1273149737,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 79530731280,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : 2095321,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 171889053690838769720592395830714914280,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "LogicalQueryStage",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Aggregate",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "LogicalQueryStage",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Join",
          "toId" : 23,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Project",
          "toId" : 22,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Aggregate",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "LogicalQueryStage",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "Join",
          "toId" : 20,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Project",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 27,
          "fromName" : "LogicalQueryStage",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Join",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n            :  +- Join Inner, (d_week_seq#261 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n            :     :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n            :     :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n            :     :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n            :     :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n            :     :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n            :     :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0\n            :     :     +- LogicalQueryStage Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1\n            :     +- LogicalQueryStage Project [d_week_seq#261], BroadcastQueryStage 2\n            +- Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n               +- Join Inner, (d_week_seq#318 = d_week_seq#54)\n                  :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n                  :  +- Join Inner, (ss_store_sk#33 = s_store_sk#285)\n                  :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n                  :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n                  :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n                  :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n                  :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n                  :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n                  :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3\n                  :     +- LogicalQueryStage Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4\n                  +- LogicalQueryStage Project [d_week_seq#318], BroadcastQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 83621670204,
        "inputRowCount" : 550165661
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227164695,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 18868,
        "IOBytes" : {
          "Total" : 1386396754,
          "Details" : {
            "IR" : 1372486294,
            "IW" : 0,
            "SR" : 6955230,
            "SW" : 6955230
          }
        }
      }
    },
    "3" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : 1122983647,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
          },
          "8" : {
            "sign" : -1724215008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 85421896560,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          },
          "19" : {
            "sign" : -960740485,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 49112912,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#318 = d_week_seq#54) "
          },
          "23" : {
            "sign" : 1741726474,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "4" : {
            "sign" : 2038535682,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 26975517919921771200,
            "rowCount" : 143486797446392400,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "15" : {
            "sign" : -1544469812,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0 "
          },
          "11" : {
            "sign" : 2062469607,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "9" : {
            "sign" : 402242688,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "22" : {
            "sign" : 402242781,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "26" : {
            "sign" : -1831807767,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4 "
          },
          "13" : {
            "sign" : 678988587,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
          },
          "24" : {
            "sign" : 2062469700,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "16" : {
            "sign" : -523930085,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1 "
          },
          "5" : {
            "sign" : -1513905076,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 29028716917200,
            "rowCount" : 268784415900,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "10" : {
            "sign" : 1741726381,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "21" : {
            "sign" : 614652153,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 70693983360,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#285) "
          },
          "6" : {
            "sign" : 453692002,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 30103854580800,
            "rowCount" : 268784415900,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "1" : {
            "sign" : 322236372,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 23531834781208353600,
            "rowCount" : 143486797446392400,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : 1284763110,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1049000,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#261], BroadcastQueryStage 2 "
          },
          "25" : {
            "sign" : -1544469719,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3 "
          },
          "14" : {
            "sign" : 122295656,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "0" : {
            "sign" : 70206379,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -1367437049,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 64802818080,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] "
          },
          "27" : {
            "sign" : 734062518,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#318], BroadcastQueryStage 5 "
          },
          "2" : {
            "sign" : -958092351,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 23531834781208353600,
            "rowCount" : 143486797446392400,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 1519898900,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 46977568,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] "
          },
          "7" : {
            "sign" : -1273149737,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 79530731280,
            "rowCount" : 736395660,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : 2095321,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 23531834781208353600,
            "rowCount" : 143486797446392400,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 14,
          "fromName" : "LogicalRelation",
          "toId" : 13,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 13,
          "fromName" : "Filter",
          "toId" : 12,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "LogicalQueryStage",
          "toId" : 11,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Join",
          "toId" : 10,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Project",
          "toId" : 9,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Aggregate",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 6,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Join",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 12,
          "fromName" : "Project",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "LogicalQueryStage",
          "toId" : 24,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Join",
          "toId" : 23,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Project",
          "toId" : 22,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Aggregate",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "LogicalQueryStage",
          "toId" : 21,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "Join",
          "toId" : 20,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Project",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 27,
          "fromName" : "LogicalQueryStage",
          "toId" : 19,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Join",
          "toId" : 18,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n            :  +- Join Inner, (d_week_seq#261 = d_week_seq#54)\n            :     :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n            :     :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n            :     :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n            :     :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n            :     :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n            :     :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n            :     :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n            :     :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n            :     :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 0\n            :     :     +- LogicalQueryStage Project [s_store_sk#78, s_store_id#79, s_store_name#83], BroadcastQueryStage 1\n            :     +- LogicalQueryStage Project [d_week_seq#261], BroadcastQueryStage 2\n            +- Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n               +- Join Inner, (d_week_seq#318 = d_week_seq#54)\n                  :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n                  :  +- Join Inner, (ss_store_sk#33 = s_store_sk#285)\n                  :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n                  :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n                  :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n                  :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n                  :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n                  :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n                  :     :        +- LogicalQueryStage Project [d_date_sk#50, d_week_seq#54, d_day_name#64], BroadcastQueryStage 3\n                  :     +- LogicalQueryStage Project [s_store_sk#285, s_store_id#286], BroadcastQueryStage 4\n                  +- LogicalQueryStage Project [d_week_seq#318], BroadcastQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 83622203300,
        "inputRowCount" : 550238296
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 2,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227163440,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 20123,
        "IOBytes" : {
          "Total" : 1387032802,
          "Details" : {
            "IR" : 1373117882,
            "IW" : 0,
            "SR" : 6957460,
            "SW" : 6957460
          }
        }
      }
    }
  },
  "RuntimeQSs" : {
    "12" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 414091538,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 51248256,
                "rowCount" : 533836
              },
              "compileTime" : {
                "sizeInBytes" : 51248256,
                "rowCount" : 533836
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] "
          },
          "1" : {
            "sign" : 1466181379,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 53383600,
                "rowCount" : 533836
              },
              "compileTime" : {
                "sizeInBytes" : 53383600,
                "rowCount" : 533836
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#318 = d_week_seq#54) "
          },
          "2" : {
            "sign" : -959706114,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 55473891744,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 55473891744,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] "
          },
          "3" : {
            "sign" : -901334022,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 60096716056,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 60096716056,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#285) "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Project",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n+- Join Inner, (d_week_seq#318 = d_week_seq#54)\n   :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n   :  +- Join Inner, (ss_store_sk#33 = s_store_sk#285)\n   :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n   :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n   :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n   :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n   :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n   :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n   :     :        +- Project [d_date_sk#50, d_week_seq#54, d_day_name#64]\n   :     :           +- Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#374 [], xxhash64(d_week_seq#54, 42)))\n   :     :              :  +- Aggregate [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373]\n   :     :              :     +- Project [d_week_seq#318]\n   :     :              :        +- Filter ((isnotnull(d_month_seq#317) AND ((d_month_seq#317 >= 1197) AND (d_month_seq#317 <= 1208))) AND isnotnull(d_week_seq#318))\n   :     :              :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#314,d_date_id#315,d_date#316,d_month_seq#317,d_week_seq#318,d_quarter_seq#319,d_year#320,d_dow#321,d_moy#322,d_dom#323,d_qoy#324,d_fy_year#325,d_fy_quarter_seq#326,d_fy_week_seq#327,d_day_name#328,d_quarter_name#329,d_holiday#330,d_weekend#331,d_following_holiday#332,d_first_dom#333,d_last_dom#334,d_same_day_ly#335,d_same_day_lq#336,d_current_day#337,... 4 more fields] parquet\n   :     :              +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_date_id#51,d_date#52,d_month_seq#53,d_week_seq#54,d_quarter_seq#55,d_year#56,d_dow#57,d_moy#58,d_dom#59,d_qoy#60,d_fy_year#61,d_fy_quarter_seq#62,d_fy_week_seq#63,d_day_name#64,d_quarter_name#65,d_holiday#66,d_weekend#67,d_following_holiday#68,d_first_dom#69,d_last_dom#70,d_same_day_ly#71,d_same_day_lq#72,d_current_day#73,... 4 more fields] parquet\n   :     +- Project [s_store_sk#285, s_store_id#286]\n   :        +- Filter (isnotnull(s_store_sk#285) AND isnotnull(s_store_id#286))\n   :           +- Relation spark_catalog.tpcds_100.store[s_store_sk#285,s_store_id#286,s_rec_start_date#287,s_rec_end_date#288,s_closed_date_sk#289,s_store_name#290,s_number_employees#291,s_floor_space#292,s_hours#293,s_manager#294,s_market_id#295,s_geography_class#296,s_market_desc#297,s_market_manager#298,s_division_id#299,s_division_name#300,s_company_id#301,s_company_name#302,s_street_number#303,s_street_name#304,s_street_type#305,s_suite_number#306,s_city#307,s_county#308,... 5 more fields] parquet\n   +- Project [d_week_seq#318]\n      +- Filter ((isnotnull(d_month_seq#317) AND ((d_month_seq#317 >= 1197) AND (d_month_seq#317 <= 1208))) AND isnotnull(d_week_seq#318))\n         +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#314,d_date_id#315,d_date#316,d_month_seq#317,d_week_seq#318,d_quarter_seq#319,d_year#320,d_dow#321,d_moy#322,d_dom#323,d_qoy#324,d_fy_year#325,d_fy_quarter_seq#326,d_fy_week_seq#327,d_day_name#328,d_quarter_name#329,d_holiday#330,d_weekend#331,d_following_holiday#332,d_first_dom#333,d_last_dom#334,d_same_day_ly#335,d_same_day_lq#336,d_current_day#337,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : -1037659061,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 5628000,
            "rowCount" : 70350,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [9]: [d_week_seq#54, ss_store_sk#33, sum#398L, sum#399L, sum#400L, sum#401L, sum#402L, sum#403L, sum#404L] Keys [2]: [d_week_seq#54, ss_store_sk#33] Functions [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))] Aggregate Attributes [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END))#342L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END))#343L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END))#344L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END))#345L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END))#346L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END))#347L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))#348L] Results [9]: [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END))#342L,17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END))#343L,17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END))#344L,17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END))#345L,17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END))#346L,17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END))#347L,17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))#348L,17,2) AS sat_sales#256] "
          },
          "5" : {
            "sign" : 555831614,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [9]: [d_week_seq#54, ss_store_sk#33, sum#398L, sum#399L, sum#400L, sum#401L, sum#402L, sum#403L, sum#404L] Arguments: 6 "
          },
          "6" : {
            "sign" : 256368621,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [2]: [s_store_sk#285, s_store_id#286] Arguments: 4 "
          },
          "1" : {
            "sign" : 263735786,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 53383600,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [d_week_seq#54] Right keys [1]: [d_week_seq#318] Join type: Inner Join condition: None "
          },
          "0" : {
            "sign" : -1875595783,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 51248256,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [9]: [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249] Input [10]: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286, d_week_seq#318] "
          },
          "2" : {
            "sign" : 1567222261,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 55473891744,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [9]: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286] Input [11]: [d_week_seq#54, ss_store_sk#33, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_sk#285, s_store_id#286] "
          },
          "7" : {
            "sign" : -356751603,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1049000,
            "rowCount" : 366,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [1]: [d_week_seq#318] Arguments: 5 "
          },
          "3" : {
            "sign" : 1191233423,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 60096716056,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_store_sk#33] Right keys [1]: [s_store_sk#285] Join type: Inner Join condition: None "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "ShuffleQueryStage",
          "toId" : 4,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "HashAggregate",
          "toId" : 3,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "BroadcastQueryStage",
          "toId" : 3,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "BroadcastHashJoin",
          "toId" : 2,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Project",
          "toId" : 1,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "BroadcastQueryStage",
          "toId" : 1,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "BroadcastHashJoin",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n+- BroadcastHashJoin [d_week_seq#54], [d_week_seq#318], Inner, BuildRight, false\n   :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n   :  +- BroadcastHashJoin [ss_store_sk#33], [s_store_sk#285], Inner, BuildRight, false\n   :     :- HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256])\n   :     :  +- ShuffleQueryStage 6\n   :     :     +- Exchange hashpartitioning(d_week_seq#54, ss_store_sk#33, 200), ENSURE_REQUIREMENTS, [plan_id=1149]\n   :     :        +- *(7) HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sum#398L, sum#399L, sum#400L, sum#401L, sum#402L, sum#403L, sum#404L])\n   :     :           +- *(7) Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n   :     :              +- *(7) BroadcastHashJoin [ss_sold_date_sk#49], [d_date_sk#50], Inner, BuildRight, false\n   :     :                 :- *(7) Filter isnotnull(ss_store_sk#33)\n   :     :                 :  +- *(7) ColumnarToRow\n   :     :                 :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#33,ss_sales_price#39,ss_sold_date_sk#49] Batched: true, DataFilters: [isnotnull(ss_store_sk#33)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#49)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n   :     :                 +- BroadcastQueryStage 3\n   :     :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=408]\n   :     :                       +- *(4) Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#374, [id=#164], xxhash64(d_week_seq#54, 42)))\n   :     :                          :  +- Subquery subquery#374, [id=#164]\n   :     :                          :     +- AdaptiveSparkPlan isFinalPlan=true\n                                             +- == Final Plan ==\n                                                ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n                                                +- ShuffleQueryStage 0\n                                                   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=497]\n                                                      +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n                                                         +- *(1) Project [d_week_seq#318]\n                                                            +- *(1) Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                                               +- *(1) ColumnarToRow\n                                                                  +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n                                             +- == Initial Plan ==\n                                                ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n                                                +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=162]\n                                                   +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n                                                      +- Project [d_week_seq#318]\n                                                         +- Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                                            +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n   :     :                          +- *(4) ColumnarToRow\n   :     :                             +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n   :     +- BroadcastQueryStage 4\n   :        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=428]\n   :           +- *(5) Filter (isnotnull(s_store_sk#285) AND isnotnull(s_store_id#286))\n   :              +- *(5) ColumnarToRow\n   :                 +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#285,s_store_id#286] Batched: true, DataFilters: [isnotnull(s_store_sk#285), isnotnull(s_store_id#286)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string>\n   +- BroadcastQueryStage 5\n      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=447]\n         +- *(6) Project [d_week_seq#318]\n            +- *(6) Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n               +- *(6) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 7728792,
        "inputRowCount" : 71118
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "2" : [ 14052, 15813, 13864, 13632, 13325, 14291, 14068, 14811, 14934, 15049, 15767, 16638, 13850, 13416, 16086, 12427, 14669, 13582, 14326, 13253, 14280, 12605, 15064, 13824, 16593, 16211, 15013, 13545, 13850, 14648, 15420, 13060, 15343, 13401, 11222, 14181, 12507, 13781, 13500, 14437, 12541, 14918, 14090, 15657, 12771, 13983, 15923, 16853, 15335, 14213, 16681, 15112, 13159, 15716, 12009, 15291, 11722, 15888, 14154, 14900, 15733, 14732, 13503, 13132, 13618, 13296, 14183, 17008, 13660, 15121, 12455, 15501, 15781, 14585, 16257, 15058, 11946, 11869, 13966, 14163, 14397, 16604, 15133, 14534, 16923, 16357, 12923, 15341, 17411, 14621, 16396, 14760, 14709, 16202, 14909, 15898, 14996, 14824, 15248, 14907, 16501, 14823, 13596, 15359, 13486, 13918, 11532, 13993, 16584, 14139, 13695, 13959, 14601, 15237, 15042, 14399, 13973, 14383, 14518, 15067, 14791, 14760, 15537, 14478, 16441, 14797, 15407, 15897, 16237, 12014, 14144, 14644, 13061, 15434, 14397, 14477, 11903, 14310, 13634, 14357, 15324, 11800, 12171, 14018, 15492, 13099, 14803, 14512, 17075, 14743, 15165, 14212, 15314, 15366, 14703, 14664, 14143, 12225, 14304, 15013, 14709, 14566, 15731, 13130, 14884, 14265, 13176, 13274, 15177, 14329, 13962, 12927, 16115, 14940, 15017, 14223, 14761, 16962, 13843, 17299, 14259, 13214, 11719, 14631, 17255, 14356, 16249, 14108, 17699, 14973, 14888, 15866, 15905, 15798, 12549, 14536, 12985, 16212, 14153, 16272 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 1,
        "FinishedTasksTotalTimeInMs" : 282.0,
        "FinishedTasksDistributionInMs" : [ 282.0, 282.0, 282.0, 282.0, 282.0 ]
      },
      "QueryStageOptimizationId" : 12,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 16 ],
      "Objectives" : {
        "DurationInMs" : 2817,
        "TotalTasksDurationInMs" : 366,
        "IOBytes" : {
          "Total" : 3434932,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 2789958,
            "SW" : 644974
          }
        }
      }
    },
    "8" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -30884576,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 16080,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 16080,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#285, s_store_id#286] "
          },
          "1" : {
            "sign" : 1201031723,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_store_sk#285) AND isnotnull(s_store_id#286)) "
          },
          "2" : {
            "sign" : -1476112881,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#285, s_store_id#286, s_rec_start_date#287, s_rec_end_date#288, s_closed_date_sk#289, s_store_name#290, s_number_employees#291, s_floor_space#292, s_hours#293, s_manager#294, s_market_id#295, s_geography_class#296, s_market_desc#297, s_market_manager#298, s_division_id#299, s_division_name#300, s_company_id#301, s_company_name#302, s_street_number#303, s_street_name#304, s_street_type#305, s_suite_number#306, s_city#307, s_county#308, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_store_sk#285, s_store_id#286]\n+- Filter (isnotnull(s_store_sk#285) AND isnotnull(s_store_id#286))\n   +- Relation spark_catalog.tpcds_100.store[s_store_sk#285,s_store_id#286,s_rec_start_date#287,s_rec_end_date#288,s_closed_date_sk#289,s_store_name#290,s_number_employees#291,s_floor_space#292,s_hours#293,s_manager#294,s_market_id#295,s_geography_class#296,s_market_desc#297,s_market_manager#298,s_division_id#299,s_division_name#300,s_company_id#301,s_company_name#302,s_street_number#303,s_street_name#304,s_street_type#305,s_suite_number#306,s_city#307,s_county#308,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1914747925,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 16080,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [s_store_sk#285, s_store_id#286] Condition : (isnotnull(s_store_sk#285) AND isnotnull(s_store_id#286)) "
          },
          "1" : {
            "sign" : -1053558321,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 16080,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store Output [2]: [s_store_sk#285, s_store_id#286] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store] PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)] ReadSchema: struct<s_store_sk:int,s_store_id:string> "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store",
          "toId" : 0,
          "toName" : "Filter",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Filter (isnotnull(s_store_sk#285) AND isnotnull(s_store_id#286))\n+- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#285,s_store_id#286] Batched: true, DataFilters: [isnotnull(s_store_sk#285), isnotnull(s_store_id#286)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 16080,
        "inputRowCount" : 402
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 4,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 6 ],
      "Objectives" : {
        "DurationInMs" : 1534,
        "TotalTasksDurationInMs" : 1527,
        "IOBytes" : {
          "Total" : 15932,
          "Details" : {
            "IR" : 15932,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "4" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -1594511434,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 4032,
                "rowCount" : 336
              },
              "compileTime" : {
                "sizeInBytes" : 4032,
                "rowCount" : 336
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#261] "
          },
          "1" : {
            "sign" : -509192512,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 82656,
                "rowCount" : 336
              },
              "compileTime" : {
                "sizeInBytes" : 82656,
                "rowCount" : 336
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#260) AND ((d_month_seq#260 >= 1185) AND (d_month_seq#260 <= 1196))) AND isnotnull(d_week_seq#261)) "
          },
          "2" : {
            "sign" : -1049610981,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#257, d_date_id#258, d_date#259, d_month_seq#260, d_week_seq#261, d_quarter_seq#262, d_year#263, d_dow#264, d_moy#265, d_dom#266, d_qoy#267, d_fy_year#268, d_fy_quarter_seq#269, d_fy_week_seq#270, d_day_name#271, d_quarter_name#272, d_holiday#273, d_weekend#274, d_following_holiday#275, d_first_dom#276, d_last_dom#277, d_same_day_ly#278, d_same_day_lq#279, d_current_day#280, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_week_seq#261]\n+- Filter ((isnotnull(d_month_seq#260) AND ((d_month_seq#260 >= 1185) AND (d_month_seq#260 <= 1196))) AND isnotnull(d_week_seq#261))\n   +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#257,d_date_id#258,d_date#259,d_month_seq#260,d_week_seq#261,d_quarter_seq#262,d_year#263,d_dow#264,d_moy#265,d_dom#266,d_qoy#267,d_fy_year#268,d_fy_quarter_seq#269,d_fy_week_seq#270,d_day_name#271,d_quarter_name#272,d_holiday#273,d_weekend#274,d_following_holiday#275,d_first_dom#276,d_last_dom#277,d_same_day_ly#278,d_same_day_lq#279,d_current_day#280,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 852723274,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [d_week_seq#261] Input [2]: [d_month_seq#260, d_week_seq#261] "
          },
          "1" : {
            "sign" : 1911566212,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [d_month_seq#260, d_week_seq#261] Condition : (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261)) "
          },
          "2" : {
            "sign" : -652324793,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.date_dim Output [2]: [d_month_seq#260, d_week_seq#261] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim] PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196), IsNotNull(d_week_seq)] ReadSchema: struct<d_month_seq:int,d_week_seq:int> "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.date_dim",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_week_seq#261]\n+- Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n   +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 4032,
        "inputRowCount" : 336
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 2,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 4 ],
      "Objectives" : {
        "DurationInMs" : 1648,
        "TotalTasksDurationInMs" : 1644,
        "IOBytes" : {
          "Total" : 102233,
          "Details" : {
            "IR" : 102233,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "15" : {
      "QSLogical" : {
        "operators" : {
          "4" : {
            "sign" : 603652736,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 7540258401792,
                "rowCount" : 39272179176
              },
              "compileTime" : {
                "sizeInBytes" : 7540258401792,
                "rowCount" : 39272179176
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52))) "
          },
          "5" : {
            "sign" : -2041546065,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 8216880,
                "rowCount" : 73365
              },
              "compileTime" : {
                "sizeInBytes" : 59789632,
                "rowCount" : 533836
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239], ShuffleQueryStage 9 "
          },
          "1" : {
            "sign" : -1076008290,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6597726101568,
                "rowCount" : 39272179176
              },
              "compileTime" : {
                "sizeInBytes" : 6597726101568,
                "rowCount" : 39272179176
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "0" : {
            "sign" : 895089129,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 16400,
                "rowCount" : 100
              },
              "compileTime" : {
                "sizeInBytes" : 16400,
                "rowCount" : 100
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 150979455,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6597726101568,
                "rowCount" : 39272179176
              },
              "compileTime" : {
                "sizeInBytes" : 6597726101568,
                "rowCount" : 39272179176
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true "
          },
          "3" : {
            "sign" : -532882077,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6597726101568,
                "rowCount" : 39272179176
              },
              "compileTime" : {
                "sizeInBytes" : 6597726101568,
                "rowCount" : 39272179176
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], true\n      +- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n         +- Join Inner, ((s_store_id1#232 = s_store_id2#242) AND (d_week_seq1#231 = (d_week_seq2#241 - 52)))\n            :- LogicalQueryStage Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239], ShuffleQueryStage 9\n            +- LogicalQueryStage Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : -1193896796,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 35651584,
            "rowCount" : 73566,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [9]: [d_week_seq2#241, s_store_id2#242, sun_sales2#243, mon_sales2#244, tue_sales2#245, wed_sales2#246, thu_sales2#247, fri_sales2#248, sat_sales2#249] Arguments: 10 "
          },
          "1" : {
            "sign" : 1728709233,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 6597726101568,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [10]: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355] Input [19]: [s_store_name1#230, d_week_seq1#231, s_store_id1#232, sun_sales1#233, mon_sales1#234, tue_sales1#235, wed_sales1#236, thu_sales1#237, fri_sales1#238, sat_sales1#239, d_week_seq2#241, s_store_id2#242, sun_sales2#243, mon_sales2#244, tue_sales2#245, wed_sales2#246, thu_sales2#247, fri_sales2#248, sat_sales2#249] "
          },
          "0" : {
            "sign" : -157719579,
            "className" : "org.apache.spark.sql.execution.TakeOrderedAndProjectExec",
            "sizeInBytes" : 16400,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) TakeOrderedAndProject Input [10]: [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1 / sun_sales2)#349, (mon_sales1 / mon_sales2)#350, (tue_sales1 / tue_sales2)#351, (wed_sales1 / wed_sales2)#352, (thu_sales1 / thu_sales2)#353, (fri_sales1 / fri_sales2)#354, (sat_sales1 / sat_sales2)#355] Arguments: 100, [s_store_name1#230 ASC NULLS FIRST, s_store_id1#232 ASC NULLS FIRST, d_week_seq1#231 ASC NULLS FIRST], [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1 / sun_sales2)#349, (mon_sales1 / mon_sales2)#350, (tue_sales1 / tue_sales2)#351, (wed_sales1 / wed_sales2)#352, (thu_sales1 / thu_sales2)#353, (fri_sales1 / fri_sales2)#354, (sat_sales1 / sat_sales2)#355] "
          },
          "2" : {
            "sign" : -2125540428,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 7540258401792,
            "rowCount" : 39272179176,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [2]: [s_store_id1#232, d_week_seq1#231] Right keys [2]: [s_store_id2#242, (d_week_seq2#241 - 52)] Join type: Inner Join condition: None "
          },
          "3" : {
            "sign" : -1287451782,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 8216880,
            "rowCount" : 73365,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [10]: [s_store_name1#230, d_week_seq1#231, s_store_id1#232, sun_sales1#233, mon_sales1#234, tue_sales1#235, wed_sales1#236, thu_sales1#237, fri_sales1#238, sat_sales1#239] Arguments: 9 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "ShuffleQueryStage",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "BroadcastQueryStage",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "BroadcastHashJoin",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "TakeOrderedAndProject",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "TakeOrderedAndProject(limit=100, orderBy=[s_store_name1#230 ASC NULLS FIRST,s_store_id1#232 ASC NULLS FIRST,d_week_seq1#231 ASC NULLS FIRST], output=[s_store_name1#230,s_store_id1#232,d_week_seq1#231,(sun_sales1 / sun_sales2)#349,(mon_sales1 / mon_sales2)#350,(tue_sales1 / tue_sales2)#351,(wed_sales1 / wed_sales2)#352,(thu_sales1 / thu_sales2)#353,(fri_sales1 / fri_sales2)#354,(sat_sales1 / sat_sales2)#355])\n+- Project [s_store_name1#230, s_store_id1#232, d_week_seq1#231, (sun_sales1#233 / sun_sales2#243) AS (sun_sales1 / sun_sales2)#349, (mon_sales1#234 / mon_sales2#244) AS (mon_sales1 / mon_sales2)#350, (tue_sales1#235 / tue_sales2#245) AS (tue_sales1 / tue_sales2)#351, (wed_sales1#236 / wed_sales2#246) AS (wed_sales1 / wed_sales2)#352, (thu_sales1#237 / thu_sales2#247) AS (thu_sales1 / thu_sales2)#353, (fri_sales1#238 / fri_sales2#248) AS (fri_sales1 / fri_sales2)#354, (sat_sales1#239 / sat_sales2#249) AS (sat_sales1 / sat_sales2)#355]\n   +- BroadcastHashJoin [s_store_id1#232, d_week_seq1#231], [s_store_id2#242, (d_week_seq2#241 - 52)], Inner, BuildRight, false\n      :- ShuffleQueryStage 9\n      :  +- Exchange hashpartitioning(s_store_id1#232, d_week_seq1#231, 200), ENSURE_REQUIREMENTS, [plan_id=1464]\n      :     +- *(10) Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n      :        +- *(10) BroadcastHashJoin [d_week_seq#54], [d_week_seq#261], Inner, BuildRight, false\n      :           :- *(10) Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n      :           :  +- *(10) BroadcastHashJoin [ss_store_sk#33], [s_store_sk#78], Inner, BuildRight, false\n      :           :     :- *(10) HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256])\n      :           :     :  +- AQEShuffleRead coalesced\n      :           :     :     +- ShuffleQueryStage 7\n      :           :     :        +- Exchange hashpartitioning(d_week_seq#54, ss_store_sk#33, 200), ENSURE_REQUIREMENTS, [plan_id=1274]\n      :           :     :           +- *(8) HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sum#384L, sum#385L, sum#386L, sum#387L, sum#388L, sum#389L, sum#390L])\n      :           :     :              +- *(8) Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n      :           :     :                 +- *(8) BroadcastHashJoin [ss_sold_date_sk#49], [d_date_sk#50], Inner, BuildRight, false\n      :           :     :                    :- *(8) Filter isnotnull(ss_store_sk#33)\n      :           :     :                    :  +- *(8) ColumnarToRow\n      :           :     :                    :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#33,ss_sales_price#39,ss_sold_date_sk#49] Batched: true, DataFilters: [isnotnull(ss_store_sk#33)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#49)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n      :           :     :                    +- BroadcastQueryStage 0\n      :           :     :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=301]\n      :           :     :                          +- *(1) Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#371, [id=#151], xxhash64(d_week_seq#54, 42)))\n      :           :     :                             :  +- Subquery subquery#371, [id=#151]\n      :           :     :                             :     +- AdaptiveSparkPlan isFinalPlan=true\n                                                               +- == Final Plan ==\n                                                                  ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[bloomFilter#370])\n                                                                  +- ShuffleQueryStage 0\n                                                                     +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=477]\n                                                                        +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n                                                                           +- *(1) Project [d_week_seq#261]\n                                                                              +- *(1) Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n                                                                                 +- *(1) ColumnarToRow\n                                                                                    +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n                                                               +- == Initial Plan ==\n                                                                  ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[bloomFilter#370])\n                                                                  +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=149]\n                                                                     +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n                                                                        +- Project [d_week_seq#261]\n                                                                           +- Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n                                                                              +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n      :           :     :                             +- *(1) ColumnarToRow\n      :           :     :                                +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n      :           :     +- BroadcastQueryStage 1\n      :           :        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=321]\n      :           :           +- *(2) Filter (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79))\n      :           :              +- *(2) ColumnarToRow\n      :           :                 +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#78,s_store_id#79,s_store_name#83] Batched: true, DataFilters: [isnotnull(s_store_sk#78), isnotnull(s_store_id#79)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string>\n      :           +- BroadcastQueryStage 2\n      :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=340]\n      :                 +- *(3) Project [d_week_seq#261]\n      :                    +- *(3) Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n      :                       +- *(3) ColumnarToRow\n      :                          +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n      +- BroadcastQueryStage 10\n         +- BroadcastExchange HashedRelationBroadcastMode(List(input[1, string, true], (input[0, int, true] - 52)),false), [plan_id=1505]\n            +- AQEShuffleRead local\n               +- ShuffleQueryStage 8\n                  +- Exchange hashpartitioning(s_store_id2#242, (d_week_seq2#241 - 52), 200), ENSURE_REQUIREMENTS, [plan_id=1391]\n                     +- *(9) Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n                        +- *(9) BroadcastHashJoin [d_week_seq#54], [d_week_seq#318], Inner, BuildRight, false\n                           :- *(9) Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n                           :  +- *(9) BroadcastHashJoin [ss_store_sk#33], [s_store_sk#285], Inner, BuildRight, false\n                           :     :- *(9) HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256])\n                           :     :  +- AQEShuffleRead coalesced\n                           :     :     +- ShuffleQueryStage 6\n                           :     :        +- Exchange hashpartitioning(d_week_seq#54, ss_store_sk#33, 200), ENSURE_REQUIREMENTS, [plan_id=1149]\n                           :     :           +- *(7) HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sum#398L, sum#399L, sum#400L, sum#401L, sum#402L, sum#403L, sum#404L])\n                           :     :              +- *(7) Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n                           :     :                 +- *(7) BroadcastHashJoin [ss_sold_date_sk#49], [d_date_sk#50], Inner, BuildRight, false\n                           :     :                    :- *(7) Filter isnotnull(ss_store_sk#33)\n                           :     :                    :  +- *(7) ColumnarToRow\n                           :     :                    :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#33,ss_sales_price#39,ss_sold_date_sk#49] Batched: true, DataFilters: [isnotnull(ss_store_sk#33)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#49)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n                           :     :                    +- BroadcastQueryStage 3\n                           :     :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=408]\n                           :     :                          +- *(4) Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#374, [id=#164], xxhash64(d_week_seq#54, 42)))\n                           :     :                             :  +- Subquery subquery#374, [id=#164]\n                           :     :                             :     +- AdaptiveSparkPlan isFinalPlan=true\n                                                                        +- == Final Plan ==\n                                                                           ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n                                                                           +- ShuffleQueryStage 0\n                                                                              +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=497]\n                                                                                 +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n                                                                                    +- *(1) Project [d_week_seq#318]\n                                                                                       +- *(1) Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                                                                          +- *(1) ColumnarToRow\n                                                                                             +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n                                                                        +- == Initial Plan ==\n                                                                           ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n                                                                           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=162]\n                                                                              +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n                                                                                 +- Project [d_week_seq#318]\n                                                                                    +- Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                                                                       +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n                           :     :                             +- *(4) ColumnarToRow\n                           :     :                                +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n                           :     +- BroadcastQueryStage 4\n                           :        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=428]\n                           :           +- *(5) Filter (isnotnull(s_store_sk#285) AND isnotnull(s_store_id#286))\n                           :              +- *(5) ColumnarToRow\n                           :                 +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#285,s_store_id#286] Batched: true, DataFilters: [isnotnull(s_store_sk#285), isnotnull(s_store_id#286)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string>\n                           +- BroadcastQueryStage 5\n                              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=447]\n                                 +- *(6) Project [d_week_seq#318]\n                                    +- *(6) Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                       +- *(6) ColumnarToRow\n                                          +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 43868464,
        "inputRowCount" : 146931
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "5" : [ 2726, 3298, 4390, 3628, 3991, 3991, 3298, 3991, 2999, 3298, 2478, 3298, 4390, 3298, 2999, 3298, 2999, 3991, 2999, 2999, 3298, 2999, 3991, 3298, 3628, 3628, 4390, 3298, 3628, 3628, 3628, 3991, 3628, 3991, 3628, 3628, 3628, 3991, 3628, 3991, 3991, 2999, 4830, 3628, 4830, 3298, 2999, 3991, 3298, 3628, 3298, 3628, 3298, 3991, 3991, 2726, 3298, 3628, 4390, 4830, 3628, 2999, 1862, 3298, 3628, 4830, 2999, 3991, 3298, 3298, 4390, 3628, 3628, 3298, 3298, 3628, 3298, 4390, 3298, 3628, 2999, 2253, 3991, 3991, 3991, 2726, 4390, 3991, 3991, 4390, 3628, 3991, 3298, 3628, 3991, 3628, 2726, 3298, 2999, 3628, 3991, 3991, 2999, 3991, 4830, 3628, 3628, 3298, 3628, 3628, 3628, 3991, 3628, 3628, 3991, 3991, 3628, 3991, 3298, 2999, 2999, 3298, 2478, 3628, 3991, 3298, 3628, 3628, 3298, 3298, 3991, 3298, 2726, 3991, 2478, 4830, 3628, 4390, 3991, 3628, 3298, 3628, 3298, 3628, 3628, 3991, 3991, 3298, 3628, 3991, 3628, 2999, 2999, 4390, 3628, 3298, 3628, 3991, 2999, 3628, 4390, 3991, 3298, 3991, 3991, 3628, 4390, 2726, 3298, 2999, 2999, 2999, 3628, 3991, 4390, 3298, 4390, 2999, 3991, 3628, 3991, 2999, 3991, 3991, 3991, 3628, 3628, 2999, 2999, 3298, 3628, 4830, 3991, 2478, 3991, 3991, 5313, 3298, 2999, 2999 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 15,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 24 ],
      "Objectives" : {
        "DurationInMs" : 2026,
        "TotalTasksDurationInMs" : 2020,
        "IOBytes" : {
          "Total" : 685208,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 685208,
            "SW" : 0
          }
        }
      }
    },
    "11" : {
      "QSLogical" : {
        "operators" : {
          "4" : {
            "sign" : 678988587,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
          },
          "5" : {
            "sign" : 122295656,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              },
              "compileTime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "1" : {
            "sign" : 12420923,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 11683785740,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 11683785740,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "0" : {
            "sign" : 1658870036,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 131891760,
                "rowCount" : 1831830
              },
              "compileTime" : {
                "sizeInBytes" : 131891760,
                "rowCount" : 1831830
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "2" : {
            "sign" : 1024191117,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 13808110420,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 13808110420,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "3" : {
            "sign" : 1122983647,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalRelation",
          "toId" : 4,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Filter",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n+- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n   +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n      :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n      :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n      :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n      +- Project [d_date_sk#50, d_week_seq#54, d_day_name#64]\n         +- Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#371 [], xxhash64(d_week_seq#54, 42)))\n            :  +- Aggregate [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370]\n            :     +- Project [d_week_seq#261]\n            :        +- Filter ((isnotnull(d_month_seq#260) AND ((d_month_seq#260 >= 1185) AND (d_month_seq#260 <= 1196))) AND isnotnull(d_week_seq#261))\n            :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#257,d_date_id#258,d_date#259,d_month_seq#260,d_week_seq#261,d_quarter_seq#262,d_year#263,d_dow#264,d_moy#265,d_dom#266,d_qoy#267,d_fy_year#268,d_fy_quarter_seq#269,d_fy_week_seq#270,d_day_name#271,d_quarter_name#272,d_holiday#273,d_weekend#274,d_following_holiday#275,d_first_dom#276,d_last_dom#277,d_same_day_ly#278,d_same_day_lq#279,d_current_day#280,... 4 more fields] parquet\n            +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_date_id#51,d_date#52,d_month_seq#53,d_week_seq#54,d_quarter_seq#55,d_year#56,d_dow#57,d_moy#58,d_dom#59,d_qoy#60,d_fy_year#61,d_fy_quarter_seq#62,d_fy_week_seq#63,d_day_name#64,d_quarter_name#65,d_holiday#66,d_weekend#67,d_following_holiday#68,d_first_dom#69,d_last_dom#70,d_same_day_ly#71,d_same_day_lq#72,d_current_day#73,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : -1888766103,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [3]: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales/ss_sold_date_sk=2450816, ... 1822 entries] PartitionFilters: [isnotnull(ss_sold_date_sk#49)] PushedFilters: [IsNotNull(ss_store_sk)] ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)> "
          },
          "5" : {
            "sign" : 1418779716,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051544,
            "rowCount" : 371,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [3]: [d_date_sk#50, d_week_seq#54, d_day_name#64] Arguments: 0 "
          },
          "1" : {
            "sign" : 1875231536,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [4]: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] Input [6]: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49, d_date_sk#50, d_week_seq#54, d_day_name#64] "
          },
          "0" : {
            "sign" : -1172125718,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] Keys [2]: [d_week_seq#54, ss_store_sk#33] Functions [7]: [partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))] Aggregate Attributes [7]: [sum#377L, sum#378L, sum#379L, sum#380L, sum#381L, sum#382L, sum#383L] Results [9]: [d_week_seq#54, ss_store_sk#33, sum#384L, sum#385L, sum#386L, sum#387L, sum#388L, sum#389L, sum#390L] "
          },
          "2" : {
            "sign" : 1340945772,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_sold_date_sk#49] Right keys [1]: [d_date_sk#50] Join type: Inner Join condition: None "
          },
          "3" : {
            "sign" : -552795880,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] Condition : isnotnull(ss_store_sk#33) "
          }
        },
        "links" : [ {
          "fromId" : 4,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 3,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Filter",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "BroadcastQueryStage",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "BroadcastHashJoin",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sum#384L, sum#385L, sum#386L, sum#387L, sum#388L, sum#389L, sum#390L])\n+- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n   +- BroadcastHashJoin [ss_sold_date_sk#49], [d_date_sk#50], Inner, BuildRight, false\n      :- Filter isnotnull(ss_store_sk#33)\n      :  +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#33,ss_sales_price#39,ss_sold_date_sk#49] Batched: true, DataFilters: [isnotnull(ss_store_sk#33)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#49)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n      +- BroadcastQueryStage 0\n         +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=301]\n            +- *(1) Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#371, [id=#151], xxhash64(d_week_seq#54, 42)))\n               :  +- Subquery subquery#371, [id=#151]\n               :     +- AdaptiveSparkPlan isFinalPlan=true\n                        +- == Final Plan ==\n                           ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[bloomFilter#370])\n                           +- ShuffleQueryStage 0\n                              +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=477]\n                                 +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n                                    +- *(1) Project [d_week_seq#261]\n                                       +- *(1) Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n                                          +- *(1) ColumnarToRow\n                                             +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n                        +- == Initial Plan ==\n                           ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[bloomFilter#370])\n                           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=149]\n                              +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n                                 +- Project [d_week_seq#261]\n                                    +- Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n                                       +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n               +- *(1) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 6305216696,
        "inputRowCount" : 262673919
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 1,
        "FinishedTasksTotalTimeInMs" : 1176.0,
        "FinishedTasksDistributionInMs" : [ 1176.0, 1176.0, 1176.0, 1176.0, 1176.0 ]
      },
      "QueryStageOptimizationId" : 11,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 14 ],
      "Objectives" : {
        "DurationInMs" : 14452,
        "TotalTasksDurationInMs" : 48232,
        "IOBytes" : {
          "Total" : 688864676,
          "Details" : {
            "IR" : 686029586,
            "IW" : 0,
            "SR" : 0,
            "SW" : 2835090
          }
        }
      }
    },
    "9" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -1578268261,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 3876,
                "rowCount" : 323
              },
              "compileTime" : {
                "sizeInBytes" : 3876,
                "rowCount" : 323
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#318] "
          },
          "1" : {
            "sign" : -751660256,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 79458,
                "rowCount" : 323
              },
              "compileTime" : {
                "sizeInBytes" : 79458,
                "rowCount" : 323
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#317) AND ((d_month_seq#317 >= 1197) AND (d_month_seq#317 <= 1208))) AND isnotnull(d_week_seq#318)) "
          },
          "2" : {
            "sign" : -1395256588,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#314, d_date_id#315, d_date#316, d_month_seq#317, d_week_seq#318, d_quarter_seq#319, d_year#320, d_dow#321, d_moy#322, d_dom#323, d_qoy#324, d_fy_year#325, d_fy_quarter_seq#326, d_fy_week_seq#327, d_day_name#328, d_quarter_name#329, d_holiday#330, d_weekend#331, d_following_holiday#332, d_first_dom#333, d_last_dom#334, d_same_day_ly#335, d_same_day_lq#336, d_current_day#337, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_week_seq#318]\n+- Filter ((isnotnull(d_month_seq#317) AND ((d_month_seq#317 >= 1197) AND (d_month_seq#317 <= 1208))) AND isnotnull(d_week_seq#318))\n   +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#314,d_date_id#315,d_date#316,d_month_seq#317,d_week_seq#318,d_quarter_seq#319,d_year#320,d_dow#321,d_moy#322,d_dom#323,d_qoy#324,d_fy_year#325,d_fy_quarter_seq#326,d_fy_week_seq#327,d_day_name#328,d_quarter_name#329,d_holiday#330,d_weekend#331,d_following_holiday#332,d_first_dom#333,d_last_dom#334,d_same_day_ly#335,d_same_day_lq#336,d_current_day#337,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 607664433,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [d_week_seq#318] Input [2]: [d_month_seq#317, d_week_seq#318] "
          },
          "1" : {
            "sign" : 58288054,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [d_month_seq#317, d_week_seq#318] Condition : (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318)) "
          },
          "2" : {
            "sign" : 1629900554,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.date_dim Output [2]: [d_month_seq#317, d_week_seq#318] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim] PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208), IsNotNull(d_week_seq)] ReadSchema: struct<d_month_seq:int,d_week_seq:int> "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.date_dim",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_week_seq#318]\n+- Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n   +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 3876,
        "inputRowCount" : 323
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 5,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 12 ],
      "Objectives" : {
        "DurationInMs" : 123,
        "TotalTasksDurationInMs" : 119,
        "IOBytes" : {
          "Total" : 427122,
          "Details" : {
            "IR" : 427122,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "13" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 1651653671,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 59789632,
                "rowCount" : 533836
              },
              "compileTime" : {
                "sizeInBytes" : 59789632,
                "rowCount" : 533836
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] "
          },
          "1" : {
            "sign" : 1023264617,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 61924976,
                "rowCount" : 533836
              },
              "compileTime" : {
                "sizeInBytes" : 61924976,
                "rowCount" : 533836
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_week_seq#261 = d_week_seq#54) "
          },
          "2" : {
            "sign" : -684091520,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 64719540368,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 64719540368,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] "
          },
          "3" : {
            "sign" : -816376933,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 69342364680,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 69342364680,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (ss_store_sk#33 = s_store_sk#78) "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Project",
          "toId" : 1,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Join",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n+- Join Inner, (d_week_seq#261 = d_week_seq#54)\n   :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n   :  +- Join Inner, (ss_store_sk#33 = s_store_sk#78)\n   :     :- Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n   :     :  +- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n   :     :     +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n   :     :        :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n   :     :        :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n   :     :        :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n   :     :        +- Project [d_date_sk#50, d_week_seq#54, d_day_name#64]\n   :     :           +- Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#371 [], xxhash64(d_week_seq#54, 42)))\n   :     :              :  +- Aggregate [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370]\n   :     :              :     +- Project [d_week_seq#261]\n   :     :              :        +- Filter ((isnotnull(d_month_seq#260) AND ((d_month_seq#260 >= 1185) AND (d_month_seq#260 <= 1196))) AND isnotnull(d_week_seq#261))\n   :     :              :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#257,d_date_id#258,d_date#259,d_month_seq#260,d_week_seq#261,d_quarter_seq#262,d_year#263,d_dow#264,d_moy#265,d_dom#266,d_qoy#267,d_fy_year#268,d_fy_quarter_seq#269,d_fy_week_seq#270,d_day_name#271,d_quarter_name#272,d_holiday#273,d_weekend#274,d_following_holiday#275,d_first_dom#276,d_last_dom#277,d_same_day_ly#278,d_same_day_lq#279,d_current_day#280,... 4 more fields] parquet\n   :     :              +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_date_id#51,d_date#52,d_month_seq#53,d_week_seq#54,d_quarter_seq#55,d_year#56,d_dow#57,d_moy#58,d_dom#59,d_qoy#60,d_fy_year#61,d_fy_quarter_seq#62,d_fy_week_seq#63,d_day_name#64,d_quarter_name#65,d_holiday#66,d_weekend#67,d_following_holiday#68,d_first_dom#69,d_last_dom#70,d_same_day_ly#71,d_same_day_lq#72,d_current_day#73,... 4 more fields] parquet\n   :     +- Project [s_store_sk#78, s_store_id#79, s_store_name#83]\n   :        +- Filter (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79))\n   :           +- Relation spark_catalog.tpcds_100.store[s_store_sk#78,s_store_id#79,s_rec_start_date#80,s_rec_end_date#81,s_closed_date_sk#82,s_store_name#83,s_number_employees#84,s_floor_space#85,s_hours#86,s_manager#87,s_market_id#88,s_geography_class#89,s_market_desc#90,s_market_manager#91,s_division_id#92,s_division_name#93,s_company_id#94,s_company_name#95,s_street_number#96,s_street_name#97,s_street_type#98,s_suite_number#99,s_city#100,s_county#101,... 5 more fields] parquet\n   +- Project [d_week_seq#261]\n      +- Filter ((isnotnull(d_month_seq#260) AND ((d_month_seq#260 >= 1185) AND (d_month_seq#260 <= 1196))) AND isnotnull(d_week_seq#261))\n         +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#257,d_date_id#258,d_date#259,d_month_seq#260,d_week_seq#261,d_quarter_seq#262,d_year#263,d_dow#264,d_moy#265,d_dom#266,d_qoy#267,d_fy_year#268,d_fy_quarter_seq#269,d_fy_week_seq#270,d_day_name#271,d_quarter_name#272,d_holiday#273,d_weekend#274,d_following_holiday#275,d_first_dom#276,d_last_dom#277,d_same_day_ly#278,d_same_day_lq#279,d_current_day#280,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : -842427274,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 5579760,
            "rowCount" : 69747,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [9]: [d_week_seq#54, ss_store_sk#33, sum#384L, sum#385L, sum#386L, sum#387L, sum#388L, sum#389L, sum#390L] Keys [2]: [d_week_seq#54, ss_store_sk#33] Functions [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))] Aggregate Attributes [7]: [sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END))#342L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END))#343L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END))#344L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END))#345L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END))#346L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END))#347L, sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))#348L] Results [9]: [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END))#342L,17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END))#343L,17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END))#344L,17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END))#345L,17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END))#346L,17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END))#347L,17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))#348L,17,2) AS sat_sales#256] "
          },
          "5" : {
            "sign" : -1974486577,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [9]: [d_week_seq#54, ss_store_sk#33, sum#384L, sum#385L, sum#386L, sum#387L, sum#388L, sum#389L, sum#390L] Arguments: 7 "
          },
          "6" : {
            "sign" : -1523288813,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [3]: [s_store_sk#78, s_store_id#79, s_store_name#83] Arguments: 1 "
          },
          "1" : {
            "sign" : 1705397870,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 61924976,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [d_week_seq#54] Right keys [1]: [d_week_seq#261] Join type: Inner Join condition: None "
          },
          "0" : {
            "sign" : 321078170,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 59789632,
            "rowCount" : 533836,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [10]: [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239] Input [11]: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83, d_week_seq#261] "
          },
          "2" : {
            "sign" : 2086736703,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 64719540368,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [10]: [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83] Input [12]: [d_week_seq#54, ss_store_sk#33, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_sk#78, s_store_id#79, s_store_name#83] "
          },
          "7" : {
            "sign" : 504626532,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1049000,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [1]: [d_week_seq#261] Arguments: 2 "
          },
          "3" : {
            "sign" : 1469939340,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 69342364680,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_store_sk#33] Right keys [1]: [s_store_sk#78] Join type: Inner Join condition: None "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "ShuffleQueryStage",
          "toId" : 4,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "HashAggregate",
          "toId" : 3,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "BroadcastQueryStage",
          "toId" : 3,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "BroadcastHashJoin",
          "toId" : 2,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Project",
          "toId" : 1,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "BroadcastQueryStage",
          "toId" : 1,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "BroadcastHashJoin",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_store_name#83 AS s_store_name1#230, d_week_seq#54 AS d_week_seq1#231, s_store_id#79 AS s_store_id1#232, sun_sales#250 AS sun_sales1#233, mon_sales#251 AS mon_sales1#234, tue_sales#252 AS tue_sales1#235, wed_sales#253 AS wed_sales1#236, thu_sales#254 AS thu_sales1#237, fri_sales#255 AS fri_sales1#238, sat_sales#256 AS sat_sales1#239]\n+- BroadcastHashJoin [d_week_seq#54], [d_week_seq#261], Inner, BuildRight, false\n   :- Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#79, s_store_name#83]\n   :  +- BroadcastHashJoin [ss_store_sk#33], [s_store_sk#78], Inner, BuildRight, false\n   :     :- HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256])\n   :     :  +- ShuffleQueryStage 7\n   :     :     +- Exchange hashpartitioning(d_week_seq#54, ss_store_sk#33, 200), ENSURE_REQUIREMENTS, [plan_id=1274]\n   :     :        +- *(8) HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sum#384L, sum#385L, sum#386L, sum#387L, sum#388L, sum#389L, sum#390L])\n   :     :           +- *(8) Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n   :     :              +- *(8) BroadcastHashJoin [ss_sold_date_sk#49], [d_date_sk#50], Inner, BuildRight, false\n   :     :                 :- *(8) Filter isnotnull(ss_store_sk#33)\n   :     :                 :  +- *(8) ColumnarToRow\n   :     :                 :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#33,ss_sales_price#39,ss_sold_date_sk#49] Batched: true, DataFilters: [isnotnull(ss_store_sk#33)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#49)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n   :     :                 +- BroadcastQueryStage 0\n   :     :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=301]\n   :     :                       +- *(1) Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#371, [id=#151], xxhash64(d_week_seq#54, 42)))\n   :     :                          :  +- Subquery subquery#371, [id=#151]\n   :     :                          :     +- AdaptiveSparkPlan isFinalPlan=true\n                                             +- == Final Plan ==\n                                                ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[bloomFilter#370])\n                                                +- ShuffleQueryStage 0\n                                                   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=477]\n                                                      +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n                                                         +- *(1) Project [d_week_seq#261]\n                                                            +- *(1) Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n                                                               +- *(1) ColumnarToRow\n                                                                  +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n                                             +- == Initial Plan ==\n                                                ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[bloomFilter#370])\n                                                +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=149]\n                                                   +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n                                                      +- Project [d_week_seq#261]\n                                                         +- Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n                                                            +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n   :     :                          +- *(1) ColumnarToRow\n   :     :                             +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n   :     +- BroadcastQueryStage 1\n   :        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=321]\n   :           +- *(2) Filter (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79))\n   :              +- *(2) ColumnarToRow\n   :                 +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#78,s_store_id#79,s_store_name#83] Batched: true, DataFilters: [isnotnull(s_store_sk#78), isnotnull(s_store_id#79)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string>\n   +- BroadcastQueryStage 2\n      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=340]\n         +- *(3) Project [d_week_seq#261]\n            +- *(3) Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n               +- *(3) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 7680552,
        "inputRowCount" : 70514
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "3" : [ 11839, 16206, 14855, 15326, 14489, 14562, 16522, 15683, 15699, 14122, 17075, 16523, 16487, 14747, 15066, 15142, 16590, 16522, 14422, 16132, 15859, 13238, 14520, 15815, 14702, 14726, 14840, 14515, 15961, 13357, 14343, 12984, 12563, 15545, 12516, 13968, 16377, 14417, 11170, 14157, 16953, 15440, 14307, 12544, 14713, 13049, 14348, 14227, 13913, 14346, 16685, 14449, 15421, 15946, 15553, 13069, 14121, 14625, 16817, 15258, 14515, 15951, 15739, 16841, 14194, 14266, 14303, 15121, 15091, 13353, 12347, 15492, 15218, 14449, 14991, 14666, 15669, 16006, 16987, 13315, 16832, 16649, 14607, 15240, 12446, 13613, 13879, 14925, 15155, 14388, 14416, 15569, 13577, 14657, 14131, 15289, 12894, 13848, 14524, 15201, 13901, 12189, 14792, 16141, 15496, 12420, 12950, 16256, 15399, 15507, 13854, 13265, 17476, 14227, 15054, 15164, 14332, 13849, 16198, 14406, 14138, 16358, 14457, 16251, 16023, 14365, 12472, 15171, 14317, 16025, 15696, 14356, 16098, 15491, 16507, 13543, 16711, 17604, 16274, 14163, 15823, 13626, 14234, 14627, 13748, 14171, 12709, 14172, 13473, 15164, 16670, 14829, 15405, 14787, 13878, 17473, 15725, 14786, 13888, 12729, 15121, 15437, 15113, 12973, 12109, 14139, 14104, 15694, 13978, 14827, 16963, 12754, 16025, 16291, 13912, 15454, 15696, 14479, 16798, 15108, 14031, 16075, 15389, 15316, 14695, 13622, 15433, 14818, 12439, 13430, 15614, 15170, 14165, 14398, 15298, 14939, 13468, 14423, 14988, 16139 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 13,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 18 ],
      "Objectives" : {
        "DurationInMs" : 472,
        "TotalTasksDurationInMs" : 463,
        "IOBytes" : {
          "Total" : 3520298,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 2835090,
            "SW" : 685208
          }
        }
      }
    },
    "5" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 898084925,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 108,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 108,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373] "
          }
        },
        "links" : [ ],
        "rawPlan" : "Aggregate [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373]\n+- Project [d_week_seq#318]\n   +- Filter ((isnotnull(d_month_seq#317) AND ((d_month_seq#317 >= 1197) AND (d_month_seq#317 <= 1208))) AND isnotnull(d_week_seq#318))\n      +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#314,d_date_id#315,d_date#316,d_month_seq#317,d_week_seq#318,d_quarter_seq#319,d_year#320,d_dow#321,d_moy#322,d_dom#323,d_qoy#324,d_fy_year#325,d_fy_quarter_seq#326,d_fy_week_seq#327,d_day_name#328,d_quarter_name#329,d_holiday#330,d_weekend#331,d_following_holiday#332,d_first_dom#333,d_last_dom#334,d_same_day_ly#335,d_same_day_lq#336,d_current_day#337,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 1387096577,
            "className" : "org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec",
            "sizeInBytes" : 108,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ObjectHashAggregate Input [1]: [d_week_seq#318] Keys: [] Functions [1]: [partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)] Aggregate Attributes [1]: [buf#375] Results [1]: [buf#406] "
          },
          "1" : {
            "sign" : 607664433,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [d_week_seq#318] Input [2]: [d_month_seq#317, d_week_seq#318] "
          },
          "2" : {
            "sign" : 58288054,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [d_month_seq#317, d_week_seq#318] Condition : (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318)) "
          },
          "3" : {
            "sign" : 1629900554,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 3876,
            "rowCount" : 323,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.date_dim Output [2]: [d_month_seq#317, d_week_seq#318] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim] PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208), IsNotNull(d_week_seq)] ReadSchema: struct<d_month_seq:int,d_week_seq:int> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.date_dim",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "ObjectHashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n+- Project [d_week_seq#318]\n   +- Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n      +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 3876,
        "inputRowCount" : 323
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 7,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 5 ],
      "Objectives" : {
        "DurationInMs" : 1569,
        "TotalTasksDurationInMs" : 1563,
        "IOBytes" : {
          "Total" : 102233,
          "Details" : {
            "IR" : 102233,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "10" : {
      "QSLogical" : {
        "operators" : {
          "4" : {
            "sign" : 678988587,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33)) "
          },
          "5" : {
            "sign" : 122295656,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              },
              "compileTime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#27, ss_item_sk#28, ss_customer_sk#29, ss_cdemo_sk#30, ss_hdemo_sk#31, ss_addr_sk#32, ss_store_sk#33, ss_promo_sk#34, ss_ticket_number#35L, ss_quantity#36, ss_wholesale_cost#37, ss_list_price#38, ss_sales_price#39, ss_ext_discount_amt#40, ss_ext_sales_price#41, ss_ext_wholesale_cost#42, ss_ext_list_price#43, ss_ext_tax#44, ss_coupon_amt#45, ss_net_paid#46, ss_net_paid_inc_tax#47, ss_net_profit#48, ss_sold_date_sk#49], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "1" : {
            "sign" : 1964209704,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 11683785740,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 11683785740,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] "
          },
          "0" : {
            "sign" : -622158321,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 131891760,
                "rowCount" : 1831830
              },
              "compileTime" : {
                "sizeInBytes" : 131891760,
                "rowCount" : 1831830
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256] "
          },
          "2" : {
            "sign" : 391727048,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 13808110420,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 13808110420,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#50 = ss_sold_date_sk#49) "
          },
          "3" : {
            "sign" : 1122983647,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalRelation",
          "toId" : 4,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Filter",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [d_week_seq#54, ss_store_sk#33], [d_week_seq#54, ss_store_sk#33, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)),17,2) AS sun_sales#250, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)),17,2) AS mon_sales#251, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)),17,2) AS tue_sales#252, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)),17,2) AS wed_sales#253, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)),17,2) AS thu_sales#254, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)),17,2) AS fri_sales#255, MakeDecimal(sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END)),17,2) AS sat_sales#256]\n+- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n   +- Join Inner, (d_date_sk#50 = ss_sold_date_sk#49)\n      :- Project [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49]\n      :  +- Filter (isnotnull(ss_sold_date_sk#49) AND isnotnull(ss_store_sk#33))\n      :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#27,ss_item_sk#28,ss_customer_sk#29,ss_cdemo_sk#30,ss_hdemo_sk#31,ss_addr_sk#32,ss_store_sk#33,ss_promo_sk#34,ss_ticket_number#35L,ss_quantity#36,ss_wholesale_cost#37,ss_list_price#38,ss_sales_price#39,ss_ext_discount_amt#40,ss_ext_sales_price#41,ss_ext_wholesale_cost#42,ss_ext_list_price#43,ss_ext_tax#44,ss_coupon_amt#45,ss_net_paid#46,ss_net_paid_inc_tax#47,ss_net_profit#48,ss_sold_date_sk#49] parquet\n      +- Project [d_date_sk#50, d_week_seq#54, d_day_name#64]\n         +- Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#374 [], xxhash64(d_week_seq#54, 42)))\n            :  +- Aggregate [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373]\n            :     +- Project [d_week_seq#318]\n            :        +- Filter ((isnotnull(d_month_seq#317) AND ((d_month_seq#317 >= 1197) AND (d_month_seq#317 <= 1208))) AND isnotnull(d_week_seq#318))\n            :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#314,d_date_id#315,d_date#316,d_month_seq#317,d_week_seq#318,d_quarter_seq#319,d_year#320,d_dow#321,d_moy#322,d_dom#323,d_qoy#324,d_fy_year#325,d_fy_quarter_seq#326,d_fy_week_seq#327,d_day_name#328,d_quarter_name#329,d_holiday#330,d_weekend#331,d_following_holiday#332,d_first_dom#333,d_last_dom#334,d_same_day_ly#335,d_same_day_lq#336,d_current_day#337,... 4 more fields] parquet\n            +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_date_id#51,d_date#52,d_month_seq#53,d_week_seq#54,d_quarter_seq#55,d_year#56,d_dow#57,d_moy#58,d_dom#59,d_qoy#60,d_fy_year#61,d_fy_quarter_seq#62,d_fy_week_seq#63,d_day_name#64,d_quarter_name#65,d_holiday#66,d_weekend#67,d_following_holiday#68,d_first_dom#69,d_last_dom#70,d_same_day_ly#71,d_same_day_lq#72,d_current_day#73,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : -1888766103,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [3]: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales/ss_sold_date_sk=2450816, ... 1822 entries] PartitionFilters: [isnotnull(ss_sold_date_sk#49)] PushedFilters: [IsNotNull(ss_store_sk)] ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)> "
          },
          "5" : {
            "sign" : -972927850,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051544,
            "rowCount" : 371,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [3]: [d_date_sk#50, d_week_seq#54, d_day_name#64] Arguments: 3 "
          },
          "1" : {
            "sign" : 1239941250,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 11683785740,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [4]: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] Input [6]: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49, d_date_sk#50, d_week_seq#54, d_day_name#64] "
          },
          "0" : {
            "sign" : 1311878016,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 131891760,
            "rowCount" : 1831830,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64] Keys [2]: [d_week_seq#54, ss_store_sk#33] Functions [7]: [partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))] Aggregate Attributes [7]: [sum#391L, sum#392L, sum#393L, sum#394L, sum#395L, sum#396L, sum#397L] Results [9]: [d_week_seq#54, ss_store_sk#33, sum#398L, sum#399L, sum#400L, sum#401L, sum#402L, sum#403L, sum#404L] "
          },
          "2" : {
            "sign" : -1755464254,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 13808110420,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_sold_date_sk#49] Right keys [1]: [d_date_sk#50] Join type: Inner Join condition: None "
          },
          "3" : {
            "sign" : -552795880,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [ss_store_sk#33, ss_sales_price#39, ss_sold_date_sk#49] Condition : isnotnull(ss_store_sk#33) "
          }
        },
        "links" : [ {
          "fromId" : 4,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 3,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Filter",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "BroadcastQueryStage",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "BroadcastHashJoin",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sum#398L, sum#399L, sum#400L, sum#401L, sum#402L, sum#403L, sum#404L])\n+- Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n   +- BroadcastHashJoin [ss_sold_date_sk#49], [d_date_sk#50], Inner, BuildRight, false\n      :- Filter isnotnull(ss_store_sk#33)\n      :  +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#33,ss_sales_price#39,ss_sold_date_sk#49] Batched: true, DataFilters: [isnotnull(ss_store_sk#33)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#49)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n      +- BroadcastQueryStage 3\n         +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=408]\n            +- *(4) Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#374, [id=#164], xxhash64(d_week_seq#54, 42)))\n               :  +- Subquery subquery#374, [id=#164]\n               :     +- AdaptiveSparkPlan isFinalPlan=true\n                        +- == Final Plan ==\n                           ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n                           +- ShuffleQueryStage 0\n                              +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=497]\n                                 +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n                                    +- *(1) Project [d_week_seq#318]\n                                       +- *(1) Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                          +- *(1) ColumnarToRow\n                                             +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n                        +- == Initial Plan ==\n                           ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n                           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=162]\n                              +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n                                 +- Project [d_week_seq#318]\n                                    +- Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                       +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n               +- *(4) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 6305216696,
        "inputRowCount" : 262673919
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 10,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 13 ],
      "Objectives" : {
        "DurationInMs" : 12939,
        "TotalTasksDurationInMs" : 202078,
        "IOBytes" : {
          "Total" : 688819544,
          "Details" : {
            "IR" : 686029586,
            "IW" : 0,
            "SR" : 0,
            "SW" : 2789958
          }
        }
      }
    },
    "6" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 537328781,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 1120,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 108,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373], ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373], ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 2020838591,
            "className" : "org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec",
            "sizeInBytes" : 1120,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) ObjectHashAggregate Input [1]: [buf#406] Keys: [] Functions [1]: [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)] Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)#372] Results [1]: [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)#372 AS bloomFilter#373] "
          },
          "1" : {
            "sign" : -695276858,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 108,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [1]: [buf#406] Arguments: 0 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "ShuffleQueryStage",
          "toId" : 0,
          "toName" : "ObjectHashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n+- ShuffleQueryStage 0\n   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=497]\n      +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n         +- *(1) Project [d_week_seq#318]\n            +- *(1) Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n               +- *(1) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 1120,
        "inputRowCount" : 1
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "1" : [ 1156 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 9,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 10 ],
      "Objectives" : {
        "DurationInMs" : 820,
        "TotalTasksDurationInMs" : 799,
        "IOBytes" : {
          "Total" : 1094,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1094,
            "SW" : 0
          }
        }
      }
    },
    "1" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 682973872,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 1160,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 108,
                "rowCount" : 1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370], ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370], ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1571207750,
            "className" : "org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec",
            "sizeInBytes" : 1160,
            "rowCount" : 1,
            "isRuntime" : true,
            "predicate" : " (unknown) ObjectHashAggregate Input [1]: [buf#405] Keys: [] Functions [1]: [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)] Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)#369] Results [1]: [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)#369 AS bloomFilter#370] "
          },
          "1" : {
            "sign" : -918620774,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 108,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [1]: [buf#405] Arguments: 0 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "ShuffleQueryStage",
          "toId" : 0,
          "toName" : "ObjectHashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[bloomFilter#370])\n+- ShuffleQueryStage 0\n   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=477]\n      +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n         +- *(1) Project [d_week_seq#261]\n            +- *(1) Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n               +- *(1) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 1160,
        "inputRowCount" : 1
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "0" : [ 1156 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 8,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 8 ],
      "Objectives" : {
        "DurationInMs" : 241,
        "TotalTasksDurationInMs" : 203,
        "IOBytes" : {
          "Total" : 1136,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1136,
            "SW" : 0
          }
        }
      }
    },
    "14" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -1645591697,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 7062336,
                "rowCount" : 73566
              },
              "compileTime" : {
                "sizeInBytes" : 51248256,
                "rowCount" : 533836
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8 "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249], ShuffleQueryStage 8\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 2138249806,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 7062336,
            "rowCount" : 73566,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [9]: [d_week_seq2#241, s_store_id2#242, sun_sales2#243, mon_sales2#244, tue_sales2#245, wed_sales2#246, thu_sales2#247, fri_sales2#248, sat_sales2#249] Arguments: 8 "
          }
        },
        "links" : [ ],
        "rawPlan" : "ShuffleQueryStage 8\n+- Exchange hashpartitioning(s_store_id2#242, (d_week_seq2#241 - 52), 200), ENSURE_REQUIREMENTS, [plan_id=1391]\n   +- *(9) Project [d_week_seq#54 AS d_week_seq2#241, s_store_id#286 AS s_store_id2#242, sun_sales#250 AS sun_sales2#243, mon_sales#251 AS mon_sales2#244, tue_sales#252 AS tue_sales2#245, wed_sales#253 AS wed_sales2#246, thu_sales#254 AS thu_sales2#247, fri_sales#255 AS fri_sales2#248, sat_sales#256 AS sat_sales2#249]\n      +- *(9) BroadcastHashJoin [d_week_seq#54], [d_week_seq#318], Inner, BuildRight, false\n         :- *(9) Project [d_week_seq#54, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256, s_store_id#286]\n         :  +- *(9) BroadcastHashJoin [ss_store_sk#33], [s_store_sk#285], Inner, BuildRight, false\n         :     :- *(9) HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sun_sales#250, mon_sales#251, tue_sales#252, wed_sales#253, thu_sales#254, fri_sales#255, sat_sales#256])\n         :     :  +- AQEShuffleRead coalesced\n         :     :     +- ShuffleQueryStage 6\n         :     :        +- Exchange hashpartitioning(d_week_seq#54, ss_store_sk#33, 200), ENSURE_REQUIREMENTS, [plan_id=1149]\n         :     :           +- *(7) HashAggregate(keys=[d_week_seq#54, ss_store_sk#33], functions=[partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Sunday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Monday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Tuesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Wednesday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Thursday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Friday) THEN ss_sales_price#39 END)), partial_sum(UnscaledValue(CASE WHEN (d_day_name#64 = Saturday) THEN ss_sales_price#39 END))], output=[d_week_seq#54, ss_store_sk#33, sum#398L, sum#399L, sum#400L, sum#401L, sum#402L, sum#403L, sum#404L])\n         :     :              +- *(7) Project [ss_store_sk#33, ss_sales_price#39, d_week_seq#54, d_day_name#64]\n         :     :                 +- *(7) BroadcastHashJoin [ss_sold_date_sk#49], [d_date_sk#50], Inner, BuildRight, false\n         :     :                    :- *(7) Filter isnotnull(ss_store_sk#33)\n         :     :                    :  +- *(7) ColumnarToRow\n         :     :                    :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#33,ss_sales_price#39,ss_sold_date_sk#49] Batched: true, DataFilters: [isnotnull(ss_store_sk#33)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#49)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_sales_price:decimal(7,2)>\n         :     :                    +- BroadcastQueryStage 3\n         :     :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=408]\n         :     :                          +- *(4) Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#374, [id=#164], xxhash64(d_week_seq#54, 42)))\n         :     :                             :  +- Subquery subquery#374, [id=#164]\n         :     :                             :     +- AdaptiveSparkPlan isFinalPlan=true\n                                                      +- == Final Plan ==\n                                                         ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n                                                         +- ShuffleQueryStage 0\n                                                            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=497]\n                                                               +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n                                                                  +- *(1) Project [d_week_seq#318]\n                                                                     +- *(1) Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                                                        +- *(1) ColumnarToRow\n                                                                           +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n                                                      +- == Initial Plan ==\n                                                         ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n                                                         +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=162]\n                                                            +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n                                                               +- Project [d_week_seq#318]\n                                                                  +- Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                                                                     +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n         :     :                             +- *(4) ColumnarToRow\n         :     :                                +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n         :     +- BroadcastQueryStage 4\n         :        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=428]\n         :           +- *(5) Filter (isnotnull(s_store_sk#285) AND isnotnull(s_store_id#286))\n         :              +- *(5) ColumnarToRow\n         :                 +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#285,s_store_id#286] Batched: true, DataFilters: [isnotnull(s_store_sk#285), isnotnull(s_store_id#286)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string>\n         +- BroadcastQueryStage 5\n            +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=447]\n               +- *(6) Project [d_week_seq#318]\n                  +- *(6) Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n                     +- *(6) ColumnarToRow\n                        +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 7062336,
        "inputRowCount" : 73566
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "4" : [ 2478, 2999, 3991, 3628, 3628, 3628, 2999, 3628, 2726, 3298, 2253, 2999, 4390, 2726, 2726, 3298, 2999, 3628, 2726, 2726, 3298, 2726, 3628, 2999, 3628, 3298, 3991, 2999, 3298, 3298, 3298, 3628, 3298, 3628, 3298, 3628, 3298, 3628, 3298, 3991, 3991, 2726, 4390, 3298, 4830, 2999, 2726, 3628, 3298, 3628, 3298, 3628, 3298, 3991, 3628, 2726, 2726, 3298, 3991, 4390, 3628, 2726, 1862, 3298, 3298, 4390, 2726, 3991, 2999, 3298, 4390, 3298, 3298, 2999, 3298, 3298, 2999, 3991, 2999, 3628, 2726, 2048, 3991, 3991, 3628, 2478, 3991, 3628, 3991, 4390, 3298, 3628, 2999, 3628, 3628, 3628, 2478, 2999, 2726, 3298, 3628, 3628, 2726, 3628, 4390, 3298, 3298, 2999, 3298, 3298, 3628, 3628, 3298, 3298, 3628, 3628, 3628, 3628, 3298, 2726, 2726, 2999, 2478, 3298, 3628, 3298, 3628, 3298, 2999, 3298, 3991, 3298, 2478, 3628, 2478, 4390, 3298, 3991, 3628, 3628, 2999, 3628, 2999, 3628, 3298, 3628, 3628, 2999, 3298, 3628, 3298, 2726, 2726, 3991, 3298, 2999, 3628, 3991, 2726, 3298, 3991, 3628, 3298, 3628, 3628, 3298, 4390, 2478, 3298, 2726, 2726, 2999, 3298, 3628, 3991, 3298, 4390, 2726, 3991, 3628, 3628, 2726, 3628, 3991, 3991, 3298, 3628, 2999, 2726, 3298, 3298, 4390, 3991, 2478, 3628, 3628, 4830, 3298, 2726, 2999 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 14,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 21 ],
      "Objectives" : {
        "DurationInMs" : 89,
        "TotalTasksDurationInMs" : 86,
        "IOBytes" : {
          "Total" : 644974,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 644974,
            "SW" : 0
          }
        }
      }
    },
    "0" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 764912757,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 108,
                "rowCount" : 1
              },
              "compileTime" : {
                "sizeInBytes" : 108,
                "rowCount" : 1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370] "
          }
        },
        "links" : [ ],
        "rawPlan" : "Aggregate [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370]\n+- Project [d_week_seq#261]\n   +- Filter ((isnotnull(d_month_seq#260) AND ((d_month_seq#260 >= 1185) AND (d_month_seq#260 <= 1196))) AND isnotnull(d_week_seq#261))\n      +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#257,d_date_id#258,d_date#259,d_month_seq#260,d_week_seq#261,d_quarter_seq#262,d_year#263,d_dow#264,d_moy#265,d_dom#266,d_qoy#267,d_fy_year#268,d_fy_quarter_seq#269,d_fy_week_seq#270,d_day_name#271,d_quarter_name#272,d_holiday#273,d_weekend#274,d_following_holiday#275,d_first_dom#276,d_last_dom#277,d_same_day_ly#278,d_same_day_lq#279,d_current_day#280,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 836953091,
            "className" : "org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec",
            "sizeInBytes" : 108,
            "rowCount" : 1,
            "isRuntime" : false,
            "predicate" : " (unknown) ObjectHashAggregate Input [1]: [d_week_seq#261] Keys: [] Functions [1]: [partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)] Aggregate Attributes [1]: [buf#376] Results [1]: [buf#405] "
          },
          "1" : {
            "sign" : 852723274,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [d_week_seq#261] Input [2]: [d_month_seq#260, d_week_seq#261] "
          },
          "2" : {
            "sign" : 1911566212,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [d_month_seq#260, d_week_seq#261] Condition : (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261)) "
          },
          "3" : {
            "sign" : -652324793,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.date_dim Output [2]: [d_month_seq#260, d_week_seq#261] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim] PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196), IsNotNull(d_week_seq)] ReadSchema: struct<d_month_seq:int,d_week_seq:int> "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.date_dim",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "ObjectHashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n+- Project [d_week_seq#261]\n   +- Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n      +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 4032,
        "inputRowCount" : 336
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 6,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 1 ],
      "Objectives" : {
        "DurationInMs" : 1929,
        "TotalTasksDurationInMs" : 1862,
        "IOBytes" : {
          "Total" : 103369,
          "Details" : {
            "IR" : 102233,
            "IW" : 0,
            "SR" : 0,
            "SW" : 1136
          }
        }
      }
    },
    "2" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -927322180,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 2629764,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 2629764,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#50, d_week_seq#54, d_day_name#64] "
          },
          "1" : {
            "sign" : -1845496428,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#371 [], xxhash64(d_week_seq#54, 42))) "
          },
          "2" : {
            "sign" : 1727324964,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#50, d_date_id#51, d_date#52, d_month_seq#53, d_week_seq#54, d_quarter_seq#55, d_year#56, d_dow#57, d_moy#58, d_dom#59, d_qoy#60, d_fy_year#61, d_fy_quarter_seq#62, d_fy_week_seq#63, d_day_name#64, d_quarter_name#65, d_holiday#66, d_weekend#67, d_following_holiday#68, d_first_dom#69, d_last_dom#70, d_same_day_ly#71, d_same_day_lq#72, d_current_day#73, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_date_sk#50, d_week_seq#54, d_day_name#64]\n+- Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#371 [], xxhash64(d_week_seq#54, 42)))\n   :  +- Aggregate [bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0) AS bloomFilter#370]\n   :     +- Project [d_week_seq#261]\n   :        +- Filter ((isnotnull(d_month_seq#260) AND ((d_month_seq#260 >= 1185) AND (d_month_seq#260 <= 1196))) AND isnotnull(d_week_seq#261))\n   :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#257,d_date_id#258,d_date#259,d_month_seq#260,d_week_seq#261,d_quarter_seq#262,d_year#263,d_dow#264,d_moy#265,d_dom#266,d_qoy#267,d_fy_year#268,d_fy_quarter_seq#269,d_fy_week_seq#270,d_day_name#271,d_quarter_name#272,d_holiday#273,d_weekend#274,d_following_holiday#275,d_first_dom#276,d_last_dom#277,d_same_day_ly#278,d_same_day_lq#279,d_current_day#280,... 4 more fields] parquet\n   +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_date_id#51,d_date#52,d_month_seq#53,d_week_seq#54,d_quarter_seq#55,d_year#56,d_dow#57,d_moy#58,d_dom#59,d_qoy#60,d_fy_year#61,d_fy_quarter_seq#62,d_fy_week_seq#63,d_day_name#64,d_quarter_name#65,d_holiday#66,d_weekend#67,d_following_holiday#68,d_first_dom#69,d_last_dom#70,d_same_day_ly#71,d_same_day_lq#72,d_current_day#73,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 1208697813,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [d_date_sk#50, d_week_seq#54, d_day_name#64] Condition : ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#371, [id=#151], xxhash64(d_week_seq#54, 42))) "
          },
          "1" : {
            "sign" : -1380665859,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.date_dim Output [3]: [d_date_sk#50, d_week_seq#54, d_day_name#64] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim] PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)] ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string> "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.date_dim",
          "toId" : 0,
          "toName" : "Filter",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#371, [id=#151], xxhash64(d_week_seq#54, 42)))\n:  +- Subquery subquery#371, [id=#151]\n:     +- AdaptiveSparkPlan isFinalPlan=false\n:        +- ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[bloomFilter#370])\n:           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=149]\n:              +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#261, 42), 336, 9015, 0, 0)], output=[buf#405])\n:                 +- Project [d_week_seq#261]\n:                    +- Filter (((isnotnull(d_month_seq#260) AND (d_month_seq#260 >= 1185)) AND (d_month_seq#260 <= 1196)) AND isnotnull(d_week_seq#261))\n:                       +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#260,d_week_seq#261] Batched: true, DataFilters: [isnotnull(d_month_seq#260), (d_month_seq#260 >= 1185), (d_month_seq#260 <= 1196), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1185), LessThanOrEqual(d_month_seq,1196),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n+- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 2629764,
        "inputRowCount" : 73049
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 0,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 2 ],
      "Objectives" : {
        "DurationInMs" : 1900,
        "TotalTasksDurationInMs" : 1859,
        "IOBytes" : {
          "Total" : 103327,
          "Details" : {
            "IR" : 102233,
            "IW" : 0,
            "SR" : 0,
            "SW" : 1094
          }
        }
      }
    },
    "7" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 331680617,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 2629764,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 2629764,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#50, d_week_seq#54, d_day_name#64] "
          },
          "1" : {
            "sign" : 488610575,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#374 [], xxhash64(d_week_seq#54, 42))) "
          },
          "2" : {
            "sign" : 1727324964,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#50, d_date_id#51, d_date#52, d_month_seq#53, d_week_seq#54, d_quarter_seq#55, d_year#56, d_dow#57, d_moy#58, d_dom#59, d_qoy#60, d_fy_year#61, d_fy_quarter_seq#62, d_fy_week_seq#63, d_day_name#64, d_quarter_name#65, d_holiday#66, d_weekend#67, d_following_holiday#68, d_first_dom#69, d_last_dom#70, d_same_day_ly#71, d_same_day_lq#72, d_current_day#73, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_date_sk#50, d_week_seq#54, d_day_name#64]\n+- Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(scalar-subquery#374 [], xxhash64(d_week_seq#54, 42)))\n   :  +- Aggregate [bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0) AS bloomFilter#373]\n   :     +- Project [d_week_seq#318]\n   :        +- Filter ((isnotnull(d_month_seq#317) AND ((d_month_seq#317 >= 1197) AND (d_month_seq#317 <= 1208))) AND isnotnull(d_week_seq#318))\n   :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#314,d_date_id#315,d_date#316,d_month_seq#317,d_week_seq#318,d_quarter_seq#319,d_year#320,d_dow#321,d_moy#322,d_dom#323,d_qoy#324,d_fy_year#325,d_fy_quarter_seq#326,d_fy_week_seq#327,d_day_name#328,d_quarter_name#329,d_holiday#330,d_weekend#331,d_following_holiday#332,d_first_dom#333,d_last_dom#334,d_same_day_ly#335,d_same_day_lq#336,d_current_day#337,... 4 more fields] parquet\n   +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_date_id#51,d_date#52,d_month_seq#53,d_week_seq#54,d_quarter_seq#55,d_year#56,d_dow#57,d_moy#58,d_dom#59,d_qoy#60,d_fy_year#61,d_fy_quarter_seq#62,d_fy_week_seq#63,d_day_name#64,d_quarter_name#65,d_holiday#66,d_weekend#67,d_following_holiday#68,d_first_dom#69,d_last_dom#70,d_same_day_ly#71,d_same_day_lq#72,d_current_day#73,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1715015799,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [d_date_sk#50, d_week_seq#54, d_day_name#64] Condition : ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#374, [id=#164], xxhash64(d_week_seq#54, 42))) "
          },
          "1" : {
            "sign" : -1380665859,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 2629764,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.date_dim Output [3]: [d_date_sk#50, d_week_seq#54, d_day_name#64] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim] PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)] ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string> "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.date_dim",
          "toId" : 0,
          "toName" : "Filter",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Filter ((isnotnull(d_date_sk#50) AND isnotnull(d_week_seq#54)) AND might_contain(Subquery subquery#374, [id=#164], xxhash64(d_week_seq#54, 42)))\n:  +- Subquery subquery#374, [id=#164]\n:     +- AdaptiveSparkPlan isFinalPlan=false\n:        +- ObjectHashAggregate(keys=[], functions=[bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[bloomFilter#373])\n:           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=162]\n:              +- ObjectHashAggregate(keys=[], functions=[partial_bloom_filter_agg(xxhash64(d_week_seq#318, 42), 323, 8693, 0, 0)], output=[buf#406])\n:                 +- Project [d_week_seq#318]\n:                    +- Filter (((isnotnull(d_month_seq#317) AND (d_month_seq#317 >= 1197)) AND (d_month_seq#317 <= 1208)) AND isnotnull(d_week_seq#318))\n:                       +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_month_seq#317,d_week_seq#318] Batched: true, DataFilters: [isnotnull(d_month_seq#317), (d_month_seq#317 >= 1197), (d_month_seq#317 <= 1208), isnotnull(d_we..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>\n+- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#50,d_week_seq#54,d_day_name#64] Batched: true, DataFilters: [isnotnull(d_date_sk#50), isnotnull(d_week_seq#54)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 2629764,
        "inputRowCount" : 73049
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 3,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 11 ],
      "Objectives" : {
        "DurationInMs" : 2257,
        "TotalTasksDurationInMs" : 2253,
        "IOBytes" : {
          "Total" : 427122,
          "Details" : {
            "IR" : 427122,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "3" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 893389056,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 22512,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 22512,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#78, s_store_id#79, s_store_name#83] "
          },
          "1" : {
            "sign" : -124430594,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79)) "
          },
          "2" : {
            "sign" : -1870715280,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#78, s_store_id#79, s_rec_start_date#80, s_rec_end_date#81, s_closed_date_sk#82, s_store_name#83, s_number_employees#84, s_floor_space#85, s_hours#86, s_manager#87, s_market_id#88, s_geography_class#89, s_market_desc#90, s_market_manager#91, s_division_id#92, s_division_name#93, s_company_id#94, s_company_name#95, s_street_number#96, s_street_name#97, s_street_type#98, s_suite_number#99, s_city#100, s_county#101, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_store_sk#78, s_store_id#79, s_store_name#83]\n+- Filter (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79))\n   +- Relation spark_catalog.tpcds_100.store[s_store_sk#78,s_store_id#79,s_rec_start_date#80,s_rec_end_date#81,s_closed_date_sk#82,s_store_name#83,s_number_employees#84,s_floor_space#85,s_hours#86,s_manager#87,s_market_id#88,s_geography_class#89,s_market_desc#90,s_market_manager#91,s_division_id#92,s_division_name#93,s_company_id#94,s_company_name#95,s_street_number#96,s_street_name#97,s_street_type#98,s_suite_number#99,s_city#100,s_county#101,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 1035941776,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 22512,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [s_store_sk#78, s_store_id#79, s_store_name#83] Condition : (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79)) "
          },
          "1" : {
            "sign" : -1990519166,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 22512,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store Output [3]: [s_store_sk#78, s_store_id#79, s_store_name#83] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store] PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)] ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string> "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store",
          "toId" : 0,
          "toName" : "Filter",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Filter (isnotnull(s_store_sk#78) AND isnotnull(s_store_id#79))\n+- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#78,s_store_id#79,s_store_name#83] Batched: true, DataFilters: [isnotnull(s_store_sk#78), isnotnull(s_store_id#79)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 22512,
        "inputRowCount" : 402
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 1,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 3 ],
      "Objectives" : {
        "DurationInMs" : 1422,
        "TotalTasksDurationInMs" : 1401,
        "IOBytes" : {
          "Total" : 15622,
          "Details" : {
            "IR" : 15622,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    }
  },
  "SQLStartTimeInMs" : 1702227160785,
  "SQLEndTimeInMs" : 1702227183563,
  "Objectives" : {
    "DurationInMs" : 22778,
    "IOBytes" : {
      "Total" : 1387268822,
      "Details" : {
        "IR" : 1373353902,
        "IW" : 0,
        "SR" : 6957460,
        "SW" : 6957460
      }
    }
  }
}
