{
  "CompileTimeLQP" : {
    "LQP" : {
      "operators" : {
        "34" : {
          "sign" : 1032403944,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 82656,
          "rowCount" : 336,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#159) AND ((d_month_seq#159 >= 1212) AND (d_month_seq#159 <= 1223))) AND isnotnull(d_date_sk#156)) "
        },
        "12" : {
          "sign" : 340553390,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 39926379296,
          "rowCount" : 262673548,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#226 [ss_sold_date_sk#30]) "
        },
        "8" : {
          "sign" : 1799054268,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 37560447535,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#59 = ss_store_sk#14) "
        },
        "19" : {
          "sign" : -465917463,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#59) "
        },
        "23" : {
          "sign" : 1415626822,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
          "sizeInBytes" : 424,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) Window Arguments: [rank(_w0#94) windowspecdefinition(s_state#151, _w0#94 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#4], [s_state#151], [_w0#94 DESC NULLS LAST] "
        },
        "4" : {
          "sign" : -1917121414,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
          "sizeInBytes" : 158806397681,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) Window Arguments: [rank(_w0#199) windowspecdefinition(_w1#203, _w2#204, _w0#199 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#2], [_w1#203, _w2#204], [_w0#199 DESC NULLS LAST] "
        },
        "15" : {
          "sign" : 806171972,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 82656,
          "rowCount" : 336,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31)) "
        },
        "11" : {
          "sign" : 103482054,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 6304165152,
          "rowCount" : 262673548,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] "
        },
        "9" : {
          "sign" : 1028952948,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 5310811700,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29] "
        },
        "33" : {
          "sign" : -110070192,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 4032,
          "rowCount" : 336,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_date_sk#156] "
        },
        "22" : {
          "sign" : -2030818590,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 424,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: (ranking#4 <= 5) "
        },
        "26" : {
          "sign" : 432538741,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 17335591170,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_net_profit#125, s_state#151] "
        },
        "37" : {
          "sign" : -1500897439,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#127) "
        },
        "13" : {
          "sign" : -503710878,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 41806893656,
          "rowCount" : 275045353,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#8, ss_item_sk#9, ss_customer_sk#10, ss_cdemo_sk#11, ss_hdemo_sk#12, ss_addr_sk#13, ss_store_sk#14, ss_promo_sk#15, ss_ticket_number#16L, ss_quantity#17, ss_wholesale_cost#18, ss_list_price#19, ss_sales_price#20, ss_ext_discount_amt#21, ss_ext_sales_price#22, ss_ext_wholesale_cost#23, ss_ext_list_price#24, ss_ext_tax#25, ss_coupon_amt#26, ss_net_paid#27, ss_net_paid_inc_tax#28, ss_net_profit#29, ss_sold_date_sk#30], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "24" : {
          "sign" : 1532214050,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.WindowGroupLimit",
          "sizeInBytes" : 396,
          "rowCount" : 9,
          "isRuntime" : false,
          "predicate" : " (unknown) WindowGroupLimit Arguments: [s_state#151], [_w0#94 DESC NULLS LAST], rank(_w0#94), 5 "
        },
        "35" : {
          "sign" : 1300420706,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 17970054,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#156, d_date_id#157, d_date#158, d_month_seq#159, d_week_seq#160, d_quarter_seq#161, d_year#162, d_dow#163, d_moy#164, d_dom#165, d_qoy#166, d_fy_year#167, d_fy_quarter_seq#168, d_fy_week_seq#169, d_day_name#170, d_quarter_name#171, d_holiday#172, d_weekend#173, d_following_holiday#174, d_first_dom#175, d_last_dom#176, d_same_day_ly#177, d_same_day_lq#178, d_current_day#179, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "16" : {
          "sign" : -1043254498,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 17970054,
          "rowCount" : 73049,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#31, d_date_id#32, d_date#33, d_month_seq#34, d_week_seq#35, d_quarter_seq#36, d_year#37, d_dow#38, d_moy#39, d_dom#40, d_qoy#41, d_fy_year#42, d_fy_quarter_seq#43, d_fy_week_seq#44, d_day_name#45, d_quarter_name#46, d_holiday#47, d_weekend#48, d_following_holiday#49, d_first_dom#50, d_last_dom#51, d_same_day_ly#52, d_same_day_lq#53, d_current_day#54, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "5" : {
          "sign" : 239584259,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 151748335562,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [s_state#189, s_county#190, spark_grouping_id#188L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#0, s_state#189, s_county#190, (cast((shiftright(spark_grouping_id#188L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#188L, 0) & 1) as tinyint)) AS lochierarchy#1, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#199, (cast((shiftright(spark_grouping_id#188L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#188L, 0) & 1) as tinyint)) AS _w1#203, CASE WHEN (cast((shiftright(spark_grouping_id#188L, 0) & 1) as tinyint) = 0) THEN s_state#189 END AS _w2#204] "
        },
        "10" : {
          "sign" : 686176491,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 7435136380,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#31 = ss_sold_date_sk#30) "
        },
        "21" : {
          "sign" : -642864758,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 197,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_state#151] "
        },
        "32" : {
          "sign" : 1421424822,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 41806893656,
          "rowCount" : 275045353,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#104, ss_item_sk#105, ss_customer_sk#106, ss_cdemo_sk#107, ss_hdemo_sk#108, ss_addr_sk#109, ss_store_sk#110, ss_promo_sk#111, ss_ticket_number#112L, ss_quantity#113, ss_wholesale_cost#114, ss_list_price#115, ss_sales_price#116, ss_ext_discount_amt#117, ss_ext_sales_price#118, ss_ext_wholesale_cost#119, ss_ext_list_price#120, ss_ext_tax#121, ss_coupon_amt#122, ss_net_paid#123, ss_net_paid_inc_tax#124, ss_net_profit#125, ss_sold_date_sk#126], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "6" : {
          "sign" : -127606928,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Expand",
          "sizeInBytes" : 112928993907,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) Expand Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#189, s_county#190, spark_grouping_id#188L] "
        },
        "36" : {
          "sign" : -736941996,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 10452,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_store_sk#127, s_state#151] "
        },
        "1" : {
          "sign" : -1137862946,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
          "sizeInBytes" : 107635447317,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) LocalLimit Arguments: 100 "
        },
        "17" : {
          "sign" : 234792047,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 21306,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: LeftSemi, (s_state#83 = s_state#151) "
        },
        "25" : {
          "sign" : 1304948126,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
          "sizeInBytes" : 396,
          "rowCount" : 9,
          "isRuntime" : false,
          "predicate" : " (unknown) Aggregate Arguments: [s_state#151], [s_state#151, MakeDecimal(sum(UnscaledValue(ss_net_profit#125)),17,2) AS _w0#94, s_state#151] "
        },
        "14" : {
          "sign" : -1849171734,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 4032,
          "rowCount" : 336,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [d_date_sk#31] "
        },
        "31" : {
          "sign" : 2082106237,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
          "sizeInBytes" : 39926379296,
          "rowCount" : 262673548,
          "isRuntime" : false,
          "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_store_sk#110) AND isnotnull(ss_sold_date_sk#126)) AND dynamicpruning#213 [ss_sold_date_sk#126]) "
        },
        "0" : {
          "sign" : 1512452989,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
          "sizeInBytes" : 6100,
          "rowCount" : 100,
          "isRuntime" : false,
          "predicate" : " (unknown) GlobalLimit Arguments: 100 "
        },
        "20" : {
          "sign" : 73744801,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#59, s_store_id#60, s_rec_start_date#61, s_rec_end_date#62, s_closed_date_sk#63, s_store_name#64, s_number_employees#65, s_floor_space#66, s_hours#67, s_manager#68, s_market_id#69, s_geography_class#70, s_market_desc#71, s_market_manager#72, s_division_id#73, s_division_name#74, s_company_id#75, s_company_name#76, s_street_number#77, s_street_name#78, s_street_type#79, s_suite_number#80, s_city#81, s_county#82, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "27" : {
          "sign" : -2130476965,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 21958415482,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#127 = ss_store_sk#110) "
        },
        "2" : {
          "sign" : 1243837203,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
          "sizeInBytes" : 107635447317,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) Sort Arguments: [lochierarchy#1 DESC NULLS LAST, CASE WHEN (lochierarchy#1 = 0) THEN s_state#189 END ASC NULLS FIRST, rank_within_parent#2 ASC NULLS FIRST], true "
        },
        "38" : {
          "sign" : -795205719,
          "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
          "sizeInBytes" : 192558,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#127, s_store_id#128, s_rec_start_date#129, s_rec_end_date#130, s_closed_date_sk#131, s_store_name#132, s_number_employees#133, s_floor_space#134, s_hours#135, s_manager#136, s_market_id#137, s_geography_class#138, s_market_desc#139, s_market_manager#140, s_division_id#141, s_division_name#142, s_company_id#143, s_company_name#144, s_street_number#145, s_street_name#146, s_street_type#147, s_suite_number#148, s_city#149, s_county#150, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
        },
        "18" : {
          "sign" : 631921819,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 21306,
          "rowCount" : 402,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [s_store_sk#59, s_county#82, s_state#83] "
        },
        "30" : {
          "sign" : -1219089453,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 6304165152,
          "rowCount" : 262673548,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_store_sk#110, ss_net_profit#125, ss_sold_date_sk#126] "
        },
        "7" : {
          "sign" : -836783428,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 32937623223,
          "rowCount" : 577853039,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_net_profit#29, s_state#83, s_county#82] "
        },
        "29" : {
          "sign" : 397112260,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
          "sizeInBytes" : 7435136380,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#156 = ss_sold_date_sk#126) "
        },
        "3" : {
          "sign" : 2052431606,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 107635447317,
          "rowCount" : -1,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [total_sum#0, s_state#189, s_county#190, lochierarchy#1, rank_within_parent#2] "
        },
        "28" : {
          "sign" : -836389445,
          "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
          "sizeInBytes" : 5310811700,
          "rowCount" : 265540585,
          "isRuntime" : false,
          "predicate" : " (unknown) Project Arguments: [ss_store_sk#110, ss_net_profit#125] "
        }
      },
      "links" : [ {
        "fromId" : 13,
        "fromName" : "LogicalRelation",
        "toId" : 12,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 16,
        "fromName" : "LogicalRelation",
        "toId" : 15,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 15,
        "fromName" : "Filter",
        "toId" : 14,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 14,
        "fromName" : "Project",
        "toId" : 12,
        "toName" : "Filter",
        "linkType" : "Subquery"
      }, {
        "fromId" : 12,
        "fromName" : "Filter",
        "toId" : 11,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 11,
        "fromName" : "Project",
        "toId" : 10,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 14,
        "fromName" : "Project",
        "toId" : 10,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 10,
        "fromName" : "Join",
        "toId" : 9,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 9,
        "fromName" : "Project",
        "toId" : 8,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 20,
        "fromName" : "LogicalRelation",
        "toId" : 19,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 19,
        "fromName" : "Filter",
        "toId" : 18,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 18,
        "fromName" : "Project",
        "toId" : 17,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 32,
        "fromName" : "LogicalRelation",
        "toId" : 31,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 35,
        "fromName" : "LogicalRelation",
        "toId" : 34,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 34,
        "fromName" : "Filter",
        "toId" : 33,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 33,
        "fromName" : "Project",
        "toId" : 31,
        "toName" : "Filter",
        "linkType" : "Subquery"
      }, {
        "fromId" : 31,
        "fromName" : "Filter",
        "toId" : 30,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 30,
        "fromName" : "Project",
        "toId" : 29,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 33,
        "fromName" : "Project",
        "toId" : 29,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 29,
        "fromName" : "Join",
        "toId" : 28,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 28,
        "fromName" : "Project",
        "toId" : 27,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 38,
        "fromName" : "LogicalRelation",
        "toId" : 37,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 37,
        "fromName" : "Filter",
        "toId" : 36,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 36,
        "fromName" : "Project",
        "toId" : 27,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 27,
        "fromName" : "Join",
        "toId" : 26,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 26,
        "fromName" : "Project",
        "toId" : 25,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 25,
        "fromName" : "Aggregate",
        "toId" : 24,
        "toName" : "WindowGroupLimit",
        "linkType" : "Operator"
      }, {
        "fromId" : 24,
        "fromName" : "WindowGroupLimit",
        "toId" : 23,
        "toName" : "Window",
        "linkType" : "Operator"
      }, {
        "fromId" : 23,
        "fromName" : "Window",
        "toId" : 22,
        "toName" : "Filter",
        "linkType" : "Operator"
      }, {
        "fromId" : 22,
        "fromName" : "Filter",
        "toId" : 21,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 21,
        "fromName" : "Project",
        "toId" : 17,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 17,
        "fromName" : "Join",
        "toId" : 8,
        "toName" : "Join",
        "linkType" : "Operator"
      }, {
        "fromId" : 8,
        "fromName" : "Join",
        "toId" : 7,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 7,
        "fromName" : "Project",
        "toId" : 6,
        "toName" : "Expand",
        "linkType" : "Operator"
      }, {
        "fromId" : 6,
        "fromName" : "Expand",
        "toId" : 5,
        "toName" : "Aggregate",
        "linkType" : "Operator"
      }, {
        "fromId" : 5,
        "fromName" : "Aggregate",
        "toId" : 4,
        "toName" : "Window",
        "linkType" : "Operator"
      }, {
        "fromId" : 4,
        "fromName" : "Window",
        "toId" : 3,
        "toName" : "Project",
        "linkType" : "Operator"
      }, {
        "fromId" : 3,
        "fromName" : "Project",
        "toId" : 2,
        "toName" : "Sort",
        "linkType" : "Operator"
      }, {
        "fromId" : 2,
        "fromName" : "Sort",
        "toId" : 1,
        "toName" : "LocalLimit",
        "linkType" : "Operator"
      }, {
        "fromId" : 1,
        "fromName" : "LocalLimit",
        "toId" : 0,
        "toName" : "GlobalLimit",
        "linkType" : "Operator"
      } ],
      "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#1 DESC NULLS LAST, CASE WHEN (lochierarchy#1 = 0) THEN s_state#189 END ASC NULLS FIRST, rank_within_parent#2 ASC NULLS FIRST], true\n      +- Project [total_sum#0, s_state#189, s_county#190, lochierarchy#1, rank_within_parent#2]\n         +- Window [rank(_w0#199) windowspecdefinition(_w1#203, _w2#204, _w0#199 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#2], [_w1#203, _w2#204], [_w0#199 DESC NULLS LAST]\n            +- Aggregate [s_state#189, s_county#190, spark_grouping_id#188L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#0, s_state#189, s_county#190, (cast((shiftright(spark_grouping_id#188L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#188L, 0) & 1) as tinyint)) AS lochierarchy#1, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#199, (cast((shiftright(spark_grouping_id#188L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#188L, 0) & 1) as tinyint)) AS _w1#203, CASE WHEN (cast((shiftright(spark_grouping_id#188L, 0) & 1) as tinyint) = 0) THEN s_state#189 END AS _w2#204]\n               +- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#189, s_county#190, spark_grouping_id#188L]\n                  +- Project [ss_net_profit#29, s_state#83, s_county#82]\n                     +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n                        :- Project [ss_store_sk#14, ss_net_profit#29]\n                        :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n                        :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n                        :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#226 [ss_sold_date_sk#30])\n                        :     :     :  +- Project [d_date_sk#31]\n                        :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n                        :     +- Project [d_date_sk#31]\n                        :        +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        +- Join LeftSemi, (s_state#83 = s_state#151)\n                           :- Project [s_store_sk#59, s_county#82, s_state#83]\n                           :  +- Filter isnotnull(s_store_sk#59)\n                           :     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n                           +- Project [s_state#151]\n                              +- Filter (ranking#4 <= 5)\n                                 +- Window [rank(_w0#94) windowspecdefinition(s_state#151, _w0#94 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#4], [s_state#151], [_w0#94 DESC NULLS LAST]\n                                    +- WindowGroupLimit [s_state#151], [_w0#94 DESC NULLS LAST], rank(_w0#94), 5\n                                       +- Aggregate [s_state#151], [s_state#151, MakeDecimal(sum(UnscaledValue(ss_net_profit#125)),17,2) AS _w0#94, s_state#151]\n                                          +- Project [ss_net_profit#125, s_state#151]\n                                             +- Join Inner, (s_store_sk#127 = ss_store_sk#110)\n                                                :- Project [ss_store_sk#110, ss_net_profit#125]\n                                                :  +- Join Inner, (d_date_sk#156 = ss_sold_date_sk#126)\n                                                :     :- Project [ss_store_sk#110, ss_net_profit#125, ss_sold_date_sk#126]\n                                                :     :  +- Filter ((isnotnull(ss_store_sk#110) AND isnotnull(ss_sold_date_sk#126)) AND dynamicpruning#213 [ss_sold_date_sk#126])\n                                                :     :     :  +- Project [d_date_sk#156]\n                                                :     :     :     +- Filter ((isnotnull(d_month_seq#159) AND ((d_month_seq#159 >= 1212) AND (d_month_seq#159 <= 1223))) AND isnotnull(d_date_sk#156))\n                                                :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#156,d_date_id#157,d_date#158,d_month_seq#159,d_week_seq#160,d_quarter_seq#161,d_year#162,d_dow#163,d_moy#164,d_dom#165,d_qoy#166,d_fy_year#167,d_fy_quarter_seq#168,d_fy_week_seq#169,d_day_name#170,d_quarter_name#171,d_holiday#172,d_weekend#173,d_following_holiday#174,d_first_dom#175,d_last_dom#176,d_same_day_ly#177,d_same_day_lq#178,d_current_day#179,... 4 more fields] parquet\n                                                :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#104,ss_item_sk#105,ss_customer_sk#106,ss_cdemo_sk#107,ss_hdemo_sk#108,ss_addr_sk#109,ss_store_sk#110,ss_promo_sk#111,ss_ticket_number#112L,ss_quantity#113,ss_wholesale_cost#114,ss_list_price#115,ss_sales_price#116,ss_ext_discount_amt#117,ss_ext_sales_price#118,ss_ext_wholesale_cost#119,ss_ext_list_price#120,ss_ext_tax#121,ss_coupon_amt#122,ss_net_paid#123,ss_net_paid_inc_tax#124,ss_net_profit#125,ss_sold_date_sk#126] parquet\n                                                :     +- Project [d_date_sk#156]\n                                                :        +- Filter ((isnotnull(d_month_seq#159) AND ((d_month_seq#159 >= 1212) AND (d_month_seq#159 <= 1223))) AND isnotnull(d_date_sk#156))\n                                                :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#156,d_date_id#157,d_date#158,d_month_seq#159,d_week_seq#160,d_quarter_seq#161,d_year#162,d_dow#163,d_moy#164,d_dom#165,d_qoy#166,d_fy_year#167,d_fy_quarter_seq#168,d_fy_week_seq#169,d_day_name#170,d_quarter_name#171,d_holiday#172,d_weekend#173,d_following_holiday#174,d_first_dom#175,d_last_dom#176,d_same_day_ly#177,d_same_day_lq#178,d_current_day#179,... 4 more fields] parquet\n                                                +- Project [s_store_sk#127, s_state#151]\n                                                   +- Filter isnotnull(s_store_sk#127)\n                                                      +- Relation spark_catalog.tpcds_100.store[s_store_sk#127,s_store_id#128,s_rec_start_date#129,s_rec_end_date#130,s_closed_date_sk#131,s_store_name#132,s_number_employees#133,s_floor_space#134,s_hours#135,s_manager#136,s_market_id#137,s_geography_class#138,s_market_desc#139,s_market_manager#140,s_division_id#141,s_division_name#142,s_company_id#143,s_company_name#144,s_street_number#145,s_street_name#146,s_street_type#147,s_suite_number#148,s_city#149,s_county#150,... 5 more fields] parquet\n"
    },
    "IM" : {
      "inputSizeInBytes" : 83650112536,
      "inputRowCount" : 550237608
    },
    "PD" : { },
    "Configuration" : {
      "theta_c" : [ {
        "spark.executor.memory" : "1g"
      }, {
        "spark.executor.cores" : "1"
      }, {
        "spark.executor.instances" : "16"
      }, {
        "spark.default.parallelism" : "16"
      }, {
        "spark.reducer.maxSizeInFlight" : "48m"
      }, {
        "spark.shuffle.sort.bypassMergeThreshold" : "200"
      }, {
        "spark.shuffle.compress" : "true"
      }, {
        "spark.memory.fraction" : "0.6"
      } ],
      "theta_p" : [ {
        "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
      }, {
        "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
      }, {
        "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
      }, {
        "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
      }, {
        "spark.sql.shuffle.partitions" : "200"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
      }, {
        "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
      }, {
        "spark.sql.files.maxPartitionBytes" : "128MB"
      }, {
        "spark.sql.files.openCostInBytes" : "4MB"
      } ],
      "theta_s" : [ {
        "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
      }, {
        "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
      } ]
    }
  },
  "RuntimeLQPs" : {
    "8" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : -1911189852,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 1657,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "5" : {
            "sign" : 852429987,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1584,
            "rowCount" : 19,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367], ShuffleQueryStage 8 "
          },
          "1" : {
            "sign" : 805606001,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 1123,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "0" : {
            "sign" : 1798789390,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 163706360,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 1123,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "3" : {
            "sign" : -1043803157,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1123,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- LogicalQueryStage Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367], ShuffleQueryStage 8\n"
      },
      "IM" : {
        "inputSizeInBytes" : 1584,
        "inputRowCount" : 19
      },
      "PD" : {
        "2" : [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 276, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227252954,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 430,
        "IOBytes" : {
          "Total" : 1483,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1483,
            "SW" : 0
          }
        }
      }
    },
    "4" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : -288548948,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30]) "
          },
          "8" : {
            "sign" : -21721840,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 37560447535,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#59 = ss_store_sk#14) "
          },
          "19" : {
            "sign" : 631921819,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#59, s_county#82, s_state#83] "
          },
          "23" : {
            "sign" : -215504976,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 9874,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (ranking#250 <= 5) "
          },
          "4" : {
            "sign" : -1337475797,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 158806397681,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "15" : {
            "sign" : 806171972,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 82656,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31)) "
          },
          "11" : {
            "sign" : -1024450876,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] "
          },
          "9" : {
            "sign" : -967047166,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1917516900400,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29] "
          },
          "22" : {
            "sign" : -1099650659,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4607,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_state#314] "
          },
          "26" : {
            "sign" : -1123325026,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 9216,
            "rowCount" : 288,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314], HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))]) "
          },
          "13" : {
            "sign" : -503710878,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#8, ss_item_sk#9, ss_customer_sk#10, ss_cdemo_sk#11, ss_hdemo_sk#12, ss_addr_sk#13, ss_store_sk#14, ss_promo_sk#15, ss_ticket_number#16L, ss_quantity#17, ss_wholesale_cost#18, ss_list_price#19, ss_sales_price#20, ss_ext_discount_amt#21, ss_ext_sales_price#22, ss_ext_wholesale_cost#23, ss_ext_list_price#24, ss_ext_tax#25, ss_coupon_amt#26, ss_net_paid#27, ss_net_paid_inc_tax#28, ss_net_profit#29, ss_sold_date_sk#30], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "24" : {
            "sign" : -1353567877,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 9874,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST] "
          },
          "16" : {
            "sign" : -1043254498,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#31, d_date_id#32, d_date#33, d_month_seq#34, d_week_seq#35, d_quarter_seq#36, d_year#37, d_dow#38, d_moy#39, d_dom#40, d_qoy#41, d_fy_year#42, d_fy_quarter_seq#43, d_fy_week_seq#44, d_day_name#45, d_quarter_name#46, d_holiday#47, d_weekend#48, d_following_holiday#49, d_first_dom#50, d_last_dom#51, d_same_day_ly#52, d_same_day_lq#53, d_current_day#54, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "5" : {
            "sign" : -1176014018,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 151748335562,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367] "
          },
          "10" : {
            "sign" : -835972677,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2684523660560,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#31 = ss_sold_date_sk#30) "
          },
          "21" : {
            "sign" : 73744801,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#59, s_store_id#60, s_rec_start_date#61, s_rec_end_date#62, s_closed_date_sk#63, s_store_name#64, s_number_employees#65, s_floor_space#66, s_hours#67, s_manager#68, s_market_id#69, s_geography_class#70, s_market_desc#71, s_market_manager#72, s_division_id#73, s_division_name#74, s_company_id#75, s_company_name#76, s_street_number#77, s_street_name#78, s_street_type#79, s_suite_number#80, s_city#81, s_county#82, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "6" : {
            "sign" : -356097819,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Expand",
            "sizeInBytes" : 112928993907,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Expand Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] "
          },
          "1" : {
            "sign" : -358654160,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : -680408626,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#31], BroadcastQueryStage 0 "
          },
          "25" : {
            "sign" : 1504588801,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.WindowGroupLimit",
            "sizeInBytes" : 9216,
            "rowCount" : 288,
            "isRuntime" : false,
            "predicate" : " (unknown) WindowGroupLimit Arguments: [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5 "
          },
          "14" : {
            "sign" : -1849171734,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#31] "
          },
          "0" : {
            "sign" : -65641451,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -465917463,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#59) "
          },
          "2" : {
            "sign" : 1170863807,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 1998172509,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: LeftSemi, (s_state#83 = s_state#314) "
          },
          "7" : {
            "sign" : -264845290,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 32937623223,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#29, s_state#83, s_county#82] "
          },
          "3" : {
            "sign" : 1413303286,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          }
        },
        "links" : [ {
          "fromId" : 13,
          "fromName" : "LogicalRelation",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalRelation",
          "toId" : 15,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Filter",
          "toId" : 14,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Project",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 12,
          "fromName" : "Filter",
          "toId" : 11,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Project",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Join",
          "toId" : 9,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Project",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "LogicalRelation",
          "toId" : 20,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Filter",
          "toId" : 19,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "LogicalQueryStage",
          "toId" : 25,
          "toName" : "WindowGroupLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "WindowGroupLimit",
          "toId" : 24,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Window",
          "toId" : 23,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Filter",
          "toId" : 22,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Join",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Expand",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Expand",
          "toId" : 5,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Aggregate",
          "toId" : 4,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367]\n               +- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n                  +- Project [ss_net_profit#29, s_state#83, s_county#82]\n                     +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n                        :- Project [ss_store_sk#14, ss_net_profit#29]\n                        :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n                        :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n                        :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30])\n                        :     :     :  +- Project [d_date_sk#31]\n                        :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n                        :     +- LogicalQueryStage Project [d_date_sk#31], BroadcastQueryStage 0\n                        +- Join LeftSemi, (s_state#83 = s_state#314)\n                           :- Project [s_store_sk#59, s_county#82, s_state#83]\n                           :  +- Filter isnotnull(s_store_sk#59)\n                           :     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n                           +- Project [s_state#314]\n                              +- Filter (ranking#250 <= 5)\n                                 +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                                    +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5\n                                       +- LogicalQueryStage Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314], HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 41808146926,
        "inputRowCount" : 275046408
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227249398,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 3986,
        "IOBytes" : {
          "Total" : 235937215,
          "Details" : {
            "IR" : 235807733,
            "IW" : 0,
            "SR" : 75684,
            "SW" : 53798
          }
        }
      }
    },
    "5" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : -288548948,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30]) "
          },
          "8" : {
            "sign" : 1900872701,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 37560447535,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#59 = ss_store_sk#14) "
          },
          "19" : {
            "sign" : 631921819,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#59, s_county#82, s_state#83] "
          },
          "4" : {
            "sign" : -1867951208,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 158806397681,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "15" : {
            "sign" : 806171972,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 82656,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31)) "
          },
          "11" : {
            "sign" : -1024450876,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] "
          },
          "9" : {
            "sign" : -967047166,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1917516900400,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29] "
          },
          "22" : {
            "sign" : 1861510666,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 33555456,
            "rowCount" : 9,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_state#314], BroadcastQueryStage 5 "
          },
          "13" : {
            "sign" : -503710878,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#8, ss_item_sk#9, ss_customer_sk#10, ss_cdemo_sk#11, ss_hdemo_sk#12, ss_addr_sk#13, ss_store_sk#14, ss_promo_sk#15, ss_ticket_number#16L, ss_quantity#17, ss_wholesale_cost#18, ss_list_price#19, ss_sales_price#20, ss_ext_discount_amt#21, ss_ext_sales_price#22, ss_ext_wholesale_cost#23, ss_ext_list_price#24, ss_ext_tax#25, ss_coupon_amt#26, ss_net_paid#27, ss_net_paid_inc_tax#28, ss_net_profit#29, ss_sold_date_sk#30], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "16" : {
            "sign" : -1043254498,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#31, d_date_id#32, d_date#33, d_month_seq#34, d_week_seq#35, d_quarter_seq#36, d_year#37, d_dow#38, d_moy#39, d_dom#40, d_qoy#41, d_fy_year#42, d_fy_quarter_seq#43, d_fy_week_seq#44, d_day_name#45, d_quarter_name#46, d_holiday#47, d_weekend#48, d_following_holiday#49, d_first_dom#50, d_last_dom#51, d_same_day_ly#52, d_same_day_lq#53, d_current_day#54, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "5" : {
            "sign" : 155201095,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 151748335562,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367] "
          },
          "10" : {
            "sign" : -835972677,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2684523660560,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#31 = ss_sold_date_sk#30) "
          },
          "21" : {
            "sign" : 73744801,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#59, s_store_id#60, s_rec_start_date#61, s_rec_end_date#62, s_closed_date_sk#63, s_store_name#64, s_number_employees#65, s_floor_space#66, s_hours#67, s_manager#68, s_market_id#69, s_geography_class#70, s_market_desc#71, s_market_manager#72, s_division_id#73, s_division_name#74, s_company_id#75, s_company_name#76, s_street_number#77, s_street_name#78, s_street_type#79, s_suite_number#80, s_city#81, s_county#82, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "6" : {
            "sign" : 1513657170,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Expand",
            "sizeInBytes" : 112928993907,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Expand Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] "
          },
          "1" : {
            "sign" : 320964665,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : -680408626,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#31], BroadcastQueryStage 0 "
          },
          "14" : {
            "sign" : -1849171734,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#31] "
          },
          "0" : {
            "sign" : -506688126,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -465917463,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#59) "
          },
          "2" : {
            "sign" : 1303585324,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 365263206,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: LeftSemi, (s_state#83 = s_state#314) "
          },
          "7" : {
            "sign" : 1992602399,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 32937623223,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#29, s_state#83, s_county#82] "
          },
          "3" : {
            "sign" : -1960122625,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          }
        },
        "links" : [ {
          "fromId" : 13,
          "fromName" : "LogicalRelation",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalRelation",
          "toId" : 15,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Filter",
          "toId" : 14,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Project",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 12,
          "fromName" : "Filter",
          "toId" : 11,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Project",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Join",
          "toId" : 9,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Project",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "LogicalRelation",
          "toId" : 20,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Filter",
          "toId" : 19,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "LogicalQueryStage",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Join",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Expand",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Expand",
          "toId" : 5,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Aggregate",
          "toId" : 4,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367]\n               +- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n                  +- Project [ss_net_profit#29, s_state#83, s_county#82]\n                     +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n                        :- Project [ss_store_sk#14, ss_net_profit#29]\n                        :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n                        :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n                        :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30])\n                        :     :     :  +- Project [d_date_sk#31]\n                        :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n                        :     +- LogicalQueryStage Project [d_date_sk#31], BroadcastQueryStage 0\n                        +- Join LeftSemi, (s_state#83 = s_state#314)\n                           :- Project [s_store_sk#59, s_county#82, s_state#83]\n                           :  +- Filter isnotnull(s_store_sk#59)\n                           :     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n                           +- LogicalQueryStage Project [s_state#314], BroadcastQueryStage 5\n"
      },
      "IM" : {
        "inputSizeInBytes" : 41841693166,
        "inputRowCount" : 275046129
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227250033,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 3351,
        "IOBytes" : {
          "Total" : 235915329,
          "Details" : {
            "IR" : 235807733,
            "IW" : 0,
            "SR" : 53798,
            "SW" : 53798
          }
        }
      }
    },
    "6" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : -288548948,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30]) "
          },
          "8" : {
            "sign" : 1598211643,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2466693740674560,
            "rowCount" : 38542089698040,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#59 = ss_store_sk#14) "
          },
          "4" : {
            "sign" : 1359319680,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 10406364218470800,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "15" : {
            "sign" : 806171972,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 82656,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31)) "
          },
          "11" : {
            "sign" : -1024450876,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] "
          },
          "9" : {
            "sign" : -967047166,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1917516900400,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29] "
          },
          "13" : {
            "sign" : -503710878,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#8, ss_item_sk#9, ss_customer_sk#10, ss_cdemo_sk#11, ss_hdemo_sk#12, ss_addr_sk#13, ss_store_sk#14, ss_promo_sk#15, ss_ticket_number#16L, ss_quantity#17, ss_wholesale_cost#18, ss_list_price#19, ss_sales_price#20, ss_ext_discount_amt#21, ss_ext_sales_price#22, ss_ext_wholesale_cost#23, ss_ext_list_price#24, ss_ext_tax#25, ss_coupon_amt#26, ss_net_paid#27, ss_net_paid_inc_tax#28, ss_net_profit#29, ss_sold_date_sk#30], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "16" : {
            "sign" : -1043254498,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#31, d_date_id#32, d_date#33, d_month_seq#34, d_week_seq#35, d_quarter_seq#36, d_year#37, d_dow#38, d_moy#39, d_dom#40, d_qoy#41, d_fy_year#42, d_fy_quarter_seq#43, d_fy_week_seq#44, d_day_name#45, d_quarter_name#46, d_holiday#47, d_weekend#48, d_following_holiday#49, d_first_dom#50, d_last_dom#51, d_same_day_ly#52, d_same_day_lq#53, d_current_day#54, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "5" : {
            "sign" : 106420065,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 9943859142094320,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367] "
          },
          "10" : {
            "sign" : -835972677,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2684523660560,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#31 = ss_sold_date_sk#30) "
          },
          "6" : {
            "sign" : 400729478,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Expand",
            "sizeInBytes" : 7400081222023680,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Expand Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] "
          },
          "1" : {
            "sign" : -529823057,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 7053202414741320,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : -680408626,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#31], BroadcastQueryStage 0 "
          },
          "14" : {
            "sign" : -1849171734,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#31] "
          },
          "0" : {
            "sign" : -1845304874,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 495044588,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 7053202414741320,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 1674575650,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Join LeftSemi, (s_state#83 = s_state#314), BroadcastQueryStage 6 "
          },
          "7" : {
            "sign" : 673155081,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2158357023090240,
            "rowCount" : 38542089698040,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#29, s_state#83, s_county#82] "
          },
          "3" : {
            "sign" : -208307415,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 7053202414741320,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          }
        },
        "links" : [ {
          "fromId" : 13,
          "fromName" : "LogicalRelation",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalRelation",
          "toId" : 15,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Filter",
          "toId" : 14,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Project",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 12,
          "fromName" : "Filter",
          "toId" : 11,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Project",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Join",
          "toId" : 9,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Project",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "LogicalQueryStage",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Expand",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Expand",
          "toId" : 5,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Aggregate",
          "toId" : 4,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367]\n               +- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n                  +- Project [ss_net_profit#29, s_state#83, s_county#82]\n                     +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n                        :- Project [ss_store_sk#14, ss_net_profit#29]\n                        :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n                        :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n                        :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30])\n                        :     :     :  +- Project [d_date_sk#31]\n                        :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n                        :     +- LogicalQueryStage Project [d_date_sk#31], BroadcastQueryStage 0\n                        +- LogicalQueryStage Join LeftSemi, (s_state#83 = s_state#314), BroadcastQueryStage 6\n"
      },
      "IM" : {
        "inputSizeInBytes" : 41808996944,
        "inputRowCount" : 275046120
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227250230,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 3154,
        "IOBytes" : {
          "Total" : 235900550,
          "Details" : {
            "IR" : 235792954,
            "IW" : 0,
            "SR" : 53798,
            "SW" : 53798
          }
        }
      }
    },
    "1" : {
      "LQP" : {
        "operators" : {
          "34" : {
            "sign" : -1747060577,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#319] "
          },
          "12" : {
            "sign" : -288548948,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30]) "
          },
          "8" : {
            "sign" : -1876349985,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 37560447535,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#59 = ss_store_sk#14) "
          },
          "19" : {
            "sign" : 631921819,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#59, s_county#82, s_state#83] "
          },
          "23" : {
            "sign" : -908117851,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 6404838910200,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (ranking#250 <= 5) "
          },
          "4" : {
            "sign" : 1222543076,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 158806397681,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "15" : {
            "sign" : 806171972,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 82656,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31)) "
          },
          "11" : {
            "sign" : -1024450876,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] "
          },
          "9" : {
            "sign" : -967047166,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 5310811700,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29] "
          },
          "33" : {
            "sign" : 1350045264,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#267, ss_item_sk#268, ss_customer_sk#269, ss_cdemo_sk#270, ss_hdemo_sk#271, ss_addr_sk#272, ss_store_sk#273, ss_promo_sk#274, ss_ticket_number#275L, ss_quantity#276, ss_wholesale_cost#277, ss_list_price#278, ss_sales_price#279, ss_ext_discount_amt#280, ss_ext_sales_price#281, ss_ext_wholesale_cost#282, ss_ext_list_price#283, ss_ext_tax#284, ss_coupon_amt#285, ss_net_paid#286, ss_net_paid_inc_tax#287, ss_net_profit#288, ss_sold_date_sk#289], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "22" : {
            "sign" : -1091448718,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 2988924824760,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_state#314] "
          },
          "26" : {
            "sign" : -919170863,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 5977849649520,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314] "
          },
          "37" : {
            "sign" : -1964699841,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#319], BroadcastQueryStage 2 "
          },
          "13" : {
            "sign" : -503710878,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#8, ss_item_sk#9, ss_customer_sk#10, ss_cdemo_sk#11, ss_hdemo_sk#12, ss_addr_sk#13, ss_store_sk#14, ss_promo_sk#15, ss_ticket_number#16L, ss_quantity#17, ss_wholesale_cost#18, ss_list_price#19, ss_sales_price#20, ss_ext_discount_amt#21, ss_ext_sales_price#22, ss_ext_wholesale_cost#23, ss_ext_list_price#24, ss_ext_tax#25, ss_coupon_amt#26, ss_net_paid#27, ss_net_paid_inc_tax#28, ss_net_profit#29, ss_sold_date_sk#30], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "24" : {
            "sign" : -203359340,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 6404838910200,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST] "
          },
          "35" : {
            "sign" : -720379420,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 82656,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319)) "
          },
          "16" : {
            "sign" : -1043254498,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#31, d_date_id#32, d_date#33, d_month_seq#34, d_week_seq#35, d_quarter_seq#36, d_year#37, d_dow#38, d_moy#39, d_dom#40, d_qoy#41, d_fy_year#42, d_fy_quarter_seq#43, d_fy_week_seq#44, d_day_name#45, d_quarter_name#46, d_holiday#47, d_weekend#48, d_following_holiday#49, d_first_dom#50, d_last_dom#51, d_same_day_ly#52, d_same_day_lq#53, d_current_day#54, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "5" : {
            "sign" : -666675049,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 151748335562,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367] "
          },
          "10" : {
            "sign" : -835972677,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 7435136380,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#31 = ss_sold_date_sk#30) "
          },
          "21" : {
            "sign" : 73744801,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#59, s_store_id#60, s_rec_start_date#61, s_rec_end_date#62, s_closed_date_sk#63, s_store_name#64, s_number_employees#65, s_floor_space#66, s_hours#67, s_manager#68, s_market_id#69, s_geography_class#70, s_market_desc#71, s_market_manager#72, s_division_id#73, s_division_name#74, s_company_id#75, s_company_name#76, s_street_number#77, s_street_name#78, s_street_type#79, s_suite_number#80, s_city#81, s_county#82, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "32" : {
            "sign" : 1061342824,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289]) "
          },
          "6" : {
            "sign" : 282260138,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Expand",
            "sizeInBytes" : 112928993907,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Expand Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] "
          },
          "36" : {
            "sign" : -1403770701,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#319, d_date_id#320, d_date#321, d_month_seq#322, d_week_seq#323, d_quarter_seq#324, d_year#325, d_dow#326, d_moy#327, d_dom#328, d_qoy#329, d_fy_year#330, d_fy_quarter_seq#331, d_fy_week_seq#332, d_day_name#333, d_quarter_name#334, d_holiday#335, d_weekend#336, d_following_holiday#337, d_first_dom#338, d_last_dom#339, d_same_day_ly#340, d_same_day_lq#341, d_current_day#342, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "1" : {
            "sign" : 231331557,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : -680408626,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#31], BroadcastQueryStage 0 "
          },
          "25" : {
            "sign" : 466225396,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.WindowGroupLimit",
            "sizeInBytes" : 5977849649520,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) WindowGroupLimit Arguments: [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5 "
          },
          "14" : {
            "sign" : -1849171734,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#31] "
          },
          "31" : {
            "sign" : 1656499568,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289] "
          },
          "0" : {
            "sign" : 19796282,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -465917463,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#59) "
          },
          "27" : {
            "sign" : 760105960,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 3842903346120,
            "rowCount" : 106747315170,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#288, s_state#314] "
          },
          "2" : {
            "sign" : 1087773200,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "38" : {
            "sign" : 734385352,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#290, s_state#314], BroadcastQueryStage 3 "
          },
          "18" : {
            "sign" : -2139678312,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: LeftSemi, (s_state#83 = s_state#314) "
          },
          "30" : {
            "sign" : -1905409205,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 7435136380,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#319 = ss_sold_date_sk#289) "
          },
          "7" : {
            "sign" : 2046557183,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 32937623223,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#29, s_state#83, s_county#82] "
          },
          "29" : {
            "sign" : -392513008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 5310811700,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#273, ss_net_profit#288] "
          },
          "3" : {
            "sign" : 664747423,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          },
          "28" : {
            "sign" : 1704394357,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 4696881867480,
            "rowCount" : 106747315170,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#290 = ss_store_sk#273) "
          }
        },
        "links" : [ {
          "fromId" : 13,
          "fromName" : "LogicalRelation",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalRelation",
          "toId" : 15,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Filter",
          "toId" : 14,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Project",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 12,
          "fromName" : "Filter",
          "toId" : 11,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Project",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Join",
          "toId" : 9,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Project",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "LogicalRelation",
          "toId" : 20,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Filter",
          "toId" : 19,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 33,
          "fromName" : "LogicalRelation",
          "toId" : 32,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 36,
          "fromName" : "LogicalRelation",
          "toId" : 35,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 35,
          "fromName" : "Filter",
          "toId" : 34,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 34,
          "fromName" : "Project",
          "toId" : 32,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 32,
          "fromName" : "Filter",
          "toId" : 31,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 31,
          "fromName" : "Project",
          "toId" : 30,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 37,
          "fromName" : "LogicalQueryStage",
          "toId" : 30,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 30,
          "fromName" : "Join",
          "toId" : 29,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 29,
          "fromName" : "Project",
          "toId" : 28,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 38,
          "fromName" : "LogicalQueryStage",
          "toId" : 28,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 28,
          "fromName" : "Join",
          "toId" : 27,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 27,
          "fromName" : "Project",
          "toId" : 26,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "Aggregate",
          "toId" : 25,
          "toName" : "WindowGroupLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "WindowGroupLimit",
          "toId" : 24,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Window",
          "toId" : 23,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Filter",
          "toId" : 22,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Join",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Expand",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Expand",
          "toId" : 5,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Aggregate",
          "toId" : 4,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367]\n               +- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n                  +- Project [ss_net_profit#29, s_state#83, s_county#82]\n                     +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n                        :- Project [ss_store_sk#14, ss_net_profit#29]\n                        :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n                        :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n                        :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30])\n                        :     :     :  +- Project [d_date_sk#31]\n                        :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n                        :     +- LogicalQueryStage Project [d_date_sk#31], BroadcastQueryStage 0\n                        +- Join LeftSemi, (s_state#83 = s_state#314)\n                           :- Project [s_store_sk#59, s_county#82, s_state#83]\n                           :  +- Filter isnotnull(s_store_sk#59)\n                           :     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n                           +- Project [s_state#314]\n                              +- Filter (ranking#250 <= 5)\n                                 +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                                    +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5\n                                       +- Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314]\n                                          +- Project [ss_net_profit#288, s_state#314]\n                                             +- Join Inner, (s_store_sk#290 = ss_store_sk#273)\n                                                :- Project [ss_store_sk#273, ss_net_profit#288]\n                                                :  +- Join Inner, (d_date_sk#319 = ss_sold_date_sk#289)\n                                                :     :- Project [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289]\n                                                :     :  +- Filter ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289])\n                                                :     :     :  +- Project [d_date_sk#319]\n                                                :     :     :     +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                                                :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                                                :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#267,ss_item_sk#268,ss_customer_sk#269,ss_cdemo_sk#270,ss_hdemo_sk#271,ss_addr_sk#272,ss_store_sk#273,ss_promo_sk#274,ss_ticket_number#275L,ss_quantity#276,ss_wholesale_cost#277,ss_list_price#278,ss_sales_price#279,ss_ext_discount_amt#280,ss_ext_sales_price#281,ss_ext_wholesale_cost#282,ss_ext_list_price#283,ss_ext_tax#284,ss_coupon_amt#285,ss_net_paid#286,ss_net_paid_inc_tax#287,ss_net_profit#288,ss_sold_date_sk#289] parquet\n                                                :     +- LogicalQueryStage Project [d_date_sk#319], BroadcastQueryStage 2\n                                                +- LogicalQueryStage Project [s_store_sk#290, s_state#314], BroadcastQueryStage 3\n"
      },
      "IM" : {
        "inputSizeInBytes" : 83615039726,
        "inputRowCount" : 550092182
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 1,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227228937,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 24447,
        "IOBytes" : {
          "Total" : 471865022,
          "Details" : {
            "IR" : 471713654,
            "IW" : 0,
            "SR" : 75684,
            "SW" : 75684
          }
        }
      }
    },
    "2" : {
      "LQP" : {
        "operators" : {
          "34" : {
            "sign" : -1747060577,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#319] "
          },
          "12" : {
            "sign" : -288548948,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30]) "
          },
          "8" : {
            "sign" : -1876349985,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 37560447535,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#59 = ss_store_sk#14) "
          },
          "19" : {
            "sign" : 631921819,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#59, s_county#82, s_state#83] "
          },
          "23" : {
            "sign" : -908117851,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 2312525381882400,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (ranking#250 <= 5) "
          },
          "4" : {
            "sign" : 1222543076,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 158806397681,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "15" : {
            "sign" : 806171972,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 82656,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31)) "
          },
          "11" : {
            "sign" : -1024450876,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] "
          },
          "9" : {
            "sign" : -967047166,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1917516900400,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29] "
          },
          "33" : {
            "sign" : 1350045264,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#267, ss_item_sk#268, ss_customer_sk#269, ss_cdemo_sk#270, ss_hdemo_sk#271, ss_addr_sk#272, ss_store_sk#273, ss_promo_sk#274, ss_ticket_number#275L, ss_quantity#276, ss_wholesale_cost#277, ss_list_price#278, ss_sales_price#279, ss_ext_discount_amt#280, ss_ext_sales_price#281, ss_ext_wholesale_cost#282, ss_ext_list_price#283, ss_ext_tax#284, ss_coupon_amt#285, ss_net_paid#286, ss_net_paid_inc_tax#287, ss_net_profit#288, ss_sold_date_sk#289], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "22" : {
            "sign" : -1091448718,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1079178511545120,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_state#314] "
          },
          "26" : {
            "sign" : -919170863,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 2158357023090240,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314] "
          },
          "37" : {
            "sign" : -1964699841,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#319], BroadcastQueryStage 2 "
          },
          "13" : {
            "sign" : -503710878,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#8, ss_item_sk#9, ss_customer_sk#10, ss_cdemo_sk#11, ss_hdemo_sk#12, ss_addr_sk#13, ss_store_sk#14, ss_promo_sk#15, ss_ticket_number#16L, ss_quantity#17, ss_wholesale_cost#18, ss_list_price#19, ss_sales_price#20, ss_ext_discount_amt#21, ss_ext_sales_price#22, ss_ext_wholesale_cost#23, ss_ext_list_price#24, ss_ext_tax#25, ss_coupon_amt#26, ss_net_paid#27, ss_net_paid_inc_tax#28, ss_net_profit#29, ss_sold_date_sk#30], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "24" : {
            "sign" : -203359340,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 2312525381882400,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST] "
          },
          "35" : {
            "sign" : -720379420,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 82656,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319)) "
          },
          "16" : {
            "sign" : -1043254498,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#31, d_date_id#32, d_date#33, d_month_seq#34, d_week_seq#35, d_quarter_seq#36, d_year#37, d_dow#38, d_moy#39, d_dom#40, d_qoy#41, d_fy_year#42, d_fy_quarter_seq#43, d_fy_week_seq#44, d_day_name#45, d_quarter_name#46, d_holiday#47, d_weekend#48, d_following_holiday#49, d_first_dom#50, d_last_dom#51, d_same_day_ly#52, d_same_day_lq#53, d_current_day#54, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "5" : {
            "sign" : -666675049,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 151748335562,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367] "
          },
          "10" : {
            "sign" : -835972677,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2684523660560,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#31 = ss_sold_date_sk#30) "
          },
          "21" : {
            "sign" : 73744801,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#59, s_store_id#60, s_rec_start_date#61, s_rec_end_date#62, s_closed_date_sk#63, s_store_name#64, s_number_employees#65, s_floor_space#66, s_hours#67, s_manager#68, s_market_id#69, s_geography_class#70, s_market_desc#71, s_market_manager#72, s_division_id#73, s_division_name#74, s_company_id#75, s_company_name#76, s_street_number#77, s_street_name#78, s_street_type#79, s_suite_number#80, s_city#81, s_county#82, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "32" : {
            "sign" : 1061342824,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289]) "
          },
          "6" : {
            "sign" : 282260138,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Expand",
            "sizeInBytes" : 112928993907,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Expand Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] "
          },
          "36" : {
            "sign" : -1403770701,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#319, d_date_id#320, d_date#321, d_month_seq#322, d_week_seq#323, d_quarter_seq#324, d_year#325, d_dow#326, d_moy#327, d_dom#328, d_qoy#329, d_fy_year#330, d_fy_quarter_seq#331, d_fy_week_seq#332, d_day_name#333, d_quarter_name#334, d_holiday#335, d_weekend#336, d_following_holiday#337, d_first_dom#338, d_last_dom#339, d_same_day_ly#340, d_same_day_lq#341, d_current_day#342, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "1" : {
            "sign" : 231331557,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : -680408626,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#31], BroadcastQueryStage 0 "
          },
          "25" : {
            "sign" : 466225396,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.WindowGroupLimit",
            "sizeInBytes" : 2158357023090240,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) WindowGroupLimit Arguments: [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5 "
          },
          "14" : {
            "sign" : -1849171734,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#31] "
          },
          "31" : {
            "sign" : 1656499568,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289] "
          },
          "0" : {
            "sign" : 19796282,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -465917463,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#59) "
          },
          "27" : {
            "sign" : 760105960,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1387515229129440,
            "rowCount" : 38542089698040,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#288, s_state#314] "
          },
          "2" : {
            "sign" : 1087773200,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "38" : {
            "sign" : 734385352,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [s_store_sk#290, s_state#314], BroadcastQueryStage 3 "
          },
          "18" : {
            "sign" : -2139678312,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: LeftSemi, (s_state#83 = s_state#314) "
          },
          "30" : {
            "sign" : -1905409205,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2684523660560,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#319 = ss_sold_date_sk#289) "
          },
          "7" : {
            "sign" : 2046557183,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 32937623223,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#29, s_state#83, s_county#82] "
          },
          "29" : {
            "sign" : -392513008,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1917516900400,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#273, ss_net_profit#288] "
          },
          "3" : {
            "sign" : 664747423,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          },
          "28" : {
            "sign" : 1704394357,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 1695851946713760,
            "rowCount" : 38542089698040,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#290 = ss_store_sk#273) "
          }
        },
        "links" : [ {
          "fromId" : 13,
          "fromName" : "LogicalRelation",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalRelation",
          "toId" : 15,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Filter",
          "toId" : 14,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Project",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 12,
          "fromName" : "Filter",
          "toId" : 11,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Project",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Join",
          "toId" : 9,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Project",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "LogicalRelation",
          "toId" : 20,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Filter",
          "toId" : 19,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 33,
          "fromName" : "LogicalRelation",
          "toId" : 32,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 36,
          "fromName" : "LogicalRelation",
          "toId" : 35,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 35,
          "fromName" : "Filter",
          "toId" : 34,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 34,
          "fromName" : "Project",
          "toId" : 32,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 32,
          "fromName" : "Filter",
          "toId" : 31,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 31,
          "fromName" : "Project",
          "toId" : 30,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 37,
          "fromName" : "LogicalQueryStage",
          "toId" : 30,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 30,
          "fromName" : "Join",
          "toId" : 29,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 29,
          "fromName" : "Project",
          "toId" : 28,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 38,
          "fromName" : "LogicalQueryStage",
          "toId" : 28,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 28,
          "fromName" : "Join",
          "toId" : 27,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 27,
          "fromName" : "Project",
          "toId" : 26,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "Aggregate",
          "toId" : 25,
          "toName" : "WindowGroupLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "WindowGroupLimit",
          "toId" : 24,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Window",
          "toId" : 23,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Filter",
          "toId" : 22,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Join",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Expand",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Expand",
          "toId" : 5,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Aggregate",
          "toId" : 4,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367]\n               +- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n                  +- Project [ss_net_profit#29, s_state#83, s_county#82]\n                     +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n                        :- Project [ss_store_sk#14, ss_net_profit#29]\n                        :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n                        :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n                        :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30])\n                        :     :     :  +- Project [d_date_sk#31]\n                        :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n                        :     +- LogicalQueryStage Project [d_date_sk#31], BroadcastQueryStage 0\n                        +- Join LeftSemi, (s_state#83 = s_state#314)\n                           :- Project [s_store_sk#59, s_county#82, s_state#83]\n                           :  +- Filter isnotnull(s_store_sk#59)\n                           :     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n                           +- Project [s_state#314]\n                              +- Filter (ranking#250 <= 5)\n                                 +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                                    +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5\n                                       +- Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314]\n                                          +- Project [ss_net_profit#288, s_state#314]\n                                             +- Join Inner, (s_store_sk#290 = ss_store_sk#273)\n                                                :- Project [ss_store_sk#273, ss_net_profit#288]\n                                                :  +- Join Inner, (d_date_sk#319 = ss_sold_date_sk#289)\n                                                :     :- Project [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289]\n                                                :     :  +- Filter ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289])\n                                                :     :     :  +- Project [d_date_sk#319]\n                                                :     :     :     +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                                                :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                                                :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#267,ss_item_sk#268,ss_customer_sk#269,ss_cdemo_sk#270,ss_hdemo_sk#271,ss_addr_sk#272,ss_store_sk#273,ss_promo_sk#274,ss_ticket_number#275L,ss_quantity#276,ss_wholesale_cost#277,ss_list_price#278,ss_sales_price#279,ss_ext_discount_amt#280,ss_ext_sales_price#281,ss_ext_wholesale_cost#282,ss_ext_list_price#283,ss_ext_tax#284,ss_coupon_amt#285,ss_net_paid#286,ss_net_paid_inc_tax#287,ss_net_profit#288,ss_sold_date_sk#289] parquet\n                                                :     +- LogicalQueryStage Project [d_date_sk#319], BroadcastQueryStage 2\n                                                +- LogicalQueryStage Project [s_store_sk#290, s_state#314], BroadcastQueryStage 3\n"
      },
      "IM" : {
        "inputSizeInBytes" : 83617134654,
        "inputRowCount" : 550092240
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227230571,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 22813,
        "IOBytes" : {
          "Total" : 471752055,
          "Details" : {
            "IR" : 471600687,
            "IW" : 0,
            "SR" : 75684,
            "SW" : 75684
          }
        }
      }
    },
    "7" : {
      "LQP" : {
        "operators" : {
          "4" : {
            "sign" : -170326997,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 35363,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "5" : {
            "sign" : 657298154,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 33792,
            "rowCount" : 608,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367], HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[sum(UnscaledValue(ss_net_profit#29))]) "
          },
          "1" : {
            "sign" : -522396104,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 23968,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "0" : {
            "sign" : 644701973,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : 1155837055,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 23968,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "3" : {
            "sign" : 11625522,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 23968,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          }
        },
        "links" : [ {
          "fromId" : 5,
          "fromName" : "LogicalQueryStage",
          "toId" : 4,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- LogicalQueryStage Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367], HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[sum(UnscaledValue(ss_net_profit#29))])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 33792,
        "inputRowCount" : 608
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227252673,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 711,
        "IOBytes" : {
          "Total" : 55281,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 53798,
            "SW" : 1483
          }
        }
      }
    },
    "3" : {
      "LQP" : {
        "operators" : {
          "12" : {
            "sign" : -288548948,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 39926379296,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30]) "
          },
          "8" : {
            "sign" : -21721840,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 37560447535,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#59 = ss_store_sk#14) "
          },
          "19" : {
            "sign" : 631921819,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#59, s_county#82, s_state#83] "
          },
          "23" : {
            "sign" : -215504976,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 424,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (ranking#250 <= 5) "
          },
          "4" : {
            "sign" : -1337475797,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 158806397681,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "15" : {
            "sign" : 806171972,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 82656,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31)) "
          },
          "11" : {
            "sign" : -1024450876,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] "
          },
          "9" : {
            "sign" : -967047166,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 1917516900400,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29] "
          },
          "22" : {
            "sign" : -1099650659,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 197,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_state#314] "
          },
          "26" : {
            "sign" : -1123325026,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 396,
            "rowCount" : 9,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314], HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))]) "
          },
          "13" : {
            "sign" : -503710878,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 41806893656,
            "rowCount" : 275045353,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#8, ss_item_sk#9, ss_customer_sk#10, ss_cdemo_sk#11, ss_hdemo_sk#12, ss_addr_sk#13, ss_store_sk#14, ss_promo_sk#15, ss_ticket_number#16L, ss_quantity#17, ss_wholesale_cost#18, ss_list_price#19, ss_sales_price#20, ss_ext_discount_amt#21, ss_ext_sales_price#22, ss_ext_wholesale_cost#23, ss_ext_list_price#24, ss_ext_tax#25, ss_coupon_amt#26, ss_net_paid#27, ss_net_paid_inc_tax#28, ss_net_profit#29, ss_sold_date_sk#30], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "24" : {
            "sign" : -1353567877,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "sizeInBytes" : 424,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST] "
          },
          "16" : {
            "sign" : -1043254498,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 17970054,
            "rowCount" : 73049,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#31, d_date_id#32, d_date#33, d_month_seq#34, d_week_seq#35, d_quarter_seq#36, d_year#37, d_dow#38, d_moy#39, d_dom#40, d_qoy#41, d_fy_year#42, d_fy_quarter_seq#43, d_fy_week_seq#44, d_day_name#45, d_quarter_name#46, d_holiday#47, d_weekend#48, d_following_holiday#49, d_first_dom#50, d_last_dom#51, d_same_day_ly#52, d_same_day_lq#53, d_current_day#54, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "5" : {
            "sign" : -1176014018,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "sizeInBytes" : 151748335562,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367] "
          },
          "10" : {
            "sign" : -835972677,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 2684523660560,
            "rowCount" : 95875845020,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#31 = ss_sold_date_sk#30) "
          },
          "21" : {
            "sign" : 73744801,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#59, s_store_id#60, s_rec_start_date#61, s_rec_end_date#62, s_closed_date_sk#63, s_store_name#64, s_number_employees#65, s_floor_space#66, s_hours#67, s_manager#68, s_market_id#69, s_geography_class#70, s_market_desc#71, s_market_manager#72, s_division_id#73, s_division_name#74, s_company_id#75, s_company_name#76, s_street_number#77, s_street_name#78, s_street_type#79, s_suite_number#80, s_city#81, s_county#82, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "6" : {
            "sign" : -356097819,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Expand",
            "sizeInBytes" : 112928993907,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Expand Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] "
          },
          "1" : {
            "sign" : -358654160,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "17" : {
            "sign" : -680408626,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Project [d_date_sk#31], BroadcastQueryStage 0 "
          },
          "25" : {
            "sign" : 1504588801,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.WindowGroupLimit",
            "sizeInBytes" : 396,
            "rowCount" : 9,
            "isRuntime" : false,
            "predicate" : " (unknown) WindowGroupLimit Arguments: [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5 "
          },
          "14" : {
            "sign" : -1849171734,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#31] "
          },
          "0" : {
            "sign" : -65641451,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "20" : {
            "sign" : -465917463,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "sizeInBytes" : 192558,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#59) "
          },
          "2" : {
            "sign" : 1170863807,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "18" : {
            "sign" : 1998172509,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: LeftSemi, (s_state#83 = s_state#314) "
          },
          "7" : {
            "sign" : -264845290,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 32937623223,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#29, s_state#83, s_county#82] "
          },
          "3" : {
            "sign" : 1413303286,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          }
        },
        "links" : [ {
          "fromId" : 13,
          "fromName" : "LogicalRelation",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 16,
          "fromName" : "LogicalRelation",
          "toId" : 15,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 15,
          "fromName" : "Filter",
          "toId" : 14,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 14,
          "fromName" : "Project",
          "toId" : 12,
          "toName" : "Filter",
          "linkType" : "Subquery"
        }, {
          "fromId" : 12,
          "fromName" : "Filter",
          "toId" : 11,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 11,
          "fromName" : "Project",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 17,
          "fromName" : "LogicalQueryStage",
          "toId" : 10,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 10,
          "fromName" : "Join",
          "toId" : 9,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "Project",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 21,
          "fromName" : "LogicalRelation",
          "toId" : 20,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 20,
          "fromName" : "Filter",
          "toId" : 19,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 19,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 26,
          "fromName" : "LogicalQueryStage",
          "toId" : 25,
          "toName" : "WindowGroupLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 25,
          "fromName" : "WindowGroupLimit",
          "toId" : 24,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 24,
          "fromName" : "Window",
          "toId" : 23,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 23,
          "fromName" : "Filter",
          "toId" : 22,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 22,
          "fromName" : "Project",
          "toId" : 18,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 18,
          "fromName" : "Join",
          "toId" : 8,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "Join",
          "toId" : 7,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Project",
          "toId" : 6,
          "toName" : "Expand",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Expand",
          "toId" : 5,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Aggregate",
          "toId" : 4,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367]\n               +- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n                  +- Project [ss_net_profit#29, s_state#83, s_county#82]\n                     +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n                        :- Project [ss_store_sk#14, ss_net_profit#29]\n                        :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n                        :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n                        :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30])\n                        :     :     :  +- Project [d_date_sk#31]\n                        :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n                        :     +- LogicalQueryStage Project [d_date_sk#31], BroadcastQueryStage 0\n                        +- Join LeftSemi, (s_state#83 = s_state#314)\n                           :- Project [s_store_sk#59, s_county#82, s_state#83]\n                           :  +- Filter isnotnull(s_store_sk#59)\n                           :     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n                           +- Project [s_state#314]\n                              +- Filter (ranking#250 <= 5)\n                                 +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                                    +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5\n                                       +- LogicalQueryStage Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314], HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))])\n"
      },
      "IM" : {
        "inputSizeInBytes" : 41808138106,
        "inputRowCount" : 275046129
      },
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 16,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "StartTimeInMs" : 1702227230976,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "Objectives" : {
        "DurationInMs" : 22408,
        "IOBytes" : {
          "Total" : 471752055,
          "Details" : {
            "IR" : 471600687,
            "IW" : 0,
            "SR" : 75684,
            "SW" : 75684
          }
        }
      }
    }
  },
  "RuntimeQSs" : {
    "4" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -684488174,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 21306,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 21306,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: LeftSemi, (s_state#83 = s_state#314) "
          },
          "1" : {
            "sign" : 631921819,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 21306,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 21306,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#59, s_county#82, s_state#83] "
          },
          "2" : {
            "sign" : -465917463,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#59) "
          },
          "3" : {
            "sign" : 73744801,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#59, s_store_id#60, s_rec_start_date#61, s_rec_end_date#62, s_closed_date_sk#63, s_store_name#64, s_number_employees#65, s_floor_space#66, s_hours#67, s_manager#68, s_market_id#69, s_geography_class#70, s_market_desc#71, s_market_manager#72, s_division_id#73, s_division_name#74, s_company_id#75, s_company_name#76, s_street_number#77, s_street_name#78, s_street_type#79, s_suite_number#80, s_city#81, s_county#82, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "LogicalRelation",
          "toId" : 2,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Filter",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Join",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Join LeftSemi, (s_state#83 = s_state#314)\n:- Project [s_store_sk#59, s_county#82, s_state#83]\n:  +- Filter isnotnull(s_store_sk#59)\n:     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n+- Project [s_state#314]\n   +- Filter (ranking#250 <= 5)\n      +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n         +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5\n            +- Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314]\n               +- Project [ss_net_profit#288, s_state#314]\n                  +- Join Inner, (s_store_sk#290 = ss_store_sk#273)\n                     :- Project [ss_store_sk#273, ss_net_profit#288]\n                     :  +- Join Inner, (d_date_sk#319 = ss_sold_date_sk#289)\n                     :     :- Project [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289]\n                     :     :  +- Filter ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289])\n                     :     :     :  +- Project [d_date_sk#319]\n                     :     :     :     +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                     :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                     :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#267,ss_item_sk#268,ss_customer_sk#269,ss_cdemo_sk#270,ss_hdemo_sk#271,ss_addr_sk#272,ss_store_sk#273,ss_promo_sk#274,ss_ticket_number#275L,ss_quantity#276,ss_wholesale_cost#277,ss_list_price#278,ss_sales_price#279,ss_ext_discount_amt#280,ss_ext_sales_price#281,ss_ext_wholesale_cost#282,ss_ext_list_price#283,ss_ext_tax#284,ss_coupon_amt#285,ss_net_paid#286,ss_net_paid_inc_tax#287,ss_net_profit#288,ss_sold_date_sk#289] parquet\n                     :     +- Project [d_date_sk#319]\n                     :        +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                     :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                     +- Project [s_store_sk#290, s_state#314]\n                        +- Filter isnotnull(s_store_sk#290)\n                           +- Relation spark_catalog.tpcds_100.store[s_store_sk#290,s_store_id#291,s_rec_start_date#292,s_rec_end_date#293,s_closed_date_sk#294,s_store_name#295,s_number_employees#296,s_floor_space#297,s_hours#298,s_manager#299,s_market_id#300,s_geography_class#301,s_market_desc#302,s_market_manager#303,s_division_id#304,s_division_name#305,s_company_id#306,s_company_name#307,s_street_number#308,s_street_name#309,s_street_type#310,s_suite_number#311,s_city#312,s_county#313,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -177961020,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [s_state#83] Right keys [1]: [s_state#314] Join type: LeftSemi Join condition: None "
          },
          "1" : {
            "sign" : -1492032727,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [s_store_sk#59, s_county#82, s_state#83] Condition : isnotnull(s_store_sk#59) "
          },
          "2" : {
            "sign" : -1701400975,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 21306,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store Output [3]: [s_store_sk#59, s_county#82, s_state#83] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store] PushedFilters: [IsNotNull(s_store_sk)] ReadSchema: struct<s_store_sk:int,s_county:string,s_state:string> "
          },
          "3" : {
            "sign" : -295212302,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 33555456,
            "rowCount" : 9,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [1]: [s_state#314] Arguments: 5 "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "BroadcastQueryStage",
          "toId" : 0,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "BroadcastHashJoin [s_state#83], [s_state#314], LeftSemi, BuildRight, false\n:- Filter isnotnull(s_store_sk#59)\n:  +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#59,s_county#82,s_state#83] Batched: true, DataFilters: [isnotnull(s_store_sk#59)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_county:string,s_state:string>\n+- BroadcastQueryStage 5\n   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=1225]\n      +- *(6) Project [s_state#314]\n         +- *(6) Filter (ranking#250 <= 5)\n            +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n               +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5, Final\n                  +- *(5) Sort [s_state#314 ASC NULLS FIRST, _w0#260 DESC NULLS LAST], false, 0\n                     +- *(5) HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, _w0#260, s_state#314])\n                        +- AQEShuffleRead coalesced\n                           +- ShuffleQueryStage 4\n                              +- Exchange hashpartitioning(s_state#314, 200), ENSURE_REQUIREMENTS, [plan_id=867]\n                                 +- *(4) HashAggregate(keys=[s_state#314], functions=[partial_sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, sum#394L])\n                                    +- *(4) Project [ss_net_profit#288, s_state#314]\n                                       +- *(4) BroadcastHashJoin [ss_store_sk#273], [s_store_sk#290], Inner, BuildRight, false\n                                          :- *(4) Project [ss_store_sk#273, ss_net_profit#288]\n                                          :  +- *(4) BroadcastHashJoin [ss_sold_date_sk#289], [d_date_sk#319], Inner, BuildRight, false\n                                          :     :- *(4) Filter isnotnull(ss_store_sk#273)\n                                          :     :  +- *(4) ColumnarToRow\n                                          :     :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#273,ss_net_profit#288,ss_sold_date_sk#289] Batched: true, DataFilters: [isnotnull(ss_store_sk#273)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#289), dynamicpruningexpression(ss_sold_date_sk#289 IN dynamicpruning#3..., PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n                                          :     :           +- SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n                                          :     :              +- AdaptiveSparkPlan isFinalPlan=true\n                                                                  +- == Final Plan ==\n                                                                     BroadcastQueryStage 1\n                                                                     +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                                                  +- == Initial Plan ==\n                                                                     BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=822]\n                                                                     +- Project [d_date_sk#319]\n                                                                        +- Filter (((isnotnull(d_month_seq#322) AND (d_month_seq#322 >= 1212)) AND (d_month_seq#322 <= 1223)) AND isnotnull(d_date_sk#319))\n                                                                           +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_month_seq#322] Batched: true, DataFilters: [isnotnull(d_month_seq#322), (d_month_seq#322 >= 1212), (d_month_seq#322 <= 1223), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n                                          :     +- BroadcastQueryStage 2\n                                          :        +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                          +- BroadcastQueryStage 3\n                                             +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=388]\n                                                +- *(3) Filter isnotnull(s_store_sk#290)\n                                                   +- *(3) ColumnarToRow\n                                                      +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#290,s_state#314] Batched: true, DataFilters: [isnotnull(s_store_sk#290)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 33576762,
        "inputRowCount" : 411
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 4,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 6 ],
      "Objectives" : {
        "DurationInMs" : 95,
        "TotalTasksDurationInMs" : 91,
        "IOBytes" : {
          "Total" : 14779,
          "Details" : {
            "IR" : 14779,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "5" : {
      "QSLogical" : {
        "operators" : {
          "8" : {
            "sign" : -503710878,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              },
              "compileTime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#8, ss_item_sk#9, ss_customer_sk#10, ss_cdemo_sk#11, ss_hdemo_sk#12, ss_addr_sk#13, ss_store_sk#14, ss_promo_sk#15, ss_ticket_number#16L, ss_quantity#17, ss_wholesale_cost#18, ss_list_price#19, ss_sales_price#20, ss_ext_discount_amt#21, ss_ext_sales_price#22, ss_ext_wholesale_cost#23, ss_ext_list_price#24, ss_ext_tax#25, ss_coupon_amt#26, ss_net_paid#27, ss_net_paid_inc_tax#28, ss_net_profit#29, ss_sold_date_sk#30], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "4" : {
            "sign" : -458233930,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 5310811700,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 5310811700,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29] "
          },
          "5" : {
            "sign" : -1155235991,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 7435136380,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 7435136380,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#31 = ss_sold_date_sk#30) "
          },
          "6" : {
            "sign" : -1024450876,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] "
          },
          "1" : {
            "sign" : 576247848,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Expand",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 112928993907,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 112928993907,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Expand Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] "
          },
          "0" : {
            "sign" : 1405866361,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 151748335562,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 151748335562,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367] "
          },
          "2" : {
            "sign" : -1123692575,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 32937623223,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 32937623223,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#29, s_state#83, s_county#82] "
          },
          "7" : {
            "sign" : -288548948,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30]) "
          },
          "3" : {
            "sign" : 968014685,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 37560447535,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 37560447535,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#59 = ss_store_sk#14) "
          }
        },
        "links" : [ {
          "fromId" : 8,
          "fromName" : "LogicalRelation",
          "toId" : 7,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "Filter",
          "toId" : 6,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Project",
          "toId" : 5,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Join",
          "toId" : 4,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Project",
          "toId" : 3,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Join",
          "toId" : 2,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Project",
          "toId" : 1,
          "toName" : "Expand",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Expand",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367]\n+- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n   +- Project [ss_net_profit#29, s_state#83, s_county#82]\n      +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n         :- Project [ss_store_sk#14, ss_net_profit#29]\n         :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n         :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n         :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30])\n         :     :     :  +- Project [d_date_sk#31]\n         :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n         :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n         :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n         :     +- Project [d_date_sk#31]\n         :        +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n         :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n         +- Join LeftSemi, (s_state#83 = s_state#314)\n            :- Project [s_store_sk#59, s_county#82, s_state#83]\n            :  +- Filter isnotnull(s_store_sk#59)\n            :     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n            +- Project [s_state#314]\n               +- Filter (ranking#250 <= 5)\n                  +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                     +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5\n                        +- Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314]\n                           +- Project [ss_net_profit#288, s_state#314]\n                              +- Join Inner, (s_store_sk#290 = ss_store_sk#273)\n                                 :- Project [ss_store_sk#273, ss_net_profit#288]\n                                 :  +- Join Inner, (d_date_sk#319 = ss_sold_date_sk#289)\n                                 :     :- Project [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289]\n                                 :     :  +- Filter ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289])\n                                 :     :     :  +- Project [d_date_sk#319]\n                                 :     :     :     +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                                 :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                                 :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#267,ss_item_sk#268,ss_customer_sk#269,ss_cdemo_sk#270,ss_hdemo_sk#271,ss_addr_sk#272,ss_store_sk#273,ss_promo_sk#274,ss_ticket_number#275L,ss_quantity#276,ss_wholesale_cost#277,ss_list_price#278,ss_sales_price#279,ss_ext_discount_amt#280,ss_ext_sales_price#281,ss_ext_wholesale_cost#282,ss_ext_list_price#283,ss_ext_tax#284,ss_coupon_amt#285,ss_net_paid#286,ss_net_paid_inc_tax#287,ss_net_profit#288,ss_sold_date_sk#289] parquet\n                                 :     +- Project [d_date_sk#319]\n                                 :        +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                                 :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                                 +- Project [s_store_sk#290, s_state#314]\n                                    +- Filter isnotnull(s_store_sk#290)\n                                       +- Relation spark_catalog.tpcds_100.store[s_store_sk#290,s_store_id#291,s_rec_start_date#292,s_rec_end_date#293,s_closed_date_sk#294,s_store_name#295,s_number_employees#296,s_floor_space#297,s_hours#298,s_manager#299,s_market_id#300,s_geography_class#301,s_market_desc#302,s_market_manager#303,s_division_id#304,s_division_name#305,s_company_id#306,s_company_name#307,s_street_number#308,s_street_name#309,s_street_type#310,s_suite_number#311,s_city#312,s_county#313,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "8" : {
            "sign" : -837577231,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [1]: [d_date_sk#31] Arguments: 0 "
          },
          "4" : {
            "sign" : -26860905,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 5310811700,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [2]: [ss_store_sk#14, ss_net_profit#29] Input [4]: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30, d_date_sk#31] "
          },
          "9" : {
            "sign" : -327366171,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [3]: [s_store_sk#59, s_county#82, s_state#83] Arguments: 6 "
          },
          "5" : {
            "sign" : 589982172,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 7435136380,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_sold_date_sk#30] Right keys [1]: [d_date_sk#31] Join type: Inner Join condition: None "
          },
          "6" : {
            "sign" : -1327736104,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] Condition : isnotnull(ss_store_sk#14) "
          },
          "1" : {
            "sign" : 1214181142,
            "className" : "org.apache.spark.sql.execution.ExpandExec",
            "sizeInBytes" : 112928993907,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Expand Input [3]: [ss_net_profit#29, s_state#83, s_county#82] Arguments: [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] "
          },
          "0" : {
            "sign" : -178965705,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 151748335562,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [4]: [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L] Keys [3]: [s_state#352, s_county#353, spark_grouping_id#351L] Functions [1]: [partial_sum(UnscaledValue(ss_net_profit#29))] Aggregate Attributes [1]: [sum#391L] Results [4]: [s_state#352, s_county#353, spark_grouping_id#351L, sum#392L] "
          },
          "2" : {
            "sign" : 1643028997,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 32937623223,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [3]: [ss_net_profit#29, s_state#83, s_county#82] Input [5]: [ss_store_sk#14, ss_net_profit#29, s_store_sk#59, s_county#82, s_state#83] "
          },
          "7" : {
            "sign" : -1176224280,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [3]: [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales/ss_sold_date_sk=2450816, ... 1822 entries] PartitionFilters: [isnotnull(ss_sold_date_sk#30), dynamicpruningexpression(ss_sold_date_sk#30 IN dynamicpruning#376)] PushedFilters: [IsNotNull(ss_store_sk)] ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)> "
          },
          "3" : {
            "sign" : 807967499,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 37560447535,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_store_sk#14] Right keys [1]: [s_store_sk#59] Join type: Inner Join condition: None "
          }
        },
        "links" : [ {
          "fromId" : 7,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 6,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Filter",
          "toId" : 5,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "BroadcastQueryStage",
          "toId" : 5,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "BroadcastHashJoin",
          "toId" : 4,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Project",
          "toId" : 3,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 9,
          "fromName" : "BroadcastQueryStage",
          "toId" : 3,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "BroadcastHashJoin",
          "toId" : 2,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Project",
          "toId" : 1,
          "toName" : "Expand",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Expand",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[partial_sum(UnscaledValue(ss_net_profit#29))], output=[s_state#352, s_county#353, spark_grouping_id#351L, sum#392L])\n+- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n   +- Project [ss_net_profit#29, s_state#83, s_county#82]\n      +- BroadcastHashJoin [ss_store_sk#14], [s_store_sk#59], Inner, BuildRight, false\n         :- Project [ss_store_sk#14, ss_net_profit#29]\n         :  +- BroadcastHashJoin [ss_sold_date_sk#30], [d_date_sk#31], Inner, BuildRight, false\n         :     :- Filter isnotnull(ss_store_sk#14)\n         :     :  +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#14,ss_net_profit#29,ss_sold_date_sk#30] Batched: true, DataFilters: [isnotnull(ss_store_sk#14)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#30), dynamicpruningexpression(ss_sold_date_sk#30 IN dynamicpruning#376)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n         :     :        +- ReusedSubquery SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n         :     +- BroadcastQueryStage 0\n         :        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n         :           +- *(1) Project [d_date_sk#31]\n         :              +- *(1) Filter (((isnotnull(d_month_seq#34) AND (d_month_seq#34 >= 1212)) AND (d_month_seq#34 <= 1223)) AND isnotnull(d_date_sk#31))\n         :                 +- *(1) ColumnarToRow\n         :                    +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_month_seq#34] Batched: true, DataFilters: [isnotnull(d_month_seq#34), (d_month_seq#34 >= 1212), (d_month_seq#34 <= 1223), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n         +- BroadcastQueryStage 6\n            +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1367]\n               +- *(7) BroadcastHashJoin [s_state#83], [s_state#314], LeftSemi, BuildRight, false\n                  :- *(7) Filter isnotnull(s_store_sk#59)\n                  :  +- *(7) ColumnarToRow\n                  :     +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#59,s_county#82,s_state#83] Batched: true, DataFilters: [isnotnull(s_store_sk#59)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_county:string,s_state:string>\n                  +- BroadcastQueryStage 5\n                     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=1225]\n                        +- *(6) Project [s_state#314]\n                           +- *(6) Filter (ranking#250 <= 5)\n                              +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                                 +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5, Final\n                                    +- *(5) Sort [s_state#314 ASC NULLS FIRST, _w0#260 DESC NULLS LAST], false, 0\n                                       +- *(5) HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, _w0#260, s_state#314])\n                                          +- AQEShuffleRead coalesced\n                                             +- ShuffleQueryStage 4\n                                                +- Exchange hashpartitioning(s_state#314, 200), ENSURE_REQUIREMENTS, [plan_id=867]\n                                                   +- *(4) HashAggregate(keys=[s_state#314], functions=[partial_sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, sum#394L])\n                                                      +- *(4) Project [ss_net_profit#288, s_state#314]\n                                                         +- *(4) BroadcastHashJoin [ss_store_sk#273], [s_store_sk#290], Inner, BuildRight, false\n                                                            :- *(4) Project [ss_store_sk#273, ss_net_profit#288]\n                                                            :  +- *(4) BroadcastHashJoin [ss_sold_date_sk#289], [d_date_sk#319], Inner, BuildRight, false\n                                                            :     :- *(4) Filter isnotnull(ss_store_sk#273)\n                                                            :     :  +- *(4) ColumnarToRow\n                                                            :     :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#273,ss_net_profit#288,ss_sold_date_sk#289] Batched: true, DataFilters: [isnotnull(ss_store_sk#273)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#289), dynamicpruningexpression(ss_sold_date_sk#289 IN dynamicpruning#3..., PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n                                                            :     :           +- SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n                                                            :     :              +- AdaptiveSparkPlan isFinalPlan=true\n                                                                                    +- == Final Plan ==\n                                                                                       BroadcastQueryStage 1\n                                                                                       +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                                                                    +- == Initial Plan ==\n                                                                                       BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=822]\n                                                                                       +- Project [d_date_sk#319]\n                                                                                          +- Filter (((isnotnull(d_month_seq#322) AND (d_month_seq#322 >= 1212)) AND (d_month_seq#322 <= 1223)) AND isnotnull(d_date_sk#319))\n                                                                                             +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_month_seq#322] Batched: true, DataFilters: [isnotnull(d_month_seq#322), (d_month_seq#322 >= 1212), (d_month_seq#322 <= 1223), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n                                                            :     +- BroadcastQueryStage 2\n                                                            :        +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                                            +- BroadcastQueryStage 3\n                                                               +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=388]\n                                                                  +- *(3) Filter isnotnull(s_store_sk#290)\n                                                                     +- *(3) ColumnarToRow\n                                                                        +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#290,s_state#314] Batched: true, DataFilters: [isnotnull(s_store_sk#290)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 6306268440,
        "inputRowCount" : 262674315
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 5,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 7 ],
      "Objectives" : {
        "DurationInMs" : 2278,
        "TotalTasksDurationInMs" : 32839,
        "IOBytes" : {
          "Total" : 235845269,
          "Details" : {
            "IR" : 235792954,
            "IW" : 0,
            "SR" : 0,
            "SW" : 52315
          }
        }
      }
    },
    "6" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 657298154,
            "className" : "org.apache.spark.sql.execution.adaptive.LogicalQueryStage",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 33792,
                "rowCount" : 608
              },
              "compileTime" : {
                "sizeInBytes" : 151748335562,
                "rowCount" : -1
              }
            },
            "isRuntime" : true,
            "predicate" : " (unknown) LogicalQueryStage Arguments: Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367], HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[sum(UnscaledValue(ss_net_profit#29))]) "
          }
        },
        "links" : [ ],
        "rawPlan" : "LogicalQueryStage Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367], HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[sum(UnscaledValue(ss_net_profit#29))])\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -232656608,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 33792,
            "rowCount" : 608,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [4]: [s_state#352, s_county#353, spark_grouping_id#351L, sum#392L] Keys [3]: [s_state#352, s_county#353, spark_grouping_id#351L] Functions [1]: [sum(UnscaledValue(ss_net_profit#29))] Aggregate Attributes [1]: [sum(UnscaledValue(ss_net_profit#29))#347L] Results [7]: [MakeDecimal(sum(UnscaledValue(ss_net_profit#29))#347L,17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29))#347L,17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367] "
          },
          "1" : {
            "sign" : -2109704504,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 151748335562,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [4]: [s_state#352, s_county#353, spark_grouping_id#351L, sum#392L] Arguments: 7 "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "ShuffleQueryStage",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[sum(UnscaledValue(ss_net_profit#29))], output=[total_sum#246, s_state#352, s_county#353, lochierarchy#247, _w0#362, _w1#366, _w2#367])\n+- ShuffleQueryStage 7\n   +- Exchange hashpartitioning(s_state#352, s_county#353, spark_grouping_id#351L, 200), ENSURE_REQUIREMENTS, [plan_id=1529]\n      +- *(8) HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[partial_sum(UnscaledValue(ss_net_profit#29))], output=[s_state#352, s_county#353, spark_grouping_id#351L, sum#392L])\n         +- *(8) Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n            +- *(8) Project [ss_net_profit#29, s_state#83, s_county#82]\n               +- *(8) BroadcastHashJoin [ss_store_sk#14], [s_store_sk#59], Inner, BuildRight, false\n                  :- *(8) Project [ss_store_sk#14, ss_net_profit#29]\n                  :  +- *(8) BroadcastHashJoin [ss_sold_date_sk#30], [d_date_sk#31], Inner, BuildRight, false\n                  :     :- *(8) Filter isnotnull(ss_store_sk#14)\n                  :     :  +- *(8) ColumnarToRow\n                  :     :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#14,ss_net_profit#29,ss_sold_date_sk#30] Batched: true, DataFilters: [isnotnull(ss_store_sk#14)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#30), dynamicpruningexpression(ss_sold_date_sk#30 IN dynamicpruning#376)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n                  :     :           +- ReusedSubquery SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n                  :     +- BroadcastQueryStage 0\n                  :        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                  :           +- *(1) Project [d_date_sk#31]\n                  :              +- *(1) Filter (((isnotnull(d_month_seq#34) AND (d_month_seq#34 >= 1212)) AND (d_month_seq#34 <= 1223)) AND isnotnull(d_date_sk#31))\n                  :                 +- *(1) ColumnarToRow\n                  :                    +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_month_seq#34] Batched: true, DataFilters: [isnotnull(d_month_seq#34), (d_month_seq#34 >= 1212), (d_month_seq#34 <= 1223), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n                  +- BroadcastQueryStage 6\n                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1367]\n                        +- *(7) BroadcastHashJoin [s_state#83], [s_state#314], LeftSemi, BuildRight, false\n                           :- *(7) Filter isnotnull(s_store_sk#59)\n                           :  +- *(7) ColumnarToRow\n                           :     +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#59,s_county#82,s_state#83] Batched: true, DataFilters: [isnotnull(s_store_sk#59)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_county:string,s_state:string>\n                           +- BroadcastQueryStage 5\n                              +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=1225]\n                                 +- *(6) Project [s_state#314]\n                                    +- *(6) Filter (ranking#250 <= 5)\n                                       +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                                          +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5, Final\n                                             +- *(5) Sort [s_state#314 ASC NULLS FIRST, _w0#260 DESC NULLS LAST], false, 0\n                                                +- *(5) HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, _w0#260, s_state#314])\n                                                   +- AQEShuffleRead coalesced\n                                                      +- ShuffleQueryStage 4\n                                                         +- Exchange hashpartitioning(s_state#314, 200), ENSURE_REQUIREMENTS, [plan_id=867]\n                                                            +- *(4) HashAggregate(keys=[s_state#314], functions=[partial_sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, sum#394L])\n                                                               +- *(4) Project [ss_net_profit#288, s_state#314]\n                                                                  +- *(4) BroadcastHashJoin [ss_store_sk#273], [s_store_sk#290], Inner, BuildRight, false\n                                                                     :- *(4) Project [ss_store_sk#273, ss_net_profit#288]\n                                                                     :  +- *(4) BroadcastHashJoin [ss_sold_date_sk#289], [d_date_sk#319], Inner, BuildRight, false\n                                                                     :     :- *(4) Filter isnotnull(ss_store_sk#273)\n                                                                     :     :  +- *(4) ColumnarToRow\n                                                                     :     :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#273,ss_net_profit#288,ss_sold_date_sk#289] Batched: true, DataFilters: [isnotnull(ss_store_sk#273)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#289), dynamicpruningexpression(ss_sold_date_sk#289 IN dynamicpruning#3..., PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n                                                                     :     :           +- SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n                                                                     :     :              +- AdaptiveSparkPlan isFinalPlan=true\n                                                                                             +- == Final Plan ==\n                                                                                                BroadcastQueryStage 1\n                                                                                                +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                                                                             +- == Initial Plan ==\n                                                                                                BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=822]\n                                                                                                +- Project [d_date_sk#319]\n                                                                                                   +- Filter (((isnotnull(d_month_seq#322) AND (d_month_seq#322 >= 1212)) AND (d_month_seq#322 <= 1223)) AND isnotnull(d_date_sk#319))\n                                                                                                      +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_month_seq#322] Batched: true, DataFilters: [isnotnull(d_month_seq#322), (d_month_seq#322 >= 1212), (d_month_seq#322 <= 1223), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n                                                                     :     +- BroadcastQueryStage 2\n                                                                     :        +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                                                     +- BroadcastQueryStage 3\n                                                                        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=388]\n                                                                           +- *(3) Filter isnotnull(s_store_sk#290)\n                                                                              +- *(3) ColumnarToRow\n                                                                                 +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#290,s_state#314] Batched: true, DataFilters: [isnotnull(s_store_sk#290)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 33792,
        "inputRowCount" : 608
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "1" : [ 0, 0, 0, 0, 0, 0, 0, 2816, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2816, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2816, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3392, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2816, 0, 0, 0, 0, 2816, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3392, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2112, 0, 0, 0, 0, 0, 0, 0, 3392, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2816, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3744, 0, 0, 0, 0, 0, 3392, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3392, 5472, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2816, 0, 0, 0, 0, 0, 3392, 0, 0, 2816, 0, 0, 0, 0 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 6,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 9 ],
      "Objectives" : {
        "DurationInMs" : 203,
        "TotalTasksDurationInMs" : 195,
        "IOBytes" : {
          "Total" : 53798,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 52315,
            "SW" : 1483
          }
        }
      }
    },
    "1" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -158578416,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 10452,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 10452,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_store_sk#290, s_state#314] "
          },
          "1" : {
            "sign" : -652334023,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: isnotnull(s_store_sk#290) "
          },
          "2" : {
            "sign" : -229285394,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              },
              "compileTime" : {
                "sizeInBytes" : 192558,
                "rowCount" : 402
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [s_store_sk#290, s_store_id#291, s_rec_start_date#292, s_rec_end_date#293, s_closed_date_sk#294, s_store_name#295, s_number_employees#296, s_floor_space#297, s_hours#298, s_manager#299, s_market_id#300, s_geography_class#301, s_market_desc#302, s_market_manager#303, s_division_id#304, s_division_name#305, s_company_id#306, s_company_name#307, s_street_number#308, s_street_name#309, s_street_type#310, s_suite_number#311, s_city#312, s_county#313, ... 5 more fields], `spark_catalog`.`tpcds_100`.`store`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_store_sk#290, s_state#314]\n+- Filter isnotnull(s_store_sk#290)\n   +- Relation spark_catalog.tpcds_100.store[s_store_sk#290,s_store_id#291,s_rec_start_date#292,s_rec_end_date#293,s_closed_date_sk#294,s_store_name#295,s_number_employees#296,s_floor_space#297,s_hours#298,s_manager#299,s_market_id#300,s_geography_class#301,s_market_desc#302,s_market_manager#303,s_division_id#304,s_division_name#305,s_company_id#306,s_company_name#307,s_street_number#308,s_street_name#309,s_street_type#310,s_suite_number#311,s_city#312,s_county#313,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : 159131643,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 10452,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [s_store_sk#290, s_state#314] Condition : isnotnull(s_store_sk#290) "
          },
          "1" : {
            "sign" : 447728432,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 10452,
            "rowCount" : 402,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store Output [2]: [s_store_sk#290, s_state#314] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store] PushedFilters: [IsNotNull(s_store_sk)] ReadSchema: struct<s_store_sk:int,s_state:string> "
          }
        },
        "links" : [ {
          "fromId" : 1,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store",
          "toId" : 0,
          "toName" : "Filter",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Filter isnotnull(s_store_sk#290)\n+- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#290,s_state#314] Batched: true, DataFilters: [isnotnull(s_store_sk#290)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 10452,
        "inputRowCount" : 402
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 1,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 1 ],
      "Objectives" : {
        "DurationInMs" : 1548,
        "TotalTasksDurationInMs" : 1535,
        "IOBytes" : {
          "Total" : 14365,
          "Details" : {
            "IR" : 14365,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "0" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : -1849171734,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 4032,
                "rowCount" : 336
              },
              "compileTime" : {
                "sizeInBytes" : 4032,
                "rowCount" : 336
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [d_date_sk#31] "
          },
          "1" : {
            "sign" : 806171972,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 82656,
                "rowCount" : 336
              },
              "compileTime" : {
                "sizeInBytes" : 82656,
                "rowCount" : 336
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31)) "
          },
          "2" : {
            "sign" : -1043254498,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              },
              "compileTime" : {
                "sizeInBytes" : 17970054,
                "rowCount" : 73049
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [d_date_sk#31, d_date_id#32, d_date#33, d_month_seq#34, d_week_seq#35, d_quarter_seq#36, d_year#37, d_dow#38, d_moy#39, d_dom#40, d_qoy#41, d_fy_year#42, d_fy_quarter_seq#43, d_fy_week_seq#44, d_day_name#45, d_quarter_name#46, d_holiday#47, d_weekend#48, d_following_holiday#49, d_first_dom#50, d_last_dom#51, d_same_day_ly#52, d_same_day_lq#53, d_current_day#54, ... 4 more fields], `spark_catalog`.`tpcds_100`.`date_dim`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "LogicalRelation",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_date_sk#31]\n+- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n   +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "0" : {
            "sign" : -1411973247,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [d_date_sk#31] Input [2]: [d_date_sk#31, d_month_seq#34] "
          },
          "1" : {
            "sign" : 769526331,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [2]: [d_date_sk#31, d_month_seq#34] Condition : (((isnotnull(d_month_seq#34) AND (d_month_seq#34 >= 1212)) AND (d_month_seq#34 <= 1223)) AND isnotnull(d_date_sk#31)) "
          },
          "2" : {
            "sign" : -1198698907,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 4032,
            "rowCount" : 336,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.date_dim Output [2]: [d_date_sk#31, d_month_seq#34] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim] PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223), IsNotNull(d_date_sk)] ReadSchema: struct<d_date_sk:int,d_month_seq:int> "
          }
        },
        "links" : [ {
          "fromId" : 2,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.date_dim",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [d_date_sk#31]\n+- Filter (((isnotnull(d_month_seq#34) AND (d_month_seq#34 >= 1212)) AND (d_month_seq#34 <= 1223)) AND isnotnull(d_date_sk#31))\n   +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_month_seq#34] Batched: true, DataFilters: [isnotnull(d_month_seq#34), (d_month_seq#34 >= 1212), (d_month_seq#34 <= 1223), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 4032,
        "inputRowCount" : 336
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 0,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 2 ],
      "Objectives" : {
        "DurationInMs" : 3202,
        "TotalTasksDurationInMs" : 3193,
        "IOBytes" : {
          "Total" : 112967,
          "Details" : {
            "IR" : 112967,
            "IW" : 0,
            "SR" : 0,
            "SW" : 0
          }
        }
      }
    },
    "2" : {
      "QSLogical" : {
        "operators" : {
          "4" : {
            "sign" : -1932176107,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 7435136380,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 7435136380,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (d_date_sk#319 = ss_sold_date_sk#289) "
          },
          "5" : {
            "sign" : 1656499568,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 6304165152,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289] "
          },
          "6" : {
            "sign" : 1061342824,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              },
              "compileTime" : {
                "sizeInBytes" : 39926379296,
                "rowCount" : 262673548
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289]) "
          },
          "1" : {
            "sign" : -1502633790,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 17335591170,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 17335591170,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_net_profit#288, s_state#314] "
          },
          "0" : {
            "sign" : -536821855,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Aggregate",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 396,
                "rowCount" : 9
              },
              "compileTime" : {
                "sizeInBytes" : 396,
                "rowCount" : 9
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Aggregate Arguments: [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314] "
          },
          "2" : {
            "sign" : -1361674883,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Join",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 21958415482,
                "rowCount" : 577853039
              },
              "compileTime" : {
                "sizeInBytes" : 21958415482,
                "rowCount" : 577853039
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Join Arguments: Inner, (s_store_sk#290 = ss_store_sk#273) "
          },
          "7" : {
            "sign" : 1350045264,
            "className" : "org.apache.spark.sql.execution.datasources.LogicalRelation",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              },
              "compileTime" : {
                "sizeInBytes" : 41806893656,
                "rowCount" : 275045353
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LogicalRelation Arguments: parquet, [ss_sold_time_sk#267, ss_item_sk#268, ss_customer_sk#269, ss_cdemo_sk#270, ss_hdemo_sk#271, ss_addr_sk#272, ss_store_sk#273, ss_promo_sk#274, ss_ticket_number#275L, ss_quantity#276, ss_wholesale_cost#277, ss_list_price#278, ss_sales_price#279, ss_ext_discount_amt#280, ss_ext_sales_price#281, ss_ext_wholesale_cost#282, ss_ext_list_price#283, ss_ext_tax#284, ss_coupon_amt#285, ss_net_paid#286, ss_net_paid_inc_tax#287, ss_net_profit#288, ss_sold_date_sk#289], `spark_catalog`.`tpcds_100`.`store_sales`, org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, false "
          },
          "3" : {
            "sign" : -1482912338,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 5310811700,
                "rowCount" : 265540585
              },
              "compileTime" : {
                "sizeInBytes" : 5310811700,
                "rowCount" : 265540585
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [ss_store_sk#273, ss_net_profit#288] "
          }
        },
        "links" : [ {
          "fromId" : 7,
          "fromName" : "LogicalRelation",
          "toId" : 6,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 6,
          "fromName" : "Filter",
          "toId" : 5,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Project",
          "toId" : 4,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Join",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Join",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Join",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "Aggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314]\n+- Project [ss_net_profit#288, s_state#314]\n   +- Join Inner, (s_store_sk#290 = ss_store_sk#273)\n      :- Project [ss_store_sk#273, ss_net_profit#288]\n      :  +- Join Inner, (d_date_sk#319 = ss_sold_date_sk#289)\n      :     :- Project [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289]\n      :     :  +- Filter ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289])\n      :     :     :  +- Project [d_date_sk#319]\n      :     :     :     +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n      :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n      :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#267,ss_item_sk#268,ss_customer_sk#269,ss_cdemo_sk#270,ss_hdemo_sk#271,ss_addr_sk#272,ss_store_sk#273,ss_promo_sk#274,ss_ticket_number#275L,ss_quantity#276,ss_wholesale_cost#277,ss_list_price#278,ss_sales_price#279,ss_ext_discount_amt#280,ss_ext_sales_price#281,ss_ext_wholesale_cost#282,ss_ext_list_price#283,ss_ext_tax#284,ss_coupon_amt#285,ss_net_paid#286,ss_net_paid_inc_tax#287,ss_net_profit#288,ss_sold_date_sk#289] parquet\n      :     +- Project [d_date_sk#319]\n      :        +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n      :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n      +- Project [s_store_sk#290, s_state#314]\n         +- Filter isnotnull(s_store_sk#290)\n            +- Relation spark_catalog.tpcds_100.store[s_store_sk#290,s_store_id#291,s_rec_start_date#292,s_rec_end_date#293,s_closed_date_sk#294,s_store_name#295,s_number_employees#296,s_floor_space#297,s_hours#298,s_manager#299,s_market_id#300,s_geography_class#301,s_market_desc#302,s_market_manager#303,s_division_id#304,s_division_name#305,s_company_id#306,s_company_name#307,s_street_number#308,s_street_name#309,s_street_type#310,s_suite_number#311,s_city#312,s_county#313,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "8" : {
            "sign" : 1061583653,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051792,
            "rowCount" : 402,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [2]: [s_store_sk#290, s_state#314] Arguments: 3 "
          },
          "4" : {
            "sign" : -200326493,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 7435136380,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_sold_date_sk#289] Right keys [1]: [d_date_sk#319] Join type: Inner Join condition: None "
          },
          "5" : {
            "sign" : -32019318,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [3]: [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289] Condition : isnotnull(ss_store_sk#273) "
          },
          "6" : {
            "sign" : -930129779,
            "className" : "org.apache.spark.sql.execution.FileSourceScanExec",
            "sizeInBytes" : 6304165152,
            "rowCount" : 262673548,
            "isRuntime" : false,
            "predicate" : " (unknown) Scan parquet spark_catalog.tpcds_100.store_sales Output [3]: [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289] Batched: true Location: InMemoryFileIndex [hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_sales/ss_sold_date_sk=2450816, ... 1822 entries] PartitionFilters: [isnotnull(ss_sold_date_sk#289), dynamicpruningexpression(ss_sold_date_sk#289 IN dynamicpruning#376)] PushedFilters: [IsNotNull(ss_store_sk)] ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)> "
          },
          "1" : {
            "sign" : -1953172597,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 17335591170,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [2]: [ss_net_profit#288, s_state#314] Input [4]: [ss_store_sk#273, ss_net_profit#288, s_store_sk#290, s_state#314] "
          },
          "0" : {
            "sign" : 1828419307,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 396,
            "rowCount" : 9,
            "isRuntime" : false,
            "predicate" : " (unknown) HashAggregate Input [2]: [ss_net_profit#288, s_state#314] Keys [1]: [s_state#314] Functions [1]: [partial_sum(UnscaledValue(ss_net_profit#288))] Aggregate Attributes [1]: [sum#393L] Results [2]: [s_state#314, sum#394L] "
          },
          "2" : {
            "sign" : -328631642,
            "className" : "org.apache.spark.sql.execution.joins.BroadcastHashJoinExec",
            "sizeInBytes" : 21958415482,
            "rowCount" : 577853039,
            "isRuntime" : false,
            "predicate" : " (unknown) BroadcastHashJoin Left keys [1]: [ss_store_sk#273] Right keys [1]: [s_store_sk#290] Join type: Inner Join condition: None "
          },
          "7" : {
            "sign" : -113366717,
            "className" : "org.apache.spark.sql.execution.adaptive.BroadcastQueryStageExec",
            "sizeInBytes" : 1051496,
            "rowCount" : 365,
            "isRuntime" : true,
            "predicate" : " (unknown) BroadcastQueryStage Output [1]: [d_date_sk#319] Arguments: 2 "
          },
          "3" : {
            "sign" : -1498258504,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 5310811700,
            "rowCount" : 265540585,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [2]: [ss_store_sk#273, ss_net_profit#288] Input [4]: [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289, d_date_sk#319] "
          }
        },
        "links" : [ {
          "fromId" : 6,
          "fromName" : "Scan parquet spark_catalog.tpcds_100.store_sales",
          "toId" : 5,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "Filter",
          "toId" : 4,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 7,
          "fromName" : "BroadcastQueryStage",
          "toId" : 4,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "BroadcastHashJoin",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 8,
          "fromName" : "BroadcastQueryStage",
          "toId" : 2,
          "toName" : "BroadcastHashJoin",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "BroadcastHashJoin",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "HashAggregate(keys=[s_state#314], functions=[partial_sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, sum#394L])\n+- Project [ss_net_profit#288, s_state#314]\n   +- BroadcastHashJoin [ss_store_sk#273], [s_store_sk#290], Inner, BuildRight, false\n      :- Project [ss_store_sk#273, ss_net_profit#288]\n      :  +- BroadcastHashJoin [ss_sold_date_sk#289], [d_date_sk#319], Inner, BuildRight, false\n      :     :- Filter isnotnull(ss_store_sk#273)\n      :     :  +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#273,ss_net_profit#288,ss_sold_date_sk#289] Batched: true, DataFilters: [isnotnull(ss_store_sk#273)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#289), dynamicpruningexpression(ss_sold_date_sk#289 IN dynamicpruning#3..., PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n      :     :        +- SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n      :     :           +- AdaptiveSparkPlan isFinalPlan=false\n      :     :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=822]\n      :     :                 +- Project [d_date_sk#319]\n      :     :                    +- Filter (((isnotnull(d_month_seq#322) AND (d_month_seq#322 >= 1212)) AND (d_month_seq#322 <= 1223)) AND isnotnull(d_date_sk#319))\n      :     :                       +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_month_seq#322] Batched: true, DataFilters: [isnotnull(d_month_seq#322), (d_month_seq#322 >= 1212), (d_month_seq#322 <= 1223), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n      :     +- BroadcastQueryStage 2\n      :        +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n      +- BroadcastQueryStage 3\n         +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=388]\n            +- *(3) Filter isnotnull(s_store_sk#290)\n               +- *(3) ColumnarToRow\n                  +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#290,s_state#314] Batched: true, DataFilters: [isnotnull(s_store_sk#290)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 6306268440,
        "inputRowCount" : 262674315
      },
      "InitialPartitionNum" : 0,
      "PD" : { },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 2,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 3 ],
      "Objectives" : {
        "DurationInMs" : 18417,
        "TotalTasksDurationInMs" : 153116,
        "IOBytes" : {
          "Total" : 235814840,
          "Details" : {
            "IR" : 235792954,
            "IW" : 0,
            "SR" : 0,
            "SW" : 21886
          }
        }
      }
    },
    "7" : {
      "QSLogical" : {
        "operators" : {
          "4" : {
            "sign" : -1813850142,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 158806397681,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 158806397681,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "1" : {
            "sign" : -370171833,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.LocalLimit",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 107635447317,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 107635447317,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) LocalLimit Arguments: 100 "
          },
          "0" : {
            "sign" : -731817928,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.GlobalLimit",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 6100,
                "rowCount" : 100
              },
              "compileTime" : {
                "sizeInBytes" : 6100,
                "rowCount" : 100
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) GlobalLimit Arguments: 100 "
          },
          "2" : {
            "sign" : -70712690,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Sort",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 107635447317,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 107635447317,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Arguments: [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true "
          },
          "3" : {
            "sign" : -576688255,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 107635447317,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 107635447317,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          }
        },
        "links" : [ {
          "fromId" : 4,
          "fromName" : "Window",
          "toId" : 3,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Project",
          "toId" : 2,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Sort",
          "toId" : 1,
          "toName" : "LocalLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "LocalLimit",
          "toId" : 0,
          "toName" : "GlobalLimit",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "GlobalLimit 100\n+- LocalLimit 100\n   +- Sort [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], true\n      +- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n         +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n            +- Aggregate [s_state#352, s_county#353, spark_grouping_id#351L], [MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS total_sum#246, s_state#352, s_county#353, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS lochierarchy#247, MakeDecimal(sum(UnscaledValue(ss_net_profit#29)),17,2) AS _w0#362, (cast((shiftright(spark_grouping_id#351L, 1) & 1) as tinyint) + cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint)) AS _w1#366, CASE WHEN (cast((shiftright(spark_grouping_id#351L, 0) & 1) as tinyint) = 0) THEN s_state#352 END AS _w2#367]\n               +- Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n                  +- Project [ss_net_profit#29, s_state#83, s_county#82]\n                     +- Join Inner, (s_store_sk#59 = ss_store_sk#14)\n                        :- Project [ss_store_sk#14, ss_net_profit#29]\n                        :  +- Join Inner, (d_date_sk#31 = ss_sold_date_sk#30)\n                        :     :- Project [ss_store_sk#14, ss_net_profit#29, ss_sold_date_sk#30]\n                        :     :  +- Filter ((isnotnull(ss_sold_date_sk#30) AND isnotnull(ss_store_sk#14)) AND dynamicpruning#389 [ss_sold_date_sk#30])\n                        :     :     :  +- Project [d_date_sk#31]\n                        :     :     :     +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#8,ss_item_sk#9,ss_customer_sk#10,ss_cdemo_sk#11,ss_hdemo_sk#12,ss_addr_sk#13,ss_store_sk#14,ss_promo_sk#15,ss_ticket_number#16L,ss_quantity#17,ss_wholesale_cost#18,ss_list_price#19,ss_sales_price#20,ss_ext_discount_amt#21,ss_ext_sales_price#22,ss_ext_wholesale_cost#23,ss_ext_list_price#24,ss_ext_tax#25,ss_coupon_amt#26,ss_net_paid#27,ss_net_paid_inc_tax#28,ss_net_profit#29,ss_sold_date_sk#30] parquet\n                        :     +- Project [d_date_sk#31]\n                        :        +- Filter ((isnotnull(d_month_seq#34) AND ((d_month_seq#34 >= 1212) AND (d_month_seq#34 <= 1223))) AND isnotnull(d_date_sk#31))\n                        :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_date_id#32,d_date#33,d_month_seq#34,d_week_seq#35,d_quarter_seq#36,d_year#37,d_dow#38,d_moy#39,d_dom#40,d_qoy#41,d_fy_year#42,d_fy_quarter_seq#43,d_fy_week_seq#44,d_day_name#45,d_quarter_name#46,d_holiday#47,d_weekend#48,d_following_holiday#49,d_first_dom#50,d_last_dom#51,d_same_day_ly#52,d_same_day_lq#53,d_current_day#54,... 4 more fields] parquet\n                        +- Join LeftSemi, (s_state#83 = s_state#314)\n                           :- Project [s_store_sk#59, s_county#82, s_state#83]\n                           :  +- Filter isnotnull(s_store_sk#59)\n                           :     +- Relation spark_catalog.tpcds_100.store[s_store_sk#59,s_store_id#60,s_rec_start_date#61,s_rec_end_date#62,s_closed_date_sk#63,s_store_name#64,s_number_employees#65,s_floor_space#66,s_hours#67,s_manager#68,s_market_id#69,s_geography_class#70,s_market_desc#71,s_market_manager#72,s_division_id#73,s_division_name#74,s_company_id#75,s_company_name#76,s_street_number#77,s_street_name#78,s_street_type#79,s_suite_number#80,s_city#81,s_county#82,... 5 more fields] parquet\n                           +- Project [s_state#314]\n                              +- Filter (ranking#250 <= 5)\n                                 +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                                    +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5\n                                       +- Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314]\n                                          +- Project [ss_net_profit#288, s_state#314]\n                                             +- Join Inner, (s_store_sk#290 = ss_store_sk#273)\n                                                :- Project [ss_store_sk#273, ss_net_profit#288]\n                                                :  +- Join Inner, (d_date_sk#319 = ss_sold_date_sk#289)\n                                                :     :- Project [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289]\n                                                :     :  +- Filter ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289])\n                                                :     :     :  +- Project [d_date_sk#319]\n                                                :     :     :     +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                                                :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                                                :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#267,ss_item_sk#268,ss_customer_sk#269,ss_cdemo_sk#270,ss_hdemo_sk#271,ss_addr_sk#272,ss_store_sk#273,ss_promo_sk#274,ss_ticket_number#275L,ss_quantity#276,ss_wholesale_cost#277,ss_list_price#278,ss_sales_price#279,ss_ext_discount_amt#280,ss_ext_sales_price#281,ss_ext_wholesale_cost#282,ss_ext_list_price#283,ss_ext_tax#284,ss_coupon_amt#285,ss_net_paid#286,ss_net_paid_inc_tax#287,ss_net_profit#288,ss_sold_date_sk#289] parquet\n                                                :     +- Project [d_date_sk#319]\n                                                :        +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                                                :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                                                +- Project [s_store_sk#290, s_state#314]\n                                                   +- Filter isnotnull(s_store_sk#290)\n                                                      +- Relation spark_catalog.tpcds_100.store[s_store_sk#290,s_store_id#291,s_rec_start_date#292,s_rec_end_date#293,s_closed_date_sk#294,s_store_name#295,s_number_employees#296,s_floor_space#297,s_hours#298,s_manager#299,s_market_id#300,s_geography_class#301,s_market_desc#302,s_market_manager#303,s_division_id#304,s_division_name#305,s_company_id#306,s_company_name#307,s_street_number#308,s_street_name#309,s_street_type#310,s_suite_number#311,s_city#312,s_county#313,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : -84194909,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 1584,
            "rowCount" : 19,
            "isRuntime" : true,
            "predicate" : " (unknown) ShuffleQueryStage Output [7]: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, _w0#362, _w1#366, _w2#367] Arguments: 8 "
          },
          "1" : {
            "sign" : -1790237117,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 107635447317,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [5]: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] Input [8]: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, _w0#362, _w1#366, _w2#367, rank_within_parent#248] "
          },
          "0" : {
            "sign" : 1157773410,
            "className" : "org.apache.spark.sql.execution.TakeOrderedAndProjectExec",
            "sizeInBytes" : 6100,
            "rowCount" : 100,
            "isRuntime" : false,
            "predicate" : " (unknown) TakeOrderedAndProject Input [5]: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] Arguments: 100, [lochierarchy#247 DESC NULLS LAST, CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST, rank_within_parent#248 ASC NULLS FIRST], [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248] "
          },
          "2" : {
            "sign" : 718799746,
            "className" : "org.apache.spark.sql.execution.window.WindowExec",
            "sizeInBytes" : 158806397681,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Input [7]: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, _w0#362, _w1#366, _w2#367] Arguments: [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST] "
          },
          "3" : {
            "sign" : -272767221,
            "className" : "org.apache.spark.sql.execution.SortExec",
            "sizeInBytes" : -1,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Input [7]: [total_sum#246, s_state#352, s_county#353, lochierarchy#247, _w0#362, _w1#366, _w2#367] Arguments: [_w1#366 ASC NULLS FIRST, _w2#367 ASC NULLS FIRST, _w0#362 DESC NULLS LAST], false, 0 "
          }
        },
        "links" : [ {
          "fromId" : 4,
          "fromName" : "ShuffleQueryStage",
          "toId" : 3,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "Sort",
          "toId" : 2,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Window",
          "toId" : 1,
          "toName" : "Project",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Project",
          "toId" : 0,
          "toName" : "TakeOrderedAndProject",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "TakeOrderedAndProject(limit=100, orderBy=[lochierarchy#247 DESC NULLS LAST,CASE WHEN (lochierarchy#247 = 0) THEN s_state#352 END ASC NULLS FIRST,rank_within_parent#248 ASC NULLS FIRST], output=[total_sum#246,s_state#352,s_county#353,lochierarchy#247,rank_within_parent#248])\n+- Project [total_sum#246, s_state#352, s_county#353, lochierarchy#247, rank_within_parent#248]\n   +- Window [rank(_w0#362) windowspecdefinition(_w1#366, _w2#367, _w0#362 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#248], [_w1#366, _w2#367], [_w0#362 DESC NULLS LAST]\n      +- Sort [_w1#366 ASC NULLS FIRST, _w2#367 ASC NULLS FIRST, _w0#362 DESC NULLS LAST], false, 0\n         +- ShuffleQueryStage 8\n            +- Exchange hashpartitioning(_w1#366, _w2#367, 200), ENSURE_REQUIREMENTS, [plan_id=1582]\n               +- *(9) HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[sum(UnscaledValue(ss_net_profit#29))], output=[total_sum#246, s_state#352, s_county#353, lochierarchy#247, _w0#362, _w1#366, _w2#367])\n                  +- AQEShuffleRead coalesced\n                     +- ShuffleQueryStage 7\n                        +- Exchange hashpartitioning(s_state#352, s_county#353, spark_grouping_id#351L, 200), ENSURE_REQUIREMENTS, [plan_id=1529]\n                           +- *(8) HashAggregate(keys=[s_state#352, s_county#353, spark_grouping_id#351L], functions=[partial_sum(UnscaledValue(ss_net_profit#29))], output=[s_state#352, s_county#353, spark_grouping_id#351L, sum#392L])\n                              +- *(8) Expand [[ss_net_profit#29, s_state#83, s_county#82, 0], [ss_net_profit#29, s_state#83, null, 1], [ss_net_profit#29, null, null, 3]], [ss_net_profit#29, s_state#352, s_county#353, spark_grouping_id#351L]\n                                 +- *(8) Project [ss_net_profit#29, s_state#83, s_county#82]\n                                    +- *(8) BroadcastHashJoin [ss_store_sk#14], [s_store_sk#59], Inner, BuildRight, false\n                                       :- *(8) Project [ss_store_sk#14, ss_net_profit#29]\n                                       :  +- *(8) BroadcastHashJoin [ss_sold_date_sk#30], [d_date_sk#31], Inner, BuildRight, false\n                                       :     :- *(8) Filter isnotnull(ss_store_sk#14)\n                                       :     :  +- *(8) ColumnarToRow\n                                       :     :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#14,ss_net_profit#29,ss_sold_date_sk#30] Batched: true, DataFilters: [isnotnull(ss_store_sk#14)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#30), dynamicpruningexpression(ss_sold_date_sk#30 IN dynamicpruning#376)], PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n                                       :     :           +- ReusedSubquery SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n                                       :     +- BroadcastQueryStage 0\n                                       :        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                       :           +- *(1) Project [d_date_sk#31]\n                                       :              +- *(1) Filter (((isnotnull(d_month_seq#34) AND (d_month_seq#34 >= 1212)) AND (d_month_seq#34 <= 1223)) AND isnotnull(d_date_sk#31))\n                                       :                 +- *(1) ColumnarToRow\n                                       :                    +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#31,d_month_seq#34] Batched: true, DataFilters: [isnotnull(d_month_seq#34), (d_month_seq#34 >= 1212), (d_month_seq#34 <= 1223), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n                                       +- BroadcastQueryStage 6\n                                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1367]\n                                             +- *(7) BroadcastHashJoin [s_state#83], [s_state#314], LeftSemi, BuildRight, false\n                                                :- *(7) Filter isnotnull(s_store_sk#59)\n                                                :  +- *(7) ColumnarToRow\n                                                :     +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#59,s_county#82,s_state#83] Batched: true, DataFilters: [isnotnull(s_store_sk#59)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_county:string,s_state:string>\n                                                +- BroadcastQueryStage 5\n                                                   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=1225]\n                                                      +- *(6) Project [s_state#314]\n                                                         +- *(6) Filter (ranking#250 <= 5)\n                                                            +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n                                                               +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5, Final\n                                                                  +- *(5) Sort [s_state#314 ASC NULLS FIRST, _w0#260 DESC NULLS LAST], false, 0\n                                                                     +- *(5) HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, _w0#260, s_state#314])\n                                                                        +- AQEShuffleRead coalesced\n                                                                           +- ShuffleQueryStage 4\n                                                                              +- Exchange hashpartitioning(s_state#314, 200), ENSURE_REQUIREMENTS, [plan_id=867]\n                                                                                 +- *(4) HashAggregate(keys=[s_state#314], functions=[partial_sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, sum#394L])\n                                                                                    +- *(4) Project [ss_net_profit#288, s_state#314]\n                                                                                       +- *(4) BroadcastHashJoin [ss_store_sk#273], [s_store_sk#290], Inner, BuildRight, false\n                                                                                          :- *(4) Project [ss_store_sk#273, ss_net_profit#288]\n                                                                                          :  +- *(4) BroadcastHashJoin [ss_sold_date_sk#289], [d_date_sk#319], Inner, BuildRight, false\n                                                                                          :     :- *(4) Filter isnotnull(ss_store_sk#273)\n                                                                                          :     :  +- *(4) ColumnarToRow\n                                                                                          :     :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#273,ss_net_profit#288,ss_sold_date_sk#289] Batched: true, DataFilters: [isnotnull(ss_store_sk#273)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#289), dynamicpruningexpression(ss_sold_date_sk#289 IN dynamicpruning#3..., PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n                                                                                          :     :           +- SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n                                                                                          :     :              +- AdaptiveSparkPlan isFinalPlan=true\n                                                                                                                  +- == Final Plan ==\n                                                                                                                     BroadcastQueryStage 1\n                                                                                                                     +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                                                                                                  +- == Initial Plan ==\n                                                                                                                     BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=822]\n                                                                                                                     +- Project [d_date_sk#319]\n                                                                                                                        +- Filter (((isnotnull(d_month_seq#322) AND (d_month_seq#322 >= 1212)) AND (d_month_seq#322 <= 1223)) AND isnotnull(d_date_sk#319))\n                                                                                                                           +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_month_seq#322] Batched: true, DataFilters: [isnotnull(d_month_seq#322), (d_month_seq#322 >= 1212), (d_month_seq#322 <= 1223), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n                                                                                          :     +- BroadcastQueryStage 2\n                                                                                          :        +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                                                                          +- BroadcastQueryStage 3\n                                                                                             +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=388]\n                                                                                                +- *(3) Filter isnotnull(s_store_sk#290)\n                                                                                                   +- *(3) ColumnarToRow\n                                                                                                      +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#290,s_state#314] Batched: true, DataFilters: [isnotnull(s_store_sk#290)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 1584,
        "inputRowCount" : 19
      },
      "InitialPartitionNum" : 1,
      "PD" : {
        "2" : [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 276, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 7,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 12 ],
      "Objectives" : {
        "DurationInMs" : 293,
        "TotalTasksDurationInMs" : 284,
        "IOBytes" : {
          "Total" : 1483,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 1483,
            "SW" : 0
          }
        }
      }
    },
    "3" : {
      "QSLogical" : {
        "operators" : {
          "0" : {
            "sign" : 372694432,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Project",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 197,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 197,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Project Arguments: [s_state#314] "
          },
          "1" : {
            "sign" : -1147911259,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Filter",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 424,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 424,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Arguments: (ranking#250 <= 5) "
          },
          "2" : {
            "sign" : 168047038,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.Window",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 424,
                "rowCount" : -1
              },
              "compileTime" : {
                "sizeInBytes" : 424,
                "rowCount" : -1
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) Window Arguments: [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST] "
          },
          "3" : {
            "sign" : 631927862,
            "className" : "org.apache.spark.sql.catalyst.plans.logical.WindowGroupLimit",
            "stats" : {
              "runtime" : {
                "sizeInBytes" : 396,
                "rowCount" : 9
              },
              "compileTime" : {
                "sizeInBytes" : 396,
                "rowCount" : 9
              }
            },
            "isRuntime" : false,
            "predicate" : " (unknown) WindowGroupLimit Arguments: [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5 "
          }
        },
        "links" : [ {
          "fromId" : 3,
          "fromName" : "WindowGroupLimit",
          "toId" : 2,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Window",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_state#314]\n+- Filter (ranking#250 <= 5)\n   +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n      +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5\n         +- Aggregate [s_state#314], [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288)),17,2) AS _w0#260, s_state#314]\n            +- Project [ss_net_profit#288, s_state#314]\n               +- Join Inner, (s_store_sk#290 = ss_store_sk#273)\n                  :- Project [ss_store_sk#273, ss_net_profit#288]\n                  :  +- Join Inner, (d_date_sk#319 = ss_sold_date_sk#289)\n                  :     :- Project [ss_store_sk#273, ss_net_profit#288, ss_sold_date_sk#289]\n                  :     :  +- Filter ((isnotnull(ss_store_sk#273) AND isnotnull(ss_sold_date_sk#289)) AND dynamicpruning#376 [ss_sold_date_sk#289])\n                  :     :     :  +- Project [d_date_sk#319]\n                  :     :     :     +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                  :     :     :        +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                  :     :     +- Relation spark_catalog.tpcds_100.store_sales[ss_sold_time_sk#267,ss_item_sk#268,ss_customer_sk#269,ss_cdemo_sk#270,ss_hdemo_sk#271,ss_addr_sk#272,ss_store_sk#273,ss_promo_sk#274,ss_ticket_number#275L,ss_quantity#276,ss_wholesale_cost#277,ss_list_price#278,ss_sales_price#279,ss_ext_discount_amt#280,ss_ext_sales_price#281,ss_ext_wholesale_cost#282,ss_ext_list_price#283,ss_ext_tax#284,ss_coupon_amt#285,ss_net_paid#286,ss_net_paid_inc_tax#287,ss_net_profit#288,ss_sold_date_sk#289] parquet\n                  :     +- Project [d_date_sk#319]\n                  :        +- Filter ((isnotnull(d_month_seq#322) AND ((d_month_seq#322 >= 1212) AND (d_month_seq#322 <= 1223))) AND isnotnull(d_date_sk#319))\n                  :           +- Relation spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_date_id#320,d_date#321,d_month_seq#322,d_week_seq#323,d_quarter_seq#324,d_year#325,d_dow#326,d_moy#327,d_dom#328,d_qoy#329,d_fy_year#330,d_fy_quarter_seq#331,d_fy_week_seq#332,d_day_name#333,d_quarter_name#334,d_holiday#335,d_weekend#336,d_following_holiday#337,d_first_dom#338,d_last_dom#339,d_same_day_ly#340,d_same_day_lq#341,d_current_day#342,... 4 more fields] parquet\n                  +- Project [s_store_sk#290, s_state#314]\n                     +- Filter isnotnull(s_store_sk#290)\n                        +- Relation spark_catalog.tpcds_100.store[s_store_sk#290,s_store_id#291,s_rec_start_date#292,s_rec_end_date#293,s_closed_date_sk#294,s_store_name#295,s_number_employees#296,s_floor_space#297,s_hours#298,s_manager#299,s_market_id#300,s_geography_class#301,s_market_desc#302,s_market_manager#303,s_division_id#304,s_division_name#305,s_company_id#306,s_company_name#307,s_street_number#308,s_street_name#309,s_street_type#310,s_suite_number#311,s_city#312,s_county#313,... 5 more fields] parquet\n"
      },
      "QSPhysical" : {
        "operators" : {
          "4" : {
            "sign" : 544423811,
            "className" : "org.apache.spark.sql.execution.SortExec",
            "sizeInBytes" : -1,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Sort Input [3]: [s_state#314, _w0#260, s_state#314] Arguments: [s_state#314 ASC NULLS FIRST, _w0#260 DESC NULLS LAST], false, 0 "
          },
          "5" : {
            "sign" : -1250466687,
            "className" : "org.apache.spark.sql.execution.aggregate.HashAggregateExec",
            "sizeInBytes" : 9216,
            "rowCount" : 288,
            "isRuntime" : true,
            "predicate" : " (unknown) HashAggregate Input [2]: [s_state#314, sum#394L] Keys [1]: [s_state#314] Functions [1]: [sum(UnscaledValue(ss_net_profit#288))] Aggregate Attributes [1]: [sum(UnscaledValue(ss_net_profit#288))#256L] Results [3]: [s_state#314, MakeDecimal(sum(UnscaledValue(ss_net_profit#288))#256L,17,2) AS _w0#260, s_state#314] "
          },
          "6" : {
            "sign" : 925572992,
            "className" : "org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec",
            "sizeInBytes" : 396,
            "rowCount" : 9,
            "isRuntime" : false,
            "predicate" : " (unknown) ShuffleQueryStage Output [2]: [s_state#314, sum#394L] Arguments: 4 "
          },
          "1" : {
            "sign" : -1079964175,
            "className" : "org.apache.spark.sql.execution.FilterExec",
            "sizeInBytes" : 424,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Filter Input [4]: [s_state#314, _w0#260, s_state#314, ranking#250] Condition : (ranking#250 <= 5) "
          },
          "0" : {
            "sign" : 1367630418,
            "className" : "org.apache.spark.sql.execution.ProjectExec",
            "sizeInBytes" : 197,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Project Output [1]: [s_state#314] Input [4]: [s_state#314, _w0#260, s_state#314, ranking#250] "
          },
          "2" : {
            "sign" : -631795596,
            "className" : "org.apache.spark.sql.execution.window.WindowExec",
            "sizeInBytes" : 424,
            "rowCount" : -1,
            "isRuntime" : false,
            "predicate" : " (unknown) Window Input [3]: [s_state#314, _w0#260, s_state#314] Arguments: [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST] "
          },
          "3" : {
            "sign" : -1318496832,
            "className" : "org.apache.spark.sql.execution.window.WindowGroupLimitExec",
            "sizeInBytes" : 396,
            "rowCount" : 9,
            "isRuntime" : false,
            "predicate" : " (unknown) WindowGroupLimit Input [3]: [s_state#314, _w0#260, s_state#314] Arguments: [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5, Final "
          }
        },
        "links" : [ {
          "fromId" : 6,
          "fromName" : "ShuffleQueryStage",
          "toId" : 5,
          "toName" : "HashAggregate",
          "linkType" : "Operator"
        }, {
          "fromId" : 5,
          "fromName" : "HashAggregate",
          "toId" : 4,
          "toName" : "Sort",
          "linkType" : "Operator"
        }, {
          "fromId" : 4,
          "fromName" : "Sort",
          "toId" : 3,
          "toName" : "WindowGroupLimit",
          "linkType" : "Operator"
        }, {
          "fromId" : 3,
          "fromName" : "WindowGroupLimit",
          "toId" : 2,
          "toName" : "Window",
          "linkType" : "Operator"
        }, {
          "fromId" : 2,
          "fromName" : "Window",
          "toId" : 1,
          "toName" : "Filter",
          "linkType" : "Operator"
        }, {
          "fromId" : 1,
          "fromName" : "Filter",
          "toId" : 0,
          "toName" : "Project",
          "linkType" : "Operator"
        } ],
        "rawPlan" : "Project [s_state#314]\n+- Filter (ranking#250 <= 5)\n   +- Window [rank(_w0#260) windowspecdefinition(s_state#314, _w0#260 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ranking#250], [s_state#314], [_w0#260 DESC NULLS LAST]\n      +- WindowGroupLimit [s_state#314], [_w0#260 DESC NULLS LAST], rank(_w0#260), 5, Final\n         +- Sort [s_state#314 ASC NULLS FIRST, _w0#260 DESC NULLS LAST], false, 0\n            +- HashAggregate(keys=[s_state#314], functions=[sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, _w0#260, s_state#314])\n               +- ShuffleQueryStage 4\n                  +- Exchange hashpartitioning(s_state#314, 200), ENSURE_REQUIREMENTS, [plan_id=867]\n                     +- *(4) HashAggregate(keys=[s_state#314], functions=[partial_sum(UnscaledValue(ss_net_profit#288))], output=[s_state#314, sum#394L])\n                        +- *(4) Project [ss_net_profit#288, s_state#314]\n                           +- *(4) BroadcastHashJoin [ss_store_sk#273], [s_store_sk#290], Inner, BuildRight, false\n                              :- *(4) Project [ss_store_sk#273, ss_net_profit#288]\n                              :  +- *(4) BroadcastHashJoin [ss_sold_date_sk#289], [d_date_sk#319], Inner, BuildRight, false\n                              :     :- *(4) Filter isnotnull(ss_store_sk#273)\n                              :     :  +- *(4) ColumnarToRow\n                              :     :     +- FileScan parquet spark_catalog.tpcds_100.store_sales[ss_store_sk#273,ss_net_profit#288,ss_sold_date_sk#289] Batched: true, DataFilters: [isnotnull(ss_store_sk#273)], Format: Parquet, Location: InMemoryFileIndex(1823 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store_..., PartitionFilters: [isnotnull(ss_sold_date_sk#289), dynamicpruningexpression(ss_sold_date_sk#289 IN dynamicpruning#3..., PushedFilters: [IsNotNull(ss_store_sk)], ReadSchema: struct<ss_store_sk:int,ss_net_profit:decimal(7,2)>\n                              :     :           +- SubqueryBroadcast dynamicpruning#376, 0, [d_date_sk#319], [id=#825]\n                              :     :              +- AdaptiveSparkPlan isFinalPlan=true\n                                                      +- == Final Plan ==\n                                                         BroadcastQueryStage 1\n                                                         +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                                                      +- == Initial Plan ==\n                                                         BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=822]\n                                                         +- Project [d_date_sk#319]\n                                                            +- Filter (((isnotnull(d_month_seq#322) AND (d_month_seq#322 >= 1212)) AND (d_month_seq#322 <= 1223)) AND isnotnull(d_date_sk#319))\n                                                               +- FileScan parquet spark_catalog.tpcds_100.date_dim[d_date_sk#319,d_month_seq#322] Batched: true, DataFilters: [isnotnull(d_month_seq#322), (d_month_seq#322 >= 1212), (d_month_seq#322 <= 1223), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1212), LessThanOrEqual(d_month_seq,1223),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>\n                              :     +- BroadcastQueryStage 2\n                              :        +- ReusedExchange [d_date_sk#319], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=346]\n                              +- BroadcastQueryStage 3\n                                 +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=388]\n                                    +- *(3) Filter isnotnull(s_store_sk#290)\n                                       +- *(3) ColumnarToRow\n                                          +- FileScan parquet spark_catalog.tpcds_100.store[s_store_sk#290,s_state#314] Batched: true, DataFilters: [isnotnull(s_store_sk#290)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://node7-opa:8020/user/spark_benchmark/tpcds_100/dataset/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>\n"
      },
      "IM" : {
        "inputSizeInBytes" : 9216,
        "inputRowCount" : 288
      },
      "InitialPartitionNum" : 200,
      "PD" : {
        "0" : [ 0, 0, 0, 0, 2560, 0, 0, 0, 0, 2560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2560, 2560, 0, 0, 0, 0, 0, 0, 0, 2560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2560, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]
      },
      "RunningQueryStageSnapshot" : {
        "RunningTasksNum" : 0,
        "FinishedTasksNum" : 0,
        "FinishedTasksTotalTimeInMs" : 0.0,
        "FinishedTasksDistributionInMs" : [ 0.0, 0.0, 0.0, 0.0, 0.0 ]
      },
      "QueryStageOptimizationId" : 3,
      "RuntimeConfiguration" : {
        "theta_p" : [ {
          "spark.sql.adaptive.advisoryPartitionSizeInBytes" : "64MB"
        }, {
          "spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin" : "0.2"
        }, {
          "spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold" : "0MB"
        }, {
          "spark.sql.adaptive.autoBroadcastJoinThreshold" : "10MB"
        }, {
          "spark.sql.shuffle.partitions" : "200"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes" : "256MB"
        }, {
          "spark.sql.adaptive.skewJoin.skewedPartitionFactor" : "5"
        }, {
          "spark.sql.files.maxPartitionBytes" : "128MB"
        }, {
          "spark.sql.files.openCostInBytes" : "4MB"
        } ],
        "theta_s" : [ {
          "spark.sql.adaptive.rebalancePartitionsSmallPartitionFactor" : "0.2"
        }, {
          "spark.sql.adaptive.coalescePartitions.minPartitionSize" : "1024KB"
        } ]
      },
      "RelevantQueryStageIds" : [ 5 ],
      "Objectives" : {
        "DurationInMs" : 427,
        "TotalTasksDurationInMs" : 420,
        "IOBytes" : {
          "Total" : 21886,
          "Details" : {
            "IR" : 0,
            "IW" : 0,
            "SR" : 21886,
            "SW" : 0
          }
        }
      }
    }
  },
  "SQLStartTimeInMs" : 1702227226467,
  "SQLEndTimeInMs" : 1702227253384,
  "Objectives" : {
    "DurationInMs" : 26917,
    "IOBytes" : {
      "Total" : 471879387,
      "Details" : {
        "IR" : 471728019,
        "IW" : 0,
        "SR" : 75684,
        "SW" : 75684
      }
    }
  }
}
